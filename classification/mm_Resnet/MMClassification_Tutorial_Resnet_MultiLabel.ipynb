{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will introduce how to use MMPretrain for a multi-label classification task. <br>\n",
    "This approach is suitable for scenarios where an image may belong to two or more categories. <br>\n",
    "However, if your dataset includes bounding box annotations, it is recommended to use object detection algorithms instead. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/test/MMdet'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/test/MMdet/mmpretrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd mmpretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmpretrain.apis import list_models\n",
    "from mmpretrain.apis import get_model\n",
    "from mmpretrain.apis import inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet101-csra_1xb16_voc07-448px']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_models(task='Multi-Label Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/csra/resnet101-csra_1xb16_voc07-448px_20220722-29efb40a.pth\n"
     ]
    }
   ],
   "source": [
    "#there is only one\n",
    "model_name = 'resnet101-csra_1xb16_voc07-448px'\n",
    "model = get_model(model_name, pretrained=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['cat', 'dog']\n",
      "Prediction scores: [np.float32(0.8987128), np.float32(0.6286075)]\n"
     ]
    }
   ],
   "source": [
    "from mmengine.fileio import get\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load the image\n",
    "image_path = 'demo/cat-dog.png' # replace with your image\n",
    "with open(image_path, 'rb') as f:\n",
    "    img = Image.open(f).convert('RGB')\n",
    "\n",
    "# Preprocessing (resize to 448px as indicated in the model name)\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "img_tensor = transform(img).unsqueeze(0).to('cuda')  # Add batch dimension and move to GPU\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    result = model(img_tensor, mode='predict')\n",
    "\n",
    "# Process results\n",
    "# The model outputs probabilities for each class\n",
    "scores = result[0].pred_score.cpu().numpy()\n",
    "\n",
    "# You can set a threshold to determine positive predictions\n",
    "threshold = 0.5\n",
    "predicted_labels = np.where(scores > threshold)[0] # Get indices of classes above threshold\n",
    "\n",
    "# Get class names (if available in the model)\n",
    "class_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "predicted_class_names = [class_names[idx] for idx in predicted_labels]\n",
    "print(\"Predicted classes:\", predicted_class_names)\n",
    "scores = [scores[idx] for idx in predicted_labels]\n",
    "print(\"Prediction scores:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the VOC2007 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VOCtrainval_06-Nov-2007.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VOCtrainval_06-Nov-2007.tar: 100%|███████████| 460M/460M [04:00<00:00, 1.91MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting VOCtrainval_06-Nov-2007.tar...\n",
      "Downloading VOCtest_06-Nov-2007.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VOCtest_06-Nov-2007.tar: 100%|████████████████| 451M/451M [10:03<00:00, 747kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting VOCtest_06-Nov-2007.tar...\n",
      "Download and extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# URLs for VOC2007 dataset\n",
    "voc2007_urls = {\n",
    "    'trainval': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar',\n",
    "    'test': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar'\n",
    "}\n",
    "\n",
    "# Download and extract datasets\n",
    "for split, url in voc2007_urls.items():\n",
    "    # Download file\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join('data', filename)\n",
    "    \n",
    "    print(f\"Downloading {filename}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filepath, 'wb') as f, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=filename\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = f.write(data)\n",
    "            bar.update(size)\n",
    "    \n",
    "    # Extract file\n",
    "    print(f\"Extracting {filename}...\")\n",
    "    with tarfile.open(filepath) as tar:\n",
    "        tar.extractall('data')\n",
    "        \n",
    "    # Clean up tar file to save space\n",
    "    os.remove(filepath)\n",
    "    \n",
    "print(\"Download and extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink from data/VOCdevkit/VOC2007/JPEGImages to data/VOC2007/JPEGImages\n",
      "Copying data/VOCdevkit/VOC2007/ImageSets/Main/test.txt to data/VOC2007/ImageSets/Main/test.txt\n",
      "Copying data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt to data/VOC2007/ImageSets/Main/trainval.txt\n",
      "Copying data/VOCdevkit/VOC2007/Annotations to data/VOC2007/Annotations\n",
      "Dataset structure prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "# Here, we create directory of the dataset for training\n",
    "# Only part of the dataset is needed for this task, so we only keep necessary part, that make it easier for you to follow\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the target structure\n",
    "os.makedirs('data/VOC2007', exist_ok=True)\n",
    "os.makedirs('data/VOC2007/ImageSets', exist_ok=True)\n",
    "\n",
    "# Check if downloaded data is in the expected location\n",
    "voc_source = 'data/VOCdevkit/VOC2007'\n",
    "voc_target = 'data/VOC2007'\n",
    "\n",
    "if os.path.exists(voc_source):\n",
    "    # Link JPEGImages directory\n",
    "    src_jpeg = os.path.join(voc_source, 'JPEGImages')\n",
    "    dst_jpeg = os.path.join(voc_target, 'JPEGImages')\n",
    "    \n",
    "    if os.path.exists(src_jpeg) and not os.path.exists(dst_jpeg):\n",
    "        try:\n",
    "            os.symlink(os.path.abspath(src_jpeg), dst_jpeg)\n",
    "            print(f\"Created symlink from {src_jpeg} to {dst_jpeg}\")\n",
    "        except OSError:\n",
    "            print(f\"Copying {src_jpeg} to {dst_jpeg}\")\n",
    "            shutil.copytree(src_jpeg, dst_jpeg)\n",
    "    \n",
    "    # Copy just test.txt and trainval.txt from ImageSets/Main\n",
    "    src_main = os.path.join(voc_source, 'ImageSets/Main')\n",
    "    dst_main = os.path.join(voc_target, 'ImageSets/Main')\n",
    "    \n",
    "    os.makedirs(dst_main, exist_ok=True)\n",
    "    \n",
    "    for file in ['test.txt', 'trainval.txt']:\n",
    "        src_file = os.path.join(src_main, file)\n",
    "        dst_file = os.path.join(dst_main, file)\n",
    "        \n",
    "        if os.path.exists(src_file) and not os.path.exists(dst_file):\n",
    "            print(f\"Copying {src_file} to {dst_file}\")\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "    \n",
    "    # Copy Annotations directory\n",
    "    src_annot = os.path.join(voc_source, 'Annotations')\n",
    "    dst_annot = os.path.join(voc_target, 'Annotations')\n",
    "    \n",
    "    if os.path.exists(src_annot) and not os.path.exists(dst_annot):\n",
    "        print(f\"Copying {src_annot} to {dst_annot}\")\n",
    "        shutil.copytree(src_annot, dst_annot)\n",
    "    \n",
    "    print(\"Dataset structure prepared successfully!\")\n",
    "else:\n",
    "    print(f\"Error: Source directory {voc_source} not found. Check your download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9963 XML files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning XML files: 100%|████████████████| 9963/9963 [00:00<00:00, 12089.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9963 XML files\n",
      "Cleaned annotations saved to ./data/VOC2007/Annotations\n",
      "\n",
      "Sample of cleaned XML:\n",
      "<annotation>\n",
      "\t<filename>007813.jpg</filename>\n",
      "\t<size>\n",
      "\t\t<width>500</width>\n",
      "\t\t<height>375</height>\n",
      "\t\t<depth>3</depth>\n",
      "\t</size>\n",
      "\t<object>\n",
      "\t\t<name>dog</name>\n",
      "\t\t<difficult>0</difficult>\n",
      "\t\t</object>\n",
      "\t<object>\n",
      "\t\t<name>person</name>\n",
      "\t\t<difficult>0</difficult>\n",
      "\t\t</object>\n",
      "\t<object>\n",
      "\t\t<name>diningtable</name>\n",
      "\t\t<difficult>1</difficult>\n",
      "\t\t</object>\n",
      "</annotation>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# only part of the info in xml is needed, so we simplify them\n",
    "# after that, you can create your own dataset mimicking the format\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_xml(input_path, output_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(input_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Keep only necessary elements\n",
    "    necessary_elements = ['filename', 'size']\n",
    "    \n",
    "    # Remove unnecessary elements at the root level\n",
    "    for child in list(root):\n",
    "        if child.tag not in necessary_elements and child.tag != 'object':\n",
    "            root.remove(child)\n",
    "    \n",
    "    # Process each object element - keep only name and difficult\n",
    "    for obj in root.findall('object'):\n",
    "        # Extract name and difficult flag\n",
    "        name = obj.find('name')\n",
    "        difficult = obj.find('difficult')\n",
    "        \n",
    "        # Remove all other child elements\n",
    "        for child in list(obj):\n",
    "            if child.tag != 'name' and child.tag != 'difficult':\n",
    "                obj.remove(child)\n",
    "    \n",
    "    # Write cleaned XML to output file\n",
    "    tree.write(output_path)\n",
    "\n",
    "def main():\n",
    "    # Set input and output directories\n",
    "    _dir = './data/VOC2007/Annotations'\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all XML files in the input directory\n",
    "    xml_files = glob(os.path.join(_dir, '*.xml'))\n",
    "    \n",
    "    print(f\"Found {len(xml_files)} XML files to process\")\n",
    "    \n",
    "    # Process each XML file\n",
    "    for xml_file in tqdm(xml_files, desc=\"Cleaning XML files\"):\n",
    "        # Get just the filename\n",
    "        basename = os.path.basename(xml_file)\n",
    "        output_path = os.path.join(_dir, basename)\n",
    "        \n",
    "        # Clean and save the XML\n",
    "        clean_xml(xml_file, output_path)\n",
    "    \n",
    "    print(f\"Processed {len(xml_files)} XML files\")\n",
    "    print(f\"Cleaned annotations saved to {_dir}\")\n",
    "    \n",
    "    # Example of first processed file\n",
    "    if xml_files:\n",
    "        sample_file = os.path.join(_dir, os.path.basename(xml_files[0]))\n",
    "        print(\"\\nSample of cleaned XML:\")\n",
    "        with open(sample_file, 'r') as f:\n",
    "            print(f.read())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 5011 images\n",
      "Test dataset: 4952 images\n"
     ]
    }
   ],
   "source": [
    "from mmpretrain.datasets import VOC\n",
    "\n",
    "# Try loading the datasets again\n",
    "train_dataset = VOC(data_root='data/VOC2007', split='trainval')\n",
    "print(f\"Training dataset: {len(train_dataset)} images\")\n",
    "\n",
    "test_dataset = VOC(data_root='data/VOC2007', split='test')\n",
    "print(f\"Test dataset: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can make a copy of configs/csra/resnet101-csra_1xb16_voc07-448px.py and revise\n",
    "# remember to change num_classes if your num_classes is not 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/23 10:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 171514111\n",
      "    GPU 0,1: NVIDIA GeForce RTX 5090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.8, V12.8.93\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.8.0.dev20250422+cu128\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120;-gencode;arch=compute_120,code=compute_120\n",
      "  - CuDNN 90.8\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=b182d84228cd3fcff23cbc5e945af307fd762f5b, CUDA_VERSION=12.8, CUDNN_VERSION=9.8.0, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.22.0.dev20250422+cu128\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 171514111\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "04/23 10:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet101_8xb32_in1k_20210831-539c63f8.pth'\n",
      "data_preprocessor = dict(\n",
      "    mean=[\n",
      "        0,\n",
      "        0,\n",
      "        0,\n",
      "    ],\n",
      "    num_classes=20,\n",
      "    std=[\n",
      "        255,\n",
      "        255,\n",
      "        255,\n",
      "    ],\n",
      "    to_onehot=True,\n",
      "    to_rgb=True)\n",
      "dataset_type = 'VOC'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\n",
      "default_scope = 'mmpretrain'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=101,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet101_8xb32_in1k_20210831-539c63f8.pth',\n",
      "            prefix='backbone',\n",
      "            type='Pretrained'),\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    head=dict(\n",
      "        in_channels=2048,\n",
      "        lam=0.1,\n",
      "        loss=dict(loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        num_classes=20,\n",
      "        num_heads=1,\n",
      "        type='CSRAClsHead'),\n",
      "    neck=None,\n",
      "    type='ImageClassifier')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0002, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    paramwise_cfg=dict(custom_keys=dict(head=dict(lr_mult=10))))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=1,\n",
      "        start_factor=1e-07,\n",
      "        type='LinearLR'),\n",
      "    dict(by_epoch=True, gamma=0.1, step_size=6, type='StepLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, seed=None)\n",
      "resume = False\n",
      "test_cfg = dict()\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    dataset=dict(\n",
      "        data_root='data/VOC2007',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(scale=448, type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'sample_idx',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'flip',\n",
      "                    'flip_direction',\n",
      "                    'gt_label_difficult',\n",
      "                ),\n",
      "                type='PackInputs'),\n",
      "        ],\n",
      "        split='test',\n",
      "        type='VOC'),\n",
      "    num_workers=5,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = [\n",
      "    dict(type='VOCMultiLabelMetric'),\n",
      "    dict(average='micro', type='VOCMultiLabelMetric'),\n",
      "    dict(type='VOCAveragePrecision'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(scale=448, type='Resize'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'sample_idx',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'flip',\n",
      "            'flip_direction',\n",
      "            'gt_label_difficult',\n",
      "        ),\n",
      "        type='PackInputs'),\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=20, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    dataset=dict(\n",
      "        data_root='data/VOC2007',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                crop_ratio_range=(\n",
      "                    0.7,\n",
      "                    1.0,\n",
      "                ),\n",
      "                scale=448,\n",
      "                type='RandomResizedCrop'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='trainval',\n",
      "        type='VOC'),\n",
      "    num_workers=5,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(crop_ratio_range=(\n",
      "        0.7,\n",
      "        1.0,\n",
      "    ), scale=448, type='RandomResizedCrop'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "val_cfg = dict()\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    dataset=dict(\n",
      "        data_root='data/VOC2007',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(scale=448, type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'sample_idx',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'flip',\n",
      "                    'flip_direction',\n",
      "                    'gt_label_difficult',\n",
      "                ),\n",
      "                type='PackInputs'),\n",
      "        ],\n",
      "        split='test',\n",
      "        type='VOC'),\n",
      "    num_workers=5,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = [\n",
      "    dict(type='VOCMultiLabelMetric'),\n",
      "    dict(average='micro', type='VOCMultiLabelMetric'),\n",
      "    dict(type='VOCAveragePrecision'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/resnet101-csra_1xb16_voc07-448px'\n",
      "\n",
      "04/23 10:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "04/23 10:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "04/23 10:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- head.csra_heads.0.head.weight:lr=0.002\n",
      "04/23 10:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- head.csra_heads.0.head.weight:weight_decay=0.0001\n",
      "04/23 10:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- head.csra_heads.0.head.weight:lr_mult=10\n",
      "04/23 10:52:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Neither thr nor k is given, set thr as 0.5 by default.\n",
      "04/23 10:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone in model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet101_8xb32_in1k_20210831-539c63f8.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet101_8xb32_in1k_20210831-539c63f8.pth\n",
      "04/23 10:52:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "04/23 10:52:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "04/23 10:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/test/MMdet/mmpretrain/work_dirs/resnet101-csra_1xb16_voc07-448px.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/MMdet/mmengine/mmengine/logging/message_hub.py:346: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/aten/src/ATen/native/Scalar.cpp:22.)\n",
      "  value = value.item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/23 10:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/314]  base_lr: 6.3259e-05 lr: 6.3259e-05  eta: 0:18:34  time: 0.1756  data_time: 0.0012  memory: 8348  loss: 3.0095\n",
      "04/23 10:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/314]  base_lr: 1.2716e-04 lr: 1.2716e-04  eta: 0:18:03  time: 0.1760  data_time: 0.0010  memory: 8348  loss: 1.5298\n",
      "04/23 10:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/314]  base_lr: 1.9105e-04 lr: 1.9105e-04  eta: 0:17:40  time: 0.1755  data_time: 0.0010  memory: 8348  loss: 1.2622\n",
      "04/23 10:53:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:53:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "04/23 10:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/310]    eta: 0:00:55  time: 0.2661  data_time: 0.0002  memory: 8348  \n",
      "04/23 10:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][200/310]    eta: 0:00:29  time: 0.2664  data_time: 0.0003  memory: 1182  \n",
      "04/23 10:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][300/310]    eta: 0:00:02  time: 0.0287  data_time: 0.0002  memory: 1186  \n",
      "04/23 10:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][310/310]    multi-label/precision: 87.5851  multi-label/recall: 82.1945  multi-label/f1-score: 83.8786  multi-label/precision_micro: 89.3030  multi-label/recall_micro: 84.0439  multi-label/f1-score_micro: 86.5937  multi-label/mAP: 91.5839  data_time: 0.0008  time: 0.2091\n",
      "04/23 10:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:15:06  time: 0.0838  data_time: 0.0007  memory: 8348  loss: 1.1195\n",
      "04/23 10:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:13:31  time: 0.0838  data_time: 0.0007  memory: 8348  loss: 1.1990\n",
      "04/23 10:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][300/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:12:24  time: 0.0833  data_time: 0.0003  memory: 8348  loss: 1.0432\n",
      "04/23 10:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "04/23 10:55:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][100/310]    eta: 0:00:05  time: 0.0271  data_time: 0.0002  memory: 8348  \n",
      "04/23 10:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][200/310]    eta: 0:00:03  time: 0.0478  data_time: 0.0002  memory: 1182  \n",
      "04/23 10:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][300/310]    eta: 0:00:00  time: 0.0267  data_time: 0.0002  memory: 1186  \n",
      "04/23 10:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][310/310]    multi-label/precision: 90.2368  multi-label/recall: 86.2659  multi-label/f1-score: 87.8248  multi-label/precision_micro: 92.5395  multi-label/recall_micro: 88.4358  multi-label/f1-score_micro: 90.4411  multi-label/mAP: 93.8886  data_time: 0.0003  time: 0.0276\n",
      "04/23 10:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:11:27  time: 0.0832  data_time: 0.0003  memory: 8348  loss: 1.0925\n",
      "04/23 10:55:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:10:48  time: 0.0833  data_time: 0.0003  memory: 8348  loss: 0.6992\n",
      "04/23 10:55:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][300/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:10:16  time: 0.0833  data_time: 0.0003  memory: 8348  loss: 0.6307\n",
      "04/23 10:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "04/23 10:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][100/310]    eta: 0:00:05  time: 0.0270  data_time: 0.0002  memory: 8348  \n",
      "04/23 10:55:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][200/310]    eta: 0:00:02  time: 0.0268  data_time: 0.0002  memory: 1182  \n",
      "04/23 10:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][300/310]    eta: 0:00:00  time: 0.0267  data_time: 0.0002  memory: 1186  \n",
      "04/23 10:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][310/310]    multi-label/precision: 90.9872  multi-label/recall: 87.0530  multi-label/f1-score: 88.4835  multi-label/precision_micro: 91.8584  multi-label/recall_micro: 89.9330  multi-label/f1-score_micro: 90.8855  multi-label/mAP: 94.5074  data_time: 0.0003  time: 0.0270\n",
      "04/23 10:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:56:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:09:44  time: 0.0833  data_time: 0.0004  memory: 8348  loss: 0.7276\n",
      "04/23 10:56:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:09:20  time: 0.0833  data_time: 0.0003  memory: 8348  loss: 0.8217\n",
      "04/23 10:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][300/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:08:59  time: 0.0833  data_time: 0.0003  memory: 8348  loss: 0.6365\n",
      "04/23 10:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "04/23 10:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][100/310]    eta: 0:00:06  time: 0.0269  data_time: 0.0002  memory: 8348  \n",
      "04/23 10:56:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][200/310]    eta: 0:00:03  time: 0.0270  data_time: 0.0002  memory: 1182  \n",
      "04/23 10:56:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][300/310]    eta: 0:00:00  time: 0.0269  data_time: 0.0002  memory: 1186  \n",
      "04/23 10:56:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][310/310]    multi-label/precision: 91.4108  multi-label/recall: 87.1776  multi-label/f1-score: 89.0995  multi-label/precision_micro: 93.4968  multi-label/recall_micro: 89.1772  multi-label/f1-score_micro: 91.2859  multi-label/mAP: 94.5982  data_time: 0.0003  time: 0.0276\n",
      "04/23 10:56:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:08:37  time: 0.0832  data_time: 0.0003  memory: 8348  loss: 0.5232\n",
      "04/23 10:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:08:19  time: 0.0839  data_time: 0.0008  memory: 8348  loss: 0.6090\n",
      "04/23 10:56:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][300/314]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:08:03  time: 0.0838  data_time: 0.0007  memory: 8348  loss: 0.6019\n",
      "04/23 10:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet101-csra_1xb16_voc07-448px_20250423_105233\n",
      "04/23 10:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "04/23 10:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][100/310]    eta: 0:00:05  time: 0.0271  data_time: 0.0002  memory: 8348  \n",
      "04/23 10:57:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][200/310]    eta: 0:00:02  time: 0.0270  data_time: 0.0002  memory: 1182  \n",
      "04/23 10:57:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][300/310]    eta: 0:00:00  time: 0.0270  data_time: 0.0002  memory: 1186  \n",
      "04/23 10:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][310/310]    multi-label/precision: 91.2028  multi-label/recall: 89.0263  multi-label/f1-score: 89.9861  multi-label/precision_micro: 93.5556  multi-label/recall_micro: 90.0471  multi-label/f1-score_micro: 91.7678  multi-label/mAP: 94.8057  data_time: 0.0003  time: 0.0270\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/MMdet/mmpretrain/tools/train.py:162\u001b[0m\n\u001b[1;32m    158\u001b[0m     runner\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MMdet/mmpretrain/tools/train.py:158\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     runner \u001b[38;5;241m=\u001b[39m RUNNERS\u001b[38;5;241m.\u001b[39mbuild(cfg)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/runner/loops.py:98\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    104\u001b[0m                  \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs)):\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/runner/loops.py:115\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/runner/loops.py:131\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx\u001b[38;5;241m=\u001b[39midx, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    136\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m    137\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[1;32m    138\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/model/base_model/base_model.py:116\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    114\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward(data, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_losses(losses)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_losses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_vars\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/optim/optimizer/optimizer_wrapper.py:201\u001b[0m, in \u001b[0;36mOptimWrapper.update_params\u001b[0;34m(self, loss, step_kwargs, zero_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Update parameters only if `self._inner_count` is divisible by\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# `self._accumulative_counts` or `self._inner_count` equals to\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# `self._max_counts`\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_update():\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_grad(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mzero_kwargs)\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/optim/scheduler/param_scheduler.py:115\u001b[0m, in \u001b[0;36m_ParamScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m instance\u001b[38;5;241m.\u001b[39m_global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    114\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MMdet/mmengine/mmengine/optim/optimizer/optimizer_wrapper.py:253\u001b[0m, in \u001b[0;36mOptimWrapper.step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_kwargs:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clip_grad()\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310mmdet2/lib/python3.10/site-packages/torch/optim/optimizer.py:504\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m             )\n\u001b[0;32m--> 504\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310mmdet2/lib/python3.10/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310mmdet2/lib/python3.10/site-packages/torch/optim/sgd.py:126\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    120\u001b[0m momentum_buffer_list: \u001b[38;5;28mlist\u001b[39m[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    122\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    123\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[1;32m    124\u001b[0m )\n\u001b[0;32m--> 126\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310mmdet2/lib/python3.10/site-packages/torch/optim/sgd.py:301\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 301\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py310mmdet2/lib/python3.10/site-packages/torch/optim/sgd.py:436\u001b[0m, in \u001b[0;36m_multi_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    433\u001b[0m         bufs\u001b[38;5;241m.\u001b[39mappend(cast(Tensor, device_momentum_buffer_list[i]))\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_states_with_momentum_buffer:\n\u001b[0;32m--> 436\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(bufs, device_grads, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dampening)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run tools/train.py configs/csra/resnet101-csra_1xb16_voc07-448px.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#after training, clear cache\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310mmdet2",
   "language": "python",
   "name": "py310mmdet2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "91213f4307e046fdbab284ec7dc0c2f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad0beff560a4668bbefd99abd302cbe": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_91213f4307e046fdbab284ec7dc0c2f1",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n</pre>\n",
         "text/plain": "Inference \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
