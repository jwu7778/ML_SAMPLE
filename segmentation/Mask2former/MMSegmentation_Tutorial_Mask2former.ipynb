{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVmnaxFJvsb8"
   },
   "source": [
    "# MMSegmentation Tutorial\n",
    "Welcome to MMSegmentation!\n",
    "\n",
    "In this tutorial, we demo\n",
    "* How to do inference with MMSeg trained weight\n",
    "* How to train on your own dataset and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmsegmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd mmsegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta51clKX4cwM"
   },
   "source": [
    "## Finetune a semantic segmentation model on a new dataset\n",
    "\n",
    "To finetune on a customized dataset, the following steps are necessary.\n",
    "1. Add a new dataset class.\n",
    "2. Create a config file accordingly.\n",
    "3. Perform training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from https://challenge.isic-archive.com/data/#2018 <br>\n",
    "We use task 1 training and validation dataset, so there will be 4 zips <br>\n",
    "Including : <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Training Data (10.4GB): https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Training Ground Truth (26MB): https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Validation Data (228MB): https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Validation_Input.zip <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Validation Ground Truth (742KB): https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Validation_GroundTruth.zip <br>\n",
    "The ground truth are in masks of black and white<br>\n",
    " <br>\n",
    "Reorder the dataset into below architecture, and place it under the folder 'mmsegmentation'  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ISIC/ \n",
    "├── images/ \n",
    "│   ├── training/ (rename from ISIC2018_Task1-2_Training_Input)\n",
    "│   │   ├── 1.jpg \n",
    "│   │   ├── 2.jpg \n",
    "│   │   └── ... \n",
    "│   └── validation/ (rename from ISIC2018_Task1-2_Validation_Input)\n",
    "│       └── ... \n",
    "└── annotations/ \n",
    "    ├── training/ (rename from ISIC2018_Task1_Training_GroundTruth)\n",
    "    │   ├── 1.png \n",
    "    │   ├── 2.png \n",
    "    │   └── ... \n",
    "    └── validation/ (rename from ISIC2018_Task1_Validation_GroundTruth)\n",
    "        └── ... \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ISIC_0000143_segmentation.png\n",
      "Processed ISIC_0001385_segmentation.png\n",
      "Processed ISIC_0012836_segmentation.png\n",
      "Processed ISIC_0012722_segmentation.png\n",
      "Processed ISIC_0012348_segmentation.png\n",
      "Processed ISIC_0013034_segmentation.png\n",
      "Processed ISIC_0014983_segmentation.png\n",
      "Processed ISIC_0008528_segmentation.png\n",
      "Processed ISIC_0015311_segmentation.png\n",
      "Processed ISIC_0012828_segmentation.png\n",
      "Processed ISIC_0013390_segmentation.png\n",
      "Processed ISIC_0001449_segmentation.png\n",
      "Processed ISIC_0014357_segmentation.png\n",
      "Processed ISIC_0014166_segmentation.png\n",
      "Processed ISIC_0000259_segmentation.png\n",
      "Processed ISIC_0014284_segmentation.png\n",
      "Processed ISIC_0012324_segmentation.png\n",
      "Processed ISIC_0012510_segmentation.png\n",
      "Processed ISIC_0012518_segmentation.png\n",
      "Processed ISIC_0000268_segmentation.png\n",
      "Processed ISIC_0015962_segmentation.png\n",
      "Processed ISIC_0012369_segmentation.png\n",
      "Processed ISIC_0000054_segmentation.png\n",
      "Processed ISIC_0009564_segmentation.png\n",
      "Processed ISIC_0014511_segmentation.png\n",
      "Processed ISIC_0009896_segmentation.png\n",
      "Processed ISIC_0015251_segmentation.png\n",
      "Processed ISIC_0013207_segmentation.png\n",
      "Processed ISIC_0011212_segmentation.png\n",
      "Processed ISIC_0013291_segmentation.png\n",
      "Processed ISIC_0000131_segmentation.png\n",
      "Processed ISIC_0001105_segmentation.png\n",
      "Processed ISIC_0013487_segmentation.png\n",
      "Processed ISIC_0015078_segmentation.png\n",
      "Processed ISIC_0000528_segmentation.png\n",
      "Processed ISIC_0014577_segmentation.png\n",
      "Processed ISIC_0000336_segmentation.png\n",
      "Processed ISIC_0010847_segmentation.png\n",
      "Processed ISIC_0002488_segmentation.png\n",
      "Processed ISIC_0010851_segmentation.png\n",
      "Processed ISIC_0016041_segmentation.png\n",
      "Processed ISIC_0000134_segmentation.png\n",
      "Processed ISIC_0012708_segmentation.png\n",
      "Processed ISIC_0014930_segmentation.png\n",
      "Processed ISIC_0014969_segmentation.png\n",
      "Processed ISIC_0000172_segmentation.png\n",
      "Processed ISIC_0010262_segmentation.png\n",
      "Processed ISIC_0011120_segmentation.png\n",
      "Processed ISIC_0014527_segmentation.png\n",
      "Processed ISIC_0013673_segmentation.png\n",
      "Processed ISIC_0013799_segmentation.png\n",
      "Processed ISIC_0000088_segmentation.png\n",
      "Processed ISIC_0010444_segmentation.png\n",
      "Processed ISIC_0012329_segmentation.png\n",
      "Processed ISIC_0015967_segmentation.png\n",
      "Processed ISIC_0000476_segmentation.png\n",
      "Processed ISIC_0012095_segmentation.png\n",
      "Processed ISIC_0014273_segmentation.png\n",
      "Processed ISIC_0009430_segmentation.png\n",
      "Processed ISIC_0009964_segmentation.png\n",
      "Processed ISIC_0000328_segmentation.png\n",
      "Processed ISIC_0000357_segmentation.png\n",
      "Processed ISIC_0001133_segmentation.png\n",
      "Processed ISIC_0015200_segmentation.png\n",
      "Processed ISIC_0014117_segmentation.png\n",
      "Processed ISIC_0014151_segmentation.png\n",
      "Processed ISIC_0000256_segmentation.png\n",
      "Processed ISIC_0013314_segmentation.png\n",
      "Processed ISIC_0006982_segmentation.png\n",
      "Processed ISIC_0000173_segmentation.png\n",
      "Processed ISIC_0010479_segmentation.png\n",
      "Processed ISIC_0013198_segmentation.png\n",
      "Processed ISIC_0013676_segmentation.png\n",
      "Processed ISIC_0010342_segmentation.png\n",
      "Processed ISIC_0001131_segmentation.png\n",
      "Processed ISIC_0010252_segmentation.png\n",
      "Processed ISIC_0015468_segmentation.png\n",
      "Processed ISIC_0016054_segmentation.png\n",
      "Processed ISIC_0015943_segmentation.png\n",
      "Processed ISIC_0013492_segmentation.png\n",
      "Processed ISIC_0000156_segmentation.png\n",
      "Processed ISIC_0015034_segmentation.png\n",
      "Processed ISIC_0012945_segmentation.png\n",
      "Processed ISIC_0012415_segmentation.png\n",
      "Processed ISIC_0012768_segmentation.png\n",
      "Processed ISIC_0000355_segmentation.png\n",
      "Processed ISIC_0015030_segmentation.png\n",
      "Processed ISIC_0016027_segmentation.png\n",
      "Processed ISIC_0011295_segmentation.png\n",
      "Processed ISIC_0014103_segmentation.png\n",
      "Processed ISIC_0010467_segmentation.png\n",
      "Processed ISIC_0016040_segmentation.png\n",
      "Processed ISIC_0013321_segmentation.png\n",
      "Processed ISIC_0009998_segmentation.png\n",
      "Processed ISIC_0011119_segmentation.png\n",
      "Processed ISIC_0009941_segmentation.png\n",
      "Processed ISIC_0000298_segmentation.png\n",
      "Processed ISIC_0015310_segmentation.png\n",
      "Processed ISIC_0010057_segmentation.png\n",
      "Processed ISIC_0013936_segmentation.png\n",
      "Processed ISIC_0016062_segmentation.png\n",
      "Processed ISIC_0013602_segmentation.png\n",
      "Processed ISIC_0015233_segmentation.png\n",
      "Processed ISIC_0012206_segmentation.png\n",
      "Processed ISIC_0014862_segmentation.png\n",
      "Processed ISIC_0014743_segmentation.png\n",
      "Processed ISIC_0015079_segmentation.png\n",
      "Processed ISIC_0015115_segmentation.png\n",
      "Processed ISIC_0012856_segmentation.png\n",
      "Processed ISIC_0006940_segmentation.png\n",
      "Processed ISIC_0015041_segmentation.png\n",
      "Processed ISIC_0010202_segmentation.png\n",
      "Processed ISIC_0015984_segmentation.png\n",
      "Processed ISIC_0014185_segmentation.png\n",
      "Processed ISIC_0015021_segmentation.png\n",
      "Processed ISIC_0014291_segmentation.png\n",
      "Processed ISIC_0013271_segmentation.png\n",
      "Processed ISIC_0007087_segmentation.png\n",
      "Processed ISIC_0015947_segmentation.png\n",
      "Processed ISIC_0000149_segmentation.png\n",
      "Processed ISIC_0012957_segmentation.png\n",
      "Processed ISIC_0010071_segmentation.png\n",
      "Processed ISIC_0000360_segmentation.png\n",
      "Processed ISIC_0013403_segmentation.png\n",
      "Processed ISIC_0014093_segmentation.png\n",
      "Processed ISIC_0013808_segmentation.png\n",
      "Processed ISIC_0011202_segmentation.png\n",
      "Processed ISIC_0009951_segmentation.png\n",
      "Processed ISIC_0010605_segmentation.png\n",
      "Processed ISIC_0011356_segmentation.png\n",
      "Processed ISIC_0000048_segmentation.png\n",
      "Processed ISIC_0000046_segmentation.png\n",
      "Processed ISIC_0012670_segmentation.png\n",
      "Processed ISIC_0010568_segmentation.png\n",
      "Processed ISIC_0000376_segmentation.png\n",
      "Processed ISIC_0014769_segmentation.png\n",
      "Processed ISIC_0010567_segmentation.png\n",
      "Processed ISIC_0000316_segmentation.png\n",
      "Processed ISIC_0013809_segmentation.png\n",
      "Processed ISIC_0011173_segmentation.png\n",
      "Processed ISIC_0009897_segmentation.png\n",
      "Processed ISIC_0012855_segmentation.png\n",
      "Processed ISIC_0000098_segmentation.png\n",
      "Processed ISIC_0003005_segmentation.png\n",
      "Processed ISIC_0015295_segmentation.png\n",
      "Processed ISIC_0010006_segmentation.png\n",
      "Processed ISIC_0013499_segmentation.png\n",
      "Processed ISIC_0014032_segmentation.png\n",
      "Processed ISIC_0012272_segmentation.png\n",
      "Processed ISIC_0012889_segmentation.png\n",
      "Processed ISIC_0012263_segmentation.png\n",
      "Processed ISIC_0013488_segmentation.png\n",
      "Processed ISIC_0014722_segmentation.png\n",
      "Processed ISIC_0012473_segmentation.png\n",
      "Processed ISIC_0009937_segmentation.png\n",
      "Processed ISIC_0000200_segmentation.png\n",
      "Processed ISIC_0000029_segmentation.png\n",
      "Processed ISIC_0004346_segmentation.png\n",
      "Processed ISIC_0015132_segmentation.png\n",
      "Processed ISIC_0009868_segmentation.png\n",
      "Processed ISIC_0000488_segmentation.png\n",
      "Processed ISIC_0006795_segmentation.png\n",
      "Processed ISIC_0000415_segmentation.png\n",
      "Processed ISIC_0010374_segmentation.png\n",
      "Processed ISIC_0014525_segmentation.png\n",
      "Processed ISIC_0016048_segmentation.png\n",
      "Processed ISIC_0010329_segmentation.png\n",
      "Processed ISIC_0014163_segmentation.png\n",
      "Processed ISIC_0010194_segmentation.png\n",
      "Processed ISIC_0015189_segmentation.png\n",
      "Processed ISIC_0010368_segmentation.png\n",
      "Processed ISIC_0011104_segmentation.png\n",
      "Processed ISIC_0010191_segmentation.png\n",
      "Processed ISIC_0014937_segmentation.png\n",
      "Processed ISIC_0014076_segmentation.png\n",
      "Processed ISIC_0011144_segmentation.png\n",
      "Processed ISIC_0013172_segmentation.png\n",
      "Processed ISIC_0009902_segmentation.png\n",
      "Processed ISIC_0000209_segmentation.png\n",
      "Processed ISIC_0013925_segmentation.png\n",
      "Processed ISIC_0013844_segmentation.png\n",
      "Processed ISIC_0000246_segmentation.png\n",
      "Processed ISIC_0001306_segmentation.png\n",
      "Processed ISIC_0014635_segmentation.png\n",
      "Processed ISIC_0014863_segmentation.png\n",
      "Processed ISIC_0013226_segmentation.png\n",
      "Processed ISIC_0000358_segmentation.png\n",
      "Processed ISIC_0010047_segmentation.png\n",
      "Processed ISIC_0014788_segmentation.png\n",
      "Processed ISIC_0000080_segmentation.png\n",
      "Processed ISIC_0000458_segmentation.png\n",
      "Processed ISIC_0013977_segmentation.png\n",
      "Processed ISIC_0013529_segmentation.png\n",
      "Processed ISIC_0012212_segmentation.png\n",
      "Processed ISIC_0013689_segmentation.png\n",
      "Processed ISIC_0012391_segmentation.png\n",
      "Processed ISIC_0000043_segmentation.png\n",
      "Processed ISIC_0012865_segmentation.png\n",
      "Processed ISIC_0013045_segmentation.png\n",
      "Processed ISIC_0000051_segmentation.png\n",
      "Processed ISIC_0012148_segmentation.png\n",
      "Processed ISIC_0013610_segmentation.png\n",
      "Processed ISIC_0013474_segmentation.png\n",
      "Processed ISIC_0000207_segmentation.png\n",
      "Processed ISIC_0013177_segmentation.png\n",
      "Processed ISIC_0014498_segmentation.png\n",
      "Processed ISIC_0009988_segmentation.png\n",
      "Processed ISIC_0000317_segmentation.png\n",
      "Processed ISIC_0013837_segmentation.png\n",
      "Processed ISIC_0012092_segmentation.png\n",
      "Processed ISIC_0006800_segmentation.png\n",
      "Processed ISIC_0013581_segmentation.png\n",
      "Processed ISIC_0012109_segmentation.png\n",
      "Processed ISIC_0010219_segmentation.png\n",
      "Processed ISIC_0015537_segmentation.png\n",
      "Processed ISIC_0016051_segmentation.png\n",
      "Processed ISIC_0013275_segmentation.png\n",
      "Processed ISIC_0002871_segmentation.png\n",
      "Processed ISIC_0001254_segmentation.png\n",
      "Processed ISIC_0010344_segmentation.png\n",
      "Processed ISIC_0000354_segmentation.png\n",
      "Processed ISIC_0010362_segmentation.png\n",
      "Processed ISIC_0012664_segmentation.png\n",
      "Processed ISIC_0010474_segmentation.png\n",
      "Processed ISIC_0015989_segmentation.png\n",
      "Processed ISIC_0011294_segmentation.png\n",
      "Processed ISIC_0015496_segmentation.png\n",
      "Processed ISIC_0014617_segmentation.png\n",
      "Processed ISIC_0013423_segmentation.png\n",
      "Processed ISIC_0015416_segmentation.png\n",
      "Processed ISIC_0013124_segmentation.png\n",
      "Processed ISIC_0001186_segmentation.png\n",
      "Processed ISIC_0013793_segmentation.png\n",
      "Processed ISIC_0015082_segmentation.png\n",
      "Processed ISIC_0000882_segmentation.png\n",
      "Processed ISIC_0012737_segmentation.png\n",
      "Processed ISIC_0014469_segmentation.png\n",
      "Processed ISIC_0001148_segmentation.png\n",
      "Processed ISIC_0012464_segmentation.png\n",
      "Processed ISIC_0011230_segmentation.png\n",
      "Processed ISIC_0010263_segmentation.png\n",
      "Processed ISIC_0010332_segmentation.png\n",
      "Processed ISIC_0015043_segmentation.png\n",
      "Processed ISIC_0010372_segmentation.png\n",
      "Processed ISIC_0009583_segmentation.png\n",
      "Processed ISIC_0010229_segmentation.png\n",
      "Processed ISIC_0000385_segmentation.png\n",
      "Processed ISIC_0000453_segmentation.png\n",
      "Processed ISIC_0000416_segmentation.png\n",
      "Processed ISIC_0014749_segmentation.png\n",
      "Processed ISIC_0015395_segmentation.png\n",
      "Processed ISIC_0013637_segmentation.png\n",
      "Processed ISIC_0014742_segmentation.png\n",
      "Processed ISIC_0013126_segmentation.png\n",
      "Processed ISIC_0000068_segmentation.png\n",
      "Processed ISIC_0013082_segmentation.png\n",
      "Processed ISIC_0016064_segmentation.png\n",
      "Processed ISIC_0015220_segmentation.png\n",
      "Processed ISIC_0015020_segmentation.png\n",
      "Processed ISIC_0013794_segmentation.png\n",
      "Processed ISIC_0014599_segmentation.png\n",
      "Processed ISIC_0009976_segmentation.png\n",
      "Processed ISIC_0002476_segmentation.png\n",
      "Processed ISIC_0000113_segmentation.png\n",
      "Processed ISIC_0009956_segmentation.png\n",
      "Processed ISIC_0011214_segmentation.png\n",
      "Processed ISIC_0013304_segmentation.png\n",
      "Processed ISIC_0011229_segmentation.png\n",
      "Processed ISIC_0014554_segmentation.png\n",
      "Processed ISIC_0010100_segmentation.png\n",
      "Processed ISIC_0015990_segmentation.png\n",
      "Processed ISIC_0010364_segmentation.png\n",
      "Processed ISIC_0012445_segmentation.png\n",
      "Processed ISIC_0010173_segmentation.png\n",
      "Processed ISIC_0015417_segmentation.png\n",
      "Processed ISIC_0000003_segmentation.png\n",
      "Processed ISIC_0014502_segmentation.png\n",
      "Processed ISIC_0011324_segmentation.png\n",
      "Processed ISIC_0014804_segmentation.png\n",
      "Processed ISIC_0011402_segmentation.png\n",
      "Processed ISIC_0012902_segmentation.png\n",
      "Processed ISIC_0013644_segmentation.png\n",
      "Processed ISIC_0011328_segmentation.png\n",
      "Processed ISIC_0012538_segmentation.png\n",
      "Processed ISIC_0001134_segmentation.png\n",
      "Processed ISIC_0013588_segmentation.png\n",
      "Processed ISIC_0011151_segmentation.png\n",
      "Processed ISIC_0012789_segmentation.png\n",
      "Processed ISIC_0000499_segmentation.png\n",
      "Processed ISIC_0001423_segmentation.png\n",
      "Processed ISIC_0013680_segmentation.png\n",
      "Processed ISIC_0015383_segmentation.png\n",
      "Processed ISIC_0014944_segmentation.png\n",
      "Processed ISIC_0010037_segmentation.png\n",
      "Processed ISIC_0012837_segmentation.png\n",
      "Processed ISIC_0010607_segmentation.png\n",
      "Processed ISIC_0014440_segmentation.png\n",
      "Processed ISIC_0010597_segmentation.png\n",
      "Processed ISIC_0012932_segmentation.png\n",
      "Processed ISIC_0014932_segmentation.png\n",
      "Processed ISIC_0013671_segmentation.png\n",
      "Processed ISIC_0013075_segmentation.png\n",
      "Processed ISIC_0015013_segmentation.png\n",
      "Processed ISIC_0010226_segmentation.png\n",
      "Processed ISIC_0012493_segmentation.png\n",
      "Processed ISIC_0016022_segmentation.png\n",
      "Processed ISIC_0012453_segmentation.png\n",
      "Processed ISIC_0013369_segmentation.png\n",
      "Processed ISIC_0015985_segmentation.png\n",
      "Processed ISIC_0013167_segmentation.png\n",
      "Processed ISIC_0013326_segmentation.png\n",
      "Processed ISIC_0014547_segmentation.png\n",
      "Processed ISIC_0015175_segmentation.png\n",
      "Processed ISIC_0011150_segmentation.png\n",
      "Processed ISIC_0010019_segmentation.png\n",
      "Processed ISIC_0014938_segmentation.png\n",
      "Processed ISIC_0014288_segmentation.png\n",
      "Processed ISIC_0013191_segmentation.png\n",
      "Processed ISIC_0011207_segmentation.png\n",
      "Processed ISIC_0013634_segmentation.png\n",
      "Processed ISIC_0016053_segmentation.png\n",
      "Processed ISIC_0012823_segmentation.png\n",
      "Processed ISIC_0000372_segmentation.png\n",
      "Processed ISIC_0000384_segmentation.png\n",
      "Processed ISIC_0000281_segmentation.png\n",
      "Processed ISIC_0000219_segmentation.png\n",
      "Processed ISIC_0000423_segmentation.png\n",
      "Processed ISIC_0001427_segmentation.png\n",
      "Processed ISIC_0015144_segmentation.png\n",
      "Processed ISIC_0013719_segmentation.png\n",
      "Processed ISIC_0006671_segmentation.png\n",
      "Processed ISIC_0010251_segmentation.png\n",
      "Processed ISIC_0005000_segmentation.png\n",
      "Processed ISIC_0011383_segmentation.png\n",
      "Processed ISIC_0012290_segmentation.png\n",
      "Processed ISIC_0014855_segmentation.png\n",
      "Processed ISIC_0011352_segmentation.png\n",
      "Processed ISIC_0010020_segmentation.png\n",
      "Processed ISIC_0013106_segmentation.png\n",
      "Processed ISIC_0000498_segmentation.png\n",
      "Processed ISIC_0005620_segmentation.png\n",
      "Processed ISIC_0014982_segmentation.png\n",
      "Processed ISIC_0014132_segmentation.png\n",
      "Processed ISIC_0010462_segmentation.png\n",
      "Processed ISIC_0000351_segmentation.png\n",
      "Processed ISIC_0009942_segmentation.png\n",
      "Processed ISIC_0015002_segmentation.png\n",
      "Processed ISIC_0008280_segmentation.png\n",
      "Processed ISIC_0011348_segmentation.png\n",
      "Processed ISIC_0014675_segmentation.png\n",
      "Processed ISIC_0000433_segmentation.png\n",
      "Processed ISIC_0000490_segmentation.png\n",
      "Processed ISIC_0000412_segmentation.png\n",
      "Processed ISIC_0009344_segmentation.png\n",
      "Processed ISIC_0009910_segmentation.png\n",
      "Processed ISIC_0014211_segmentation.png\n",
      "Processed ISIC_0016059_segmentation.png\n",
      "Processed ISIC_0000388_segmentation.png\n",
      "Processed ISIC_0013089_segmentation.png\n",
      "Processed ISIC_0014697_segmentation.png\n",
      "Processed ISIC_0014657_segmentation.png\n",
      "Processed ISIC_0014263_segmentation.png\n",
      "Processed ISIC_0011338_segmentation.png\n",
      "Processed ISIC_0010090_segmentation.png\n",
      "Processed ISIC_0012273_segmentation.png\n",
      "Processed ISIC_0014992_segmentation.png\n",
      "Processed ISIC_0000109_segmentation.png\n",
      "Processed ISIC_0012261_segmentation.png\n",
      "Processed ISIC_0010321_segmentation.png\n",
      "Processed ISIC_0010059_segmentation.png\n",
      "Processed ISIC_0000165_segmentation.png\n",
      "Processed ISIC_0000290_segmentation.png\n",
      "Processed ISIC_0000436_segmentation.png\n",
      "Processed ISIC_0008524_segmentation.png\n",
      "Processed ISIC_0014921_segmentation.png\n",
      "Processed ISIC_0014624_segmentation.png\n",
      "Processed ISIC_0010060_segmentation.png\n",
      "Processed ISIC_0010215_segmentation.png\n",
      "Processed ISIC_0014619_segmentation.png\n",
      "Processed ISIC_0014090_segmentation.png\n",
      "Processed ISIC_0013996_segmentation.png\n",
      "Processed ISIC_0012746_segmentation.png\n",
      "Processed ISIC_0000008_segmentation.png\n",
      "Processed ISIC_0011353_segmentation.png\n",
      "Processed ISIC_0013792_segmentation.png\n",
      "Processed ISIC_0000377_segmentation.png\n",
      "Processed ISIC_0014768_segmentation.png\n",
      "Processed ISIC_0001852_segmentation.png\n",
      "Processed ISIC_0014682_segmentation.png\n",
      "Processed ISIC_0015627_segmentation.png\n",
      "Processed ISIC_0010319_segmentation.png\n",
      "Processed ISIC_0010382_segmentation.png\n",
      "Processed ISIC_0010346_segmentation.png\n",
      "Processed ISIC_0013962_segmentation.png\n",
      "Processed ISIC_0012182_segmentation.png\n",
      "Processed ISIC_0000262_segmentation.png\n",
      "Processed ISIC_0000045_segmentation.png\n",
      "Processed ISIC_0009860_segmentation.png\n",
      "Processed ISIC_0011330_segmentation.png\n",
      "Processed ISIC_0012160_segmentation.png\n",
      "Processed ISIC_0015102_segmentation.png\n",
      "Processed ISIC_0000409_segmentation.png\n",
      "Processed ISIC_0000431_segmentation.png\n",
      "Processed ISIC_0008626_segmentation.png\n",
      "Processed ISIC_0013921_segmentation.png\n",
      "Processed ISIC_0011132_segmentation.png\n",
      "Processed ISIC_0012903_segmentation.png\n",
      "Processed ISIC_0010249_segmentation.png\n",
      "Processed ISIC_0010360_segmentation.png\n",
      "Processed ISIC_0000030_segmentation.png\n",
      "Processed ISIC_0014963_segmentation.png\n",
      "Processed ISIC_0009967_segmentation.png\n",
      "Processed ISIC_0013690_segmentation.png\n",
      "Processed ISIC_0010238_segmentation.png\n",
      "Processed ISIC_0013434_segmentation.png\n",
      "Processed ISIC_0008659_segmentation.png\n",
      "Processed ISIC_0014395_segmentation.png\n",
      "Processed ISIC_0009931_segmentation.png\n",
      "Processed ISIC_0012136_segmentation.png\n",
      "Processed ISIC_0000539_segmentation.png\n",
      "Processed ISIC_0000252_segmentation.png\n",
      "Processed ISIC_0013525_segmentation.png\n",
      "Processed ISIC_0013118_segmentation.png\n",
      "Processed ISIC_0012099_segmentation.png\n",
      "Processed ISIC_0003559_segmentation.png\n",
      "Processed ISIC_0013562_segmentation.png\n",
      "Processed ISIC_0015167_segmentation.png\n",
      "Processed ISIC_0010458_segmentation.png\n",
      "Processed ISIC_0009982_segmentation.png\n",
      "Processed ISIC_0001299_segmentation.png\n",
      "Processed ISIC_0013223_segmentation.png\n",
      "Processed ISIC_0013164_segmentation.png\n",
      "Processed ISIC_0000186_segmentation.png\n",
      "Processed ISIC_0012201_segmentation.png\n",
      "Processed ISIC_0007788_segmentation.png\n",
      "Processed ISIC_0013512_segmentation.png\n",
      "Processed ISIC_0001242_segmentation.png\n",
      "Processed ISIC_0015158_segmentation.png\n",
      "Processed ISIC_0000205_segmentation.png\n",
      "Processed ISIC_0010055_segmentation.png\n",
      "Processed ISIC_0014325_segmentation.png\n",
      "Processed ISIC_0010860_segmentation.png\n",
      "Processed ISIC_0000244_segmentation.png\n",
      "Processed ISIC_0010863_segmentation.png\n",
      "Processed ISIC_0013621_segmentation.png\n",
      "Processed ISIC_0012089_segmentation.png\n",
      "Processed ISIC_0002879_segmentation.png\n",
      "Processed ISIC_0009977_segmentation.png\n",
      "Processed ISIC_0014952_segmentation.png\n",
      "Processed ISIC_0009904_segmentation.png\n",
      "Processed ISIC_0010178_segmentation.png\n",
      "Processed ISIC_0010853_segmentation.png\n",
      "Processed ISIC_0014573_segmentation.png\n",
      "Processed ISIC_0012725_segmentation.png\n",
      "Processed ISIC_0010190_segmentation.png\n",
      "Processed ISIC_0014652_segmentation.png\n",
      "Processed ISIC_0014476_segmentation.png\n",
      "Processed ISIC_0011306_segmentation.png\n",
      "Processed ISIC_0011171_segmentation.png\n",
      "Processed ISIC_0000391_segmentation.png\n",
      "Processed ISIC_0016005_segmentation.png\n",
      "Processed ISIC_0013840_segmentation.png\n",
      "Processed ISIC_0010481_segmentation.png\n",
      "Processed ISIC_0013053_segmentation.png\n",
      "Processed ISIC_0013975_segmentation.png\n",
      "Processed ISIC_0015445_segmentation.png\n",
      "Processed ISIC_0012191_segmentation.png\n",
      "Processed ISIC_0000061_segmentation.png\n",
      "Processed ISIC_0000504_segmentation.png\n",
      "Processed ISIC_0014920_segmentation.png\n",
      "Processed ISIC_0012450_segmentation.png\n",
      "Processed ISIC_0013617_segmentation.png\n",
      "Processed ISIC_0011095_segmentation.png\n",
      "Processed ISIC_0012268_segmentation.png\n",
      "Processed ISIC_0014526_segmentation.png\n",
      "Processed ISIC_0000390_segmentation.png\n",
      "Processed ISIC_0014843_segmentation.png\n",
      "Processed ISIC_0015118_segmentation.png\n",
      "Processed ISIC_0013777_segmentation.png\n",
      "Processed ISIC_0000370_segmentation.png\n",
      "Processed ISIC_0014346_segmentation.png\n",
      "Processed ISIC_0012521_segmentation.png\n",
      "Processed ISIC_0015952_segmentation.png\n",
      "Processed ISIC_0000037_segmentation.png\n",
      "Processed ISIC_0014987_segmentation.png\n",
      "Processed ISIC_0009966_segmentation.png\n",
      "Processed ISIC_0014962_segmentation.png\n",
      "Processed ISIC_0010257_segmentation.png\n",
      "Processed ISIC_0013430_segmentation.png\n",
      "Processed ISIC_0009879_segmentation.png\n",
      "Processed ISIC_0009973_segmentation.png\n",
      "Processed ISIC_0010356_segmentation.png\n",
      "Processed ISIC_0001140_segmentation.png\n",
      "Processed ISIC_0000277_segmentation.png\n",
      "Processed ISIC_0014726_segmentation.png\n",
      "Processed ISIC_0012806_segmentation.png\n",
      "Processed ISIC_0010032_segmentation.png\n",
      "Processed ISIC_0014923_segmentation.png\n",
      "Processed ISIC_0000527_segmentation.png\n",
      "Processed ISIC_0012379_segmentation.png\n",
      "Processed ISIC_0000420_segmentation.png\n",
      "Processed ISIC_0013410_segmentation.png\n",
      "Processed ISIC_0013025_segmentation.png\n",
      "Processed ISIC_0014890_segmentation.png\n",
      "Processed ISIC_0013886_segmentation.png\n",
      "Processed ISIC_0013258_segmentation.png\n",
      "Processed ISIC_0014933_segmentation.png\n",
      "Processed ISIC_0014423_segmentation.png\n",
      "Processed ISIC_0010017_segmentation.png\n",
      "Processed ISIC_0000073_segmentation.png\n",
      "Processed ISIC_0013063_segmentation.png\n",
      "Processed ISIC_0010574_segmentation.png\n",
      "Processed ISIC_0015260_segmentation.png\n",
      "Processed ISIC_0009995_segmentation.png\n",
      "Processed ISIC_0010002_segmentation.png\n",
      "Processed ISIC_0000530_segmentation.png\n",
      "Processed ISIC_0000052_segmentation.png\n",
      "Processed ISIC_0010025_segmentation.png\n",
      "Processed ISIC_0014110_segmentation.png\n",
      "Processed ISIC_0000323_segmentation.png\n",
      "Processed ISIC_0015625_segmentation.png\n",
      "Processed ISIC_0013663_segmentation.png\n",
      "Processed ISIC_0013459_segmentation.png\n",
      "Processed ISIC_0012205_segmentation.png\n",
      "Processed ISIC_0012814_segmentation.png\n",
      "Processed ISIC_0015018_segmentation.png\n",
      "Processed ISIC_0012989_segmentation.png\n",
      "Processed ISIC_0014081_segmentation.png\n",
      "Processed ISIC_0013087_segmentation.png\n",
      "Processed ISIC_0015140_segmentation.png\n",
      "Processed ISIC_0012702_segmentation.png\n",
      "Processed ISIC_0013500_segmentation.png\n",
      "Processed ISIC_0000135_segmentation.png\n",
      "Processed ISIC_0012372_segmentation.png\n",
      "Processed ISIC_0010435_segmentation.png\n",
      "Processed ISIC_0000546_segmentation.png\n",
      "Processed ISIC_0000556_segmentation.png\n",
      "Processed ISIC_0013054_segmentation.png\n",
      "Processed ISIC_0000393_segmentation.png\n",
      "Processed ISIC_0000229_segmentation.png\n",
      "Processed ISIC_0013334_segmentation.png\n",
      "Processed ISIC_0012320_segmentation.png\n",
      "Processed ISIC_0010370_segmentation.png\n",
      "Processed ISIC_0012257_segmentation.png\n",
      "Processed ISIC_0011143_segmentation.png\n",
      "Processed ISIC_0013465_segmentation.png\n",
      "Processed ISIC_0012897_segmentation.png\n",
      "Processed ISIC_0000235_segmentation.png\n",
      "Processed ISIC_0000081_segmentation.png\n",
      "Processed ISIC_0010265_segmentation.png\n",
      "Processed ISIC_0013573_segmentation.png\n",
      "Processed ISIC_0013969_segmentation.png\n",
      "Processed ISIC_0000292_segmentation.png\n",
      "Processed ISIC_0000274_segmentation.png\n",
      "Processed ISIC_0013306_segmentation.png\n",
      "Processed ISIC_0013998_segmentation.png\n",
      "Processed ISIC_0013359_segmentation.png\n",
      "Processed ISIC_0013364_segmentation.png\n",
      "Processed ISIC_0009252_segmentation.png\n",
      "Processed ISIC_0013775_segmentation.png\n",
      "Processed ISIC_0011345_segmentation.png\n",
      "Processed ISIC_0014771_segmentation.png\n",
      "Processed ISIC_0014458_segmentation.png\n",
      "Processed ISIC_0000250_segmentation.png\n",
      "Processed ISIC_0009929_segmentation.png\n",
      "Processed ISIC_0013498_segmentation.png\n",
      "Processed ISIC_0013516_segmentation.png\n",
      "Processed ISIC_0010457_segmentation.png\n",
      "Processed ISIC_0014430_segmentation.png\n",
      "Processed ISIC_0014784_segmentation.png\n",
      "Processed ISIC_0011158_segmentation.png\n",
      "Processed ISIC_0013000_segmentation.png\n",
      "Processed ISIC_0010062_segmentation.png\n",
      "Processed ISIC_0009035_segmentation.png\n",
      "Processed ISIC_0013340_segmentation.png\n",
      "Processed ISIC_0000218_segmentation.png\n",
      "Processed ISIC_0015978_segmentation.png\n",
      "Processed ISIC_0012224_segmentation.png\n",
      "Processed ISIC_0000215_segmentation.png\n",
      "Processed ISIC_0000523_segmentation.png\n",
      "Processed ISIC_0009874_segmentation.png\n",
      "Processed ISIC_0015180_segmentation.png\n",
      "Processed ISIC_0011357_segmentation.png\n",
      "Processed ISIC_0010192_segmentation.png\n",
      "Processed ISIC_0011223_segmentation.png\n",
      "Processed ISIC_0012740_segmentation.png\n",
      "Processed ISIC_0014642_segmentation.png\n",
      "Processed ISIC_0011386_segmentation.png\n",
      "Processed ISIC_0011341_segmentation.png\n",
      "Processed ISIC_0013346_segmentation.png\n",
      "Processed ISIC_0012221_segmentation.png\n",
      "Processed ISIC_0013385_segmentation.png\n",
      "Processed ISIC_0005247_segmentation.png\n",
      "Processed ISIC_0000001_segmentation.png\n",
      "Processed ISIC_0000224_segmentation.png\n",
      "Processed ISIC_0000062_segmentation.png\n",
      "Processed ISIC_0014651_segmentation.png\n",
      "Processed ISIC_0015363_segmentation.png\n",
      "Processed ISIC_0007241_segmentation.png\n",
      "Processed ISIC_0010093_segmentation.png\n",
      "Processed ISIC_0014454_segmentation.png\n",
      "Processed ISIC_0010593_segmentation.png\n",
      "Processed ISIC_0014222_segmentation.png\n",
      "Processed ISIC_0013365_segmentation.png\n",
      "Processed ISIC_0012883_segmentation.png\n",
      "Processed ISIC_0015638_segmentation.png\n",
      "Processed ISIC_0007693_segmentation.png\n",
      "Processed ISIC_0015955_segmentation.png\n",
      "Processed ISIC_0000548_segmentation.png\n",
      "Processed ISIC_0001102_segmentation.png\n",
      "Processed ISIC_0015064_segmentation.png\n",
      "Processed ISIC_0014745_segmentation.png\n",
      "Processed ISIC_0012494_segmentation.png\n",
      "Processed ISIC_0013953_segmentation.png\n",
      "Processed ISIC_0014791_segmentation.png\n",
      "Processed ISIC_0010573_segmentation.png\n",
      "Processed ISIC_0000245_segmentation.png\n",
      "Processed ISIC_0000481_segmentation.png\n",
      "Processed ISIC_0015224_segmentation.png\n",
      "Processed ISIC_0009979_segmentation.png\n",
      "Processed ISIC_0013416_segmentation.png\n",
      "Processed ISIC_0002438_segmentation.png\n",
      "Processed ISIC_0015996_segmentation.png\n",
      "Processed ISIC_0001188_segmentation.png\n",
      "Processed ISIC_0012699_segmentation.png\n",
      "Processed ISIC_0009885_segmentation.png\n",
      "Processed ISIC_0010094_segmentation.png\n",
      "Processed ISIC_0013141_segmentation.png\n",
      "Processed ISIC_0012179_segmentation.png\n",
      "Processed ISIC_0000505_segmentation.png\n",
      "Processed ISIC_0010074_segmentation.png\n",
      "Processed ISIC_0000439_segmentation.png\n",
      "Processed ISIC_0000552_segmentation.png\n",
      "Processed ISIC_0009943_segmentation.png\n",
      "Processed ISIC_0010240_segmentation.png\n",
      "Processed ISIC_0013319_segmentation.png\n",
      "Processed ISIC_0009800_segmentation.png\n",
      "Processed ISIC_0001128_segmentation.png\n",
      "Processed ISIC_0016015_segmentation.png\n",
      "Processed ISIC_0000332_segmentation.png\n",
      "Processed ISIC_0013958_segmentation.png\n",
      "Processed ISIC_0015011_segmentation.png\n",
      "Processed ISIC_0000217_segmentation.png\n",
      "Processed ISIC_0016016_segmentation.png\n",
      "Processed ISIC_0013457_segmentation.png\n",
      "Processed ISIC_0000105_segmentation.png\n",
      "Processed ISIC_0000226_segmentation.png\n",
      "Processed ISIC_0016033_segmentation.png\n",
      "Processed ISIC_0014823_segmentation.png\n",
      "Processed ISIC_0000283_segmentation.png\n",
      "Processed ISIC_0015226_segmentation.png\n",
      "Processed ISIC_0014567_segmentation.png\n",
      "Processed ISIC_0012680_segmentation.png\n",
      "Processed ISIC_0015982_segmentation.png\n",
      "Processed ISIC_0013802_segmentation.png\n",
      "Processed ISIC_0015418_segmentation.png\n",
      "Processed ISIC_0012549_segmentation.png\n",
      "Processed ISIC_0016011_segmentation.png\n",
      "Processed ISIC_0000125_segmentation.png\n",
      "Processed ISIC_0014625_segmentation.png\n",
      "Processed ISIC_0010480_segmentation.png\n",
      "Processed ISIC_0014913_segmentation.png\n",
      "Processed ISIC_0000294_segmentation.png\n",
      "Processed ISIC_0000482_segmentation.png\n",
      "Processed ISIC_0012758_segmentation.png\n",
      "Processed ISIC_0000116_segmentation.png\n",
      "Processed ISIC_0012840_segmentation.png\n",
      "Processed ISIC_0011327_segmentation.png\n",
      "Processed ISIC_0009884_segmentation.png\n",
      "Processed ISIC_0010005_segmentation.png\n",
      "Processed ISIC_0010016_segmentation.png\n",
      "Processed ISIC_0000263_segmentation.png\n",
      "Processed ISIC_0001367_segmentation.png\n",
      "Processed ISIC_0012382_segmentation.png\n",
      "Processed ISIC_0000407_segmentation.png\n",
      "Processed ISIC_0000155_segmentation.png\n",
      "Processed ISIC_0012508_segmentation.png\n",
      "Processed ISIC_0014195_segmentation.png\n",
      "Processed ISIC_0014069_segmentation.png\n",
      "Processed ISIC_0015510_segmentation.png\n",
      "Processed ISIC_0011297_segmentation.png\n",
      "Processed ISIC_0014583_segmentation.png\n",
      "Processed ISIC_0013176_segmentation.png\n",
      "Processed ISIC_0014848_segmentation.png\n",
      "Processed ISIC_0013233_segmentation.png\n",
      "Processed ISIC_0010595_segmentation.png\n",
      "Processed ISIC_0013523_segmentation.png\n",
      "Processed ISIC_0010367_segmentation.png\n",
      "Processed ISIC_0014046_segmentation.png\n",
      "Processed ISIC_0012550_segmentation.png\n",
      "Processed ISIC_0015419_segmentation.png\n",
      "Processed ISIC_0010092_segmentation.png\n",
      "Processed ISIC_0000227_segmentation.png\n",
      "Processed ISIC_0014336_segmentation.png\n",
      "Processed ISIC_0015961_segmentation.png\n",
      "Processed ISIC_0010222_segmentation.png\n",
      "Processed ISIC_0015212_segmentation.png\n",
      "Processed ISIC_0015476_segmentation.png\n",
      "Processed ISIC_0000456_segmentation.png\n",
      "Processed ISIC_0000485_segmentation.png\n",
      "Processed ISIC_0015232_segmentation.png\n",
      "Processed ISIC_0012523_segmentation.png\n",
      "Processed ISIC_0000136_segmentation.png\n",
      "Processed ISIC_0015331_segmentation.png\n",
      "Processed ISIC_0000251_segmentation.png\n",
      "Processed ISIC_0000348_segmentation.png\n",
      "Processed ISIC_0000382_segmentation.png\n",
      "Processed ISIC_0009940_segmentation.png\n",
      "Processed ISIC_0015133_segmentation.png\n",
      "Processed ISIC_0011146_segmentation.png\n",
      "Processed ISIC_0010014_segmentation.png\n",
      "Processed ISIC_0007156_segmentation.png\n",
      "Processed ISIC_0013084_segmentation.png\n",
      "Processed ISIC_0015330_segmentation.png\n",
      "Processed ISIC_0010476_segmentation.png\n",
      "Processed ISIC_0013147_segmentation.png\n",
      "Processed ISIC_0011092_segmentation.png\n",
      "Processed ISIC_0012529_segmentation.png\n",
      "Processed ISIC_0010036_segmentation.png\n",
      "Processed ISIC_0010104_segmentation.png\n",
      "Processed ISIC_0014360_segmentation.png\n",
      "Processed ISIC_0014770_segmentation.png\n",
      "Processed ISIC_0000461_segmentation.png\n",
      "Processed ISIC_0000243_segmentation.png\n",
      "Processed ISIC_0013432_segmentation.png\n",
      "Processed ISIC_0010365_segmentation.png\n",
      "Processed ISIC_0008403_segmentation.png\n",
      "Processed ISIC_0010256_segmentation.png\n",
      "Processed ISIC_0013169_segmentation.png\n",
      "Processed ISIC_0008294_segmentation.png\n",
      "Processed ISIC_0000320_segmentation.png\n",
      "Processed ISIC_0012187_segmentation.png\n",
      "Processed ISIC_0013748_segmentation.png\n",
      "Processed ISIC_0013749_segmentation.png\n",
      "Processed ISIC_0002287_segmentation.png\n",
      "Processed ISIC_0011296_segmentation.png\n",
      "Processed ISIC_0012489_segmentation.png\n",
      "Processed ISIC_0013086_segmentation.png\n",
      "Processed ISIC_0014966_segmentation.png\n",
      "Processed ISIC_0014347_segmentation.png\n",
      "Processed ISIC_0015645_segmentation.png\n",
      "Processed ISIC_0015007_segmentation.png\n",
      "Processed ISIC_0010461_segmentation.png\n",
      "Processed ISIC_0014714_segmentation.png\n",
      "Processed ISIC_0000017_segmentation.png\n",
      "Processed ISIC_0000365_segmentation.png\n",
      "Processed ISIC_0012697_segmentation.png\n",
      "Processed ISIC_0009938_segmentation.png\n",
      "Processed ISIC_0012137_segmentation.png\n",
      "Processed ISIC_0012313_segmentation.png\n",
      "Processed ISIC_0011336_segmentation.png\n",
      "Processed ISIC_0012097_segmentation.png\n",
      "Processed ISIC_0012159_segmentation.png\n",
      "Processed ISIC_0014385_segmentation.png\n",
      "Processed ISIC_0000077_segmentation.png\n",
      "Processed ISIC_0009971_segmentation.png\n",
      "Processed ISIC_0012314_segmentation.png\n",
      "Processed ISIC_0015026_segmentation.png\n",
      "Processed ISIC_0015482_segmentation.png\n",
      "Processed ISIC_0012930_segmentation.png\n",
      "Processed ISIC_0011149_segmentation.png\n",
      "Processed ISIC_0000191_segmentation.png\n",
      "Processed ISIC_0012988_segmentation.png\n",
      "Processed ISIC_0010081_segmentation.png\n",
      "Processed ISIC_0013394_segmentation.png\n",
      "Processed ISIC_0001374_segmentation.png\n",
      "Processed ISIC_0012852_segmentation.png\n",
      "Processed ISIC_0008541_segmentation.png\n",
      "Processed ISIC_0015455_segmentation.png\n",
      "Processed ISIC_0012173_segmentation.png\n",
      "Processed ISIC_0013355_segmentation.png\n",
      "Processed ISIC_0010011_segmentation.png\n",
      "Processed ISIC_0010041_segmentation.png\n",
      "Processed ISIC_0010185_segmentation.png\n",
      "Processed ISIC_0012659_segmentation.png\n",
      "Processed ISIC_0014136_segmentation.png\n",
      "Processed ISIC_0011079_segmentation.png\n",
      "Processed ISIC_0000169_segmentation.png\n",
      "Processed ISIC_0013204_segmentation.png\n",
      "Processed ISIC_0010341_segmentation.png\n",
      "Processed ISIC_0011227_segmentation.png\n",
      "Processed ISIC_0013374_segmentation.png\n",
      "Processed ISIC_0015057_segmentation.png\n",
      "Processed ISIC_0015152_segmentation.png\n",
      "Processed ISIC_0014762_segmentation.png\n",
      "Processed ISIC_0012701_segmentation.png\n",
      "Processed ISIC_0014807_segmentation.png\n",
      "Processed ISIC_0014393_segmentation.png\n",
      "Processed ISIC_0000214_segmentation.png\n",
      "Processed ISIC_0014229_segmentation.png\n",
      "Processed ISIC_0000232_segmentation.png\n",
      "Processed ISIC_0013961_segmentation.png\n",
      "Processed ISIC_0000470_segmentation.png\n",
      "Processed ISIC_0015015_segmentation.png\n",
      "Processed ISIC_0009895_segmentation.png\n",
      "Processed ISIC_0014366_segmentation.png\n",
      "Processed ISIC_0014839_segmentation.png\n",
      "Processed ISIC_0011228_segmentation.png\n",
      "Processed ISIC_0010472_segmentation.png\n",
      "Processed ISIC_0013739_segmentation.png\n",
      "Processed ISIC_0009504_segmentation.png\n",
      "Processed ISIC_0013037_segmentation.png\n",
      "Processed ISIC_0000509_segmentation.png\n",
      "Processed ISIC_0012178_segmentation.png\n",
      "Processed ISIC_0013553_segmentation.png\n",
      "Processed ISIC_0000177_segmentation.png\n",
      "Processed ISIC_0015966_segmentation.png\n",
      "Processed ISIC_0000000_segmentation.png\n",
      "Processed ISIC_0012905_segmentation.png\n",
      "Processed ISIC_0011218_segmentation.png\n",
      "Processed ISIC_0010067_segmentation.png\n",
      "Processed ISIC_0008807_segmentation.png\n",
      "Processed ISIC_0002829_segmentation.png\n",
      "Processed ISIC_0014951_segmentation.png\n",
      "Processed ISIC_0010241_segmentation.png\n",
      "Processed ISIC_0010602_segmentation.png\n",
      "Processed ISIC_0014663_segmentation.png\n",
      "Processed ISIC_0013159_segmentation.png\n",
      "Processed ISIC_0013595_segmentation.png\n",
      "Processed ISIC_0014783_segmentation.png\n",
      "Processed ISIC_0000345_segmentation.png\n",
      "Processed ISIC_0013807_segmentation.png\n",
      "Processed ISIC_0013200_segmentation.png\n",
      "Processed ISIC_0011169_segmentation.png\n",
      "Processed ISIC_0000288_segmentation.png\n",
      "Processed ISIC_0000297_segmentation.png\n",
      "Processed ISIC_0014735_segmentation.png\n",
      "Processed ISIC_0014353_segmentation.png\n",
      "Processed ISIC_0009981_segmentation.png\n",
      "Processed ISIC_0012108_segmentation.png\n",
      "Processed ISIC_0013458_segmentation.png\n",
      "Processed ISIC_0014028_segmentation.png\n",
      "Processed ISIC_0014780_segmentation.png\n",
      "Processed ISIC_0014703_segmentation.png\n",
      "Processed ISIC_0009083_segmentation.png\n",
      "Processed ISIC_0014164_segmentation.png\n",
      "Processed ISIC_0004715_segmentation.png\n",
      "Processed ISIC_0010003_segmentation.png\n",
      "Processed ISIC_0013437_segmentation.png\n",
      "Processed ISIC_0009936_segmentation.png\n",
      "Processed ISIC_0014907_segmentation.png\n",
      "Processed ISIC_0011203_segmentation.png\n",
      "Processed ISIC_0014787_segmentation.png\n",
      "Processed ISIC_0013981_segmentation.png\n",
      "Processed ISIC_0000541_segmentation.png\n",
      "Processed ISIC_0013594_segmentation.png\n",
      "Processed ISIC_0000034_segmentation.png\n",
      "Processed ISIC_0011105_segmentation.png\n",
      "Processed ISIC_0011347_segmentation.png\n",
      "Processed ISIC_0010207_segmentation.png\n",
      "Processed ISIC_0013079_segmentation.png\n",
      "Processed ISIC_0010349_segmentation.png\n",
      "Processed ISIC_0003462_segmentation.png\n",
      "Processed ISIC_0009906_segmentation.png\n",
      "Processed ISIC_0014928_segmentation.png\n",
      "Processed ISIC_0012288_segmentation.png\n",
      "Processed ISIC_0009918_segmentation.png\n",
      "Processed ISIC_0000059_segmentation.png\n",
      "Processed ISIC_0000276_segmentation.png\n",
      "Processed ISIC_0000057_segmentation.png\n",
      "Processed ISIC_0011131_segmentation.png\n",
      "Processed ISIC_0009160_segmentation.png\n",
      "Processed ISIC_0010558_segmentation.png\n",
      "Processed ISIC_0016071_segmentation.png\n",
      "Processed ISIC_0013804_segmentation.png\n",
      "Processed ISIC_0015160_segmentation.png\n",
      "Processed ISIC_0000359_segmentation.png\n",
      "Processed ISIC_0014586_segmentation.png\n",
      "Processed ISIC_0000228_segmentation.png\n",
      "Processed ISIC_0015995_segmentation.png\n",
      "Processed ISIC_0006776_segmentation.png\n",
      "Processed ISIC_0016069_segmentation.png\n",
      "Processed ISIC_0013740_segmentation.png\n",
      "Processed ISIC_0014746_segmentation.png\n",
      "Processed ISIC_0012376_segmentation.png\n",
      "Processed ISIC_0010206_segmentation.png\n",
      "Processed ISIC_0012204_segmentation.png\n",
      "Processed ISIC_0000007_segmentation.png\n",
      "Processed ISIC_0013047_segmentation.png\n",
      "Processed ISIC_0010465_segmentation.png\n",
      "Processed ISIC_0013140_segmentation.png\n",
      "Processed ISIC_0014365_segmentation.png\n",
      "Processed ISIC_0012965_segmentation.png\n",
      "Processed ISIC_0000338_segmentation.png\n",
      "Processed ISIC_0000486_segmentation.png\n",
      "Processed ISIC_0000050_segmentation.png\n",
      "Processed ISIC_0015968_segmentation.png\n",
      "Processed ISIC_0009955_segmentation.png\n",
      "Processed ISIC_0000147_segmentation.png\n",
      "Processed ISIC_0014833_segmentation.png\n",
      "Processed ISIC_0000271_segmentation.png\n",
      "Processed ISIC_0010102_segmentation.png\n",
      "Processed ISIC_0016009_segmentation.png\n",
      "Processed ISIC_0012669_segmentation.png\n",
      "Processed ISIC_0012520_segmentation.png\n",
      "Processed ISIC_0011121_segmentation.png\n",
      "Processed ISIC_0000521_segmentation.png\n",
      "Processed ISIC_0000102_segmentation.png\n",
      "Processed ISIC_0013567_segmentation.png\n",
      "Processed ISIC_0010490_segmentation.png\n",
      "Processed ISIC_0012135_segmentation.png\n",
      "Processed ISIC_0000396_segmentation.png\n",
      "Processed ISIC_0006914_segmentation.png\n",
      "Processed ISIC_0008256_segmentation.png\n",
      "Processed ISIC_0013918_segmentation.png\n",
      "Processed ISIC_0010447_segmentation.png\n",
      "Processed ISIC_0015357_segmentation.png\n",
      "Processed ISIC_0013493_segmentation.png\n",
      "Processed ISIC_0014961_segmentation.png\n",
      "Processed ISIC_0009953_segmentation.png\n",
      "Processed ISIC_0003346_segmentation.png\n",
      "Processed ISIC_0014946_segmentation.png\n",
      "Processed ISIC_0013244_segmentation.png\n",
      "Processed ISIC_0010475_segmentation.png\n",
      "Processed ISIC_0000093_segmentation.png\n",
      "Processed ISIC_0000011_segmentation.png\n",
      "Processed ISIC_0008993_segmentation.png\n",
      "Processed ISIC_0013165_segmentation.png\n",
      "Processed ISIC_0000152_segmentation.png\n",
      "Processed ISIC_0000386_segmentation.png\n",
      "Processed ISIC_0014897_segmentation.png\n",
      "Processed ISIC_0014585_segmentation.png\n",
      "Processed ISIC_0014786_segmentation.png\n",
      "Processed ISIC_0002948_segmentation.png\n",
      "Processed ISIC_0013311_segmentation.png\n",
      "Processed ISIC_0013224_segmentation.png\n",
      "Processed ISIC_0011292_segmentation.png\n",
      "Processed ISIC_0000249_segmentation.png\n",
      "Processed ISIC_0013494_segmentation.png\n",
      "Processed ISIC_0000026_segmentation.png\n",
      "Processed ISIC_0000545_segmentation.png\n",
      "Processed ISIC_0000204_segmentation.png\n",
      "Processed ISIC_0014665_segmentation.png\n",
      "Processed ISIC_0014478_segmentation.png\n",
      "Processed ISIC_0010606_segmentation.png\n",
      "Processed ISIC_0014910_segmentation.png\n",
      "Processed ISIC_0008396_segmentation.png\n",
      "Processed ISIC_0014026_segmentation.png\n",
      "Processed ISIC_0000021_segmentation.png\n",
      "Processed ISIC_0000536_segmentation.png\n",
      "Processed ISIC_0010009_segmentation.png\n",
      "Processed ISIC_0013472_segmentation.png\n",
      "Processed ISIC_0013972_segmentation.png\n",
      "Processed ISIC_0000223_segmentation.png\n",
      "Processed ISIC_0002469_segmentation.png\n",
      "Processed ISIC_0015974_segmentation.png\n",
      "Processed ISIC_0012330_segmentation.png\n",
      "Processed ISIC_0015203_segmentation.png\n",
      "Processed ISIC_0000299_segmentation.png\n",
      "Processed ISIC_0012715_segmentation.png\n",
      "Processed ISIC_0001871_segmentation.png\n",
      "Processed ISIC_0012210_segmentation.png\n",
      "Processed ISIC_0008406_segmentation.png\n",
      "Processed ISIC_0014853_segmentation.png\n",
      "Processed ISIC_0000139_segmentation.png\n",
      "Processed ISIC_0013193_segmentation.png\n",
      "Processed ISIC_0014831_segmentation.png\n",
      "Processed ISIC_0015526_segmentation.png\n",
      "Processed ISIC_0014149_segmentation.png\n",
      "Processed ISIC_0000321_segmentation.png\n",
      "Processed ISIC_0011372_segmentation.png\n",
      "Processed ISIC_0013651_segmentation.png\n",
      "Processed ISIC_0006651_segmentation.png\n",
      "Processed ISIC_0014915_segmentation.png\n",
      "Processed ISIC_0013249_segmentation.png\n",
      "Processed ISIC_0010557_segmentation.png\n",
      "Processed ISIC_0014073_segmentation.png\n",
      "Processed ISIC_0013986_segmentation.png\n",
      "Processed ISIC_0000036_segmentation.png\n",
      "Processed ISIC_0010232_segmentation.png\n",
      "Processed ISIC_0013329_segmentation.png\n",
      "Processed ISIC_0012941_segmentation.png\n",
      "Processed ISIC_0010493_segmentation.png\n",
      "Processed ISIC_0014698_segmentation.png\n",
      "Processed ISIC_0000315_segmentation.png\n",
      "Processed ISIC_0014898_segmentation.png\n",
      "Processed ISIC_0015190_segmentation.png\n",
      "Processed ISIC_0008913_segmentation.png\n",
      "Processed ISIC_0013184_segmentation.png\n",
      "Processed ISIC_0013395_segmentation.png\n",
      "Processed ISIC_0011211_segmentation.png\n",
      "Processed ISIC_0014328_segmentation.png\n",
      "Processed ISIC_0012303_segmentation.png\n",
      "Processed ISIC_0014441_segmentation.png\n",
      "Processed ISIC_0006350_segmentation.png\n",
      "Processed ISIC_0000999_segmentation.png\n",
      "Processed ISIC_0010184_segmentation.png\n",
      "Processed ISIC_0000089_segmentation.png\n",
      "Processed ISIC_0001119_segmentation.png\n",
      "Processed ISIC_0006711_segmentation.png\n",
      "Processed ISIC_0013966_segmentation.png\n",
      "Processed ISIC_0014796_segmentation.png\n",
      "Processed ISIC_0010468_segmentation.png\n",
      "Processed ISIC_0000363_segmentation.png\n",
      "Processed ISIC_0010066_segmentation.png\n",
      "Processed ISIC_0012681_segmentation.png\n",
      "Processed ISIC_0010844_segmentation.png\n",
      "Processed ISIC_0011323_segmentation.png\n",
      "Processed ISIC_0000013_segmentation.png\n",
      "Processed ISIC_0013400_segmentation.png\n",
      "Processed ISIC_0013012_segmentation.png\n",
      "Processed ISIC_0015607_segmentation.png\n",
      "Processed ISIC_0000421_segmentation.png\n",
      "Processed ISIC_0014879_segmentation.png\n",
      "Processed ISIC_0011199_segmentation.png\n",
      "Processed ISIC_0013559_segmentation.png\n",
      "Processed ISIC_0011304_segmentation.png\n",
      "Processed ISIC_0009869_segmentation.png\n",
      "Processed ISIC_0000019_segmentation.png\n",
      "Processed ISIC_0013341_segmentation.png\n",
      "Processed ISIC_0009875_segmentation.png\n",
      "Processed ISIC_0015948_segmentation.png\n",
      "Processed ISIC_0010862_segmentation.png\n",
      "Processed ISIC_0015215_segmentation.png\n",
      "Processed ISIC_0000392_segmentation.png\n",
      "Processed ISIC_0000337_segmentation.png\n",
      "Processed ISIC_0011161_segmentation.png\n",
      "Processed ISIC_0013670_segmentation.png\n",
      "Processed ISIC_0014860_segmentation.png\n",
      "Processed ISIC_0010043_segmentation.png\n",
      "Processed ISIC_0010220_segmentation.png\n",
      "Processed ISIC_0014763_segmentation.png\n",
      "Processed ISIC_0012911_segmentation.png\n",
      "Processed ISIC_0012228_segmentation.png\n",
      "Processed ISIC_0011112_segmentation.png\n",
      "Processed ISIC_0013489_segmentation.png\n",
      "Processed ISIC_0010176_segmentation.png\n",
      "Processed ISIC_0000188_segmentation.png\n",
      "Processed ISIC_0010247_segmentation.png\n",
      "Processed ISIC_0012726_segmentation.png\n",
      "Processed ISIC_0010038_segmentation.png\n",
      "Processed ISIC_0010317_segmentation.png\n",
      "Processed ISIC_0014637_segmentation.png\n",
      "Processed ISIC_0003805_segmentation.png\n",
      "Processed ISIC_0016050_segmentation.png\n",
      "Processed ISIC_0010237_segmentation.png\n",
      "Processed ISIC_0000501_segmentation.png\n",
      "Processed ISIC_0014702_segmentation.png\n",
      "Processed ISIC_0014805_segmentation.png\n",
      "Processed ISIC_0014798_segmentation.png\n",
      "Processed ISIC_0015254_segmentation.png\n",
      "Processed ISIC_0012663_segmentation.png\n",
      "Processed ISIC_0012706_segmentation.png\n",
      "Processed ISIC_0000473_segmentation.png\n",
      "Processed ISIC_0014876_segmentation.png\n",
      "Processed ISIC_0000408_segmentation.png\n",
      "Processed ISIC_0014956_segmentation.png\n",
      "Processed ISIC_0016065_segmentation.png\n",
      "Processed ISIC_0000137_segmentation.png\n",
      "Processed ISIC_0014664_segmentation.png\n",
      "Processed ISIC_0013572_segmentation.png\n",
      "Processed ISIC_0013007_segmentation.png\n",
      "Processed ISIC_0000483_segmentation.png\n",
      "Processed ISIC_0015108_segmentation.png\n",
      "Processed ISIC_0013288_segmentation.png\n",
      "Processed ISIC_0000153_segmentation.png\n",
      "Processed ISIC_0014233_segmentation.png\n",
      "Processed ISIC_0000550_segmentation.png\n",
      "Processed ISIC_0010585_segmentation.png\n",
      "Processed ISIC_0015204_segmentation.png\n",
      "Processed ISIC_0000176_segmentation.png\n",
      "Processed ISIC_0014270_segmentation.png\n",
      "Processed ISIC_0000466_segmentation.png\n",
      "Processed ISIC_0010042_segmentation.png\n",
      "Processed ISIC_0000374_segmentation.png\n",
      "Processed ISIC_0000031_segmentation.png\n",
      "Processed ISIC_0015166_segmentation.png\n",
      "Processed ISIC_0000151_segmentation.png\n",
      "Processed ISIC_0011167_segmentation.png\n",
      "Processed ISIC_0014639_segmentation.png\n",
      "Processed ISIC_0013526_segmentation.png\n",
      "Processed ISIC_0013424_segmentation.png\n",
      "Processed ISIC_0010442_segmentation.png\n",
      "Processed ISIC_0010264_segmentation.png\n",
      "Processed ISIC_0013015_segmentation.png\n",
      "Processed ISIC_0014249_segmentation.png\n",
      "Processed ISIC_0009961_segmentation.png\n",
      "Processed ISIC_0012986_segmentation.png\n",
      "Processed ISIC_0014845_segmentation.png\n",
      "Processed ISIC_0014985_segmentation.png\n",
      "Processed ISIC_0000108_segmentation.png\n",
      "Processed ISIC_0012956_segmentation.png\n",
      "Processed ISIC_0012318_segmentation.png\n",
      "Processed ISIC_0014500_segmentation.png\n",
      "Processed ISIC_0009919_segmentation.png\n",
      "Processed ISIC_0016004_segmentation.png\n",
      "Processed ISIC_0015153_segmentation.png\n",
      "Processed ISIC_0013461_segmentation.png\n",
      "Processed ISIC_0000378_segmentation.png\n",
      "Processed ISIC_0012151_segmentation.png\n",
      "Processed ISIC_0014947_segmentation.png\n",
      "Processed ISIC_0016055_segmentation.png\n",
      "Processed ISIC_0014838_segmentation.png\n",
      "Processed ISIC_0013833_segmentation.png\n",
      "Processed ISIC_0016014_segmentation.png\n",
      "Processed ISIC_0000189_segmentation.png\n",
      "Processed ISIC_0016063_segmentation.png\n",
      "Processed ISIC_0013155_segmentation.png\n",
      "Processed ISIC_0012481_segmentation.png\n",
      "Processed ISIC_0015237_segmentation.png\n",
      "Processed ISIC_0016026_segmentation.png\n",
      "Processed ISIC_0012749_segmentation.png\n",
      "Processed ISIC_0015940_segmentation.png\n",
      "Processed ISIC_0000014_segmentation.png\n",
      "Processed ISIC_0012756_segmentation.png\n",
      "Processed ISIC_0016030_segmentation.png\n",
      "Processed ISIC_0014503_segmentation.png\n",
      "Processed ISIC_0014219_segmentation.png\n",
      "Processed ISIC_0015185_segmentation.png\n",
      "Processed ISIC_0012969_segmentation.png\n",
      "Processed ISIC_0012107_segmentation.png\n",
      "Processed ISIC_0013738_segmentation.png\n",
      "Processed ISIC_0011109_segmentation.png\n",
      "Processed ISIC_0012662_segmentation.png\n",
      "Processed ISIC_0010497_segmentation.png\n",
      "Processed ISIC_0000254_segmentation.png\n",
      "Processed ISIC_0010044_segmentation.png\n",
      "Processed ISIC_0015987_segmentation.png\n",
      "Processed ISIC_0012484_segmentation.png\n",
      "Processed ISIC_0014683_segmentation.png\n",
      "Processed ISIC_0016060_segmentation.png\n",
      "Processed ISIC_0013073_segmentation.png\n",
      "Processed ISIC_0013257_segmentation.png\n",
      "Processed ISIC_0010204_segmentation.png\n",
      "Processed ISIC_0000383_segmentation.png\n",
      "Processed ISIC_0013511_segmentation.png\n",
      "Processed ISIC_0015566_segmentation.png\n",
      "Processed ISIC_0010000_segmentation.png\n",
      "Processed ISIC_0015279_segmentation.png\n",
      "Processed ISIC_0014029_segmentation.png\n",
      "Processed ISIC_0000344_segmentation.png\n",
      "Processed ISIC_0015044_segmentation.png\n",
      "Processed ISIC_0015936_segmentation.png\n",
      "Processed ISIC_0013269_segmentation.png\n",
      "Processed ISIC_0000199_segmentation.png\n",
      "Processed ISIC_0008600_segmentation.png\n",
      "Processed ISIC_0011303_segmentation.png\n",
      "Processed ISIC_0012891_segmentation.png\n",
      "Processed ISIC_0015211_segmentation.png\n",
      "Processed ISIC_0010850_segmentation.png\n",
      "Processed ISIC_0013797_segmentation.png\n",
      "Processed ISIC_0010852_segmentation.png\n",
      "Processed ISIC_0013333_segmentation.png\n",
      "Processed ISIC_0011162_segmentation.png\n",
      "Processed ISIC_0015184_segmentation.png\n",
      "Processed ISIC_0010361_segmentation.png\n",
      "Processed ISIC_0015950_segmentation.png\n",
      "Processed ISIC_0012374_segmentation.png\n",
      "Processed ISIC_0000175_segmentation.png\n",
      "Processed ISIC_0015963_segmentation.png\n",
      "Processed ISIC_0011360_segmentation.png\n",
      "Processed ISIC_0015031_segmentation.png\n",
      "Processed ISIC_0015060_segmentation.png\n",
      "Processed ISIC_0014715_segmentation.png\n",
      "Processed ISIC_0013190_segmentation.png\n",
      "Processed ISIC_0014522_segmentation.png\n",
      "Processed ISIC_0001103_segmentation.png\n",
      "Processed ISIC_0000319_segmentation.png\n",
      "Processed ISIC_0010327_segmentation.png\n",
      "Processed ISIC_0003728_segmentation.png\n",
      "Processed ISIC_0014911_segmentation.png\n",
      "Processed ISIC_0012311_segmentation.png\n",
      "Processed ISIC_0015243_segmentation.png\n",
      "Processed ISIC_0012155_segmentation.png\n",
      "Processed ISIC_0000146_segmentation.png\n",
      "Processed ISIC_0013213_segmentation.png\n",
      "Processed ISIC_0014728_segmentation.png\n",
      "Processed ISIC_0010864_segmentation.png\n",
      "Processed ISIC_0013674_segmentation.png\n",
      "Processed ISIC_0010046_segmentation.png\n",
      "Processed ISIC_0013170_segmentation.png\n",
      "Processed ISIC_0014867_segmentation.png\n",
      "Processed ISIC_0000183_segmentation.png\n",
      "Processed ISIC_0000352_segmentation.png\n",
      "Processed ISIC_0002374_segmentation.png\n",
      "Processed ISIC_0000079_segmentation.png\n",
      "Processed ISIC_0000282_segmentation.png\n",
      "Processed ISIC_0010566_segmentation.png\n",
      "Processed ISIC_0012338_segmentation.png\n",
      "Processed ISIC_0012406_segmentation.png\n",
      "Processed ISIC_0003582_segmentation.png\n",
      "Processed ISIC_0014183_segmentation.png\n",
      "Processed ISIC_0000303_segmentation.png\n",
      "Processed ISIC_0003174_segmentation.png\n",
      "Processed ISIC_0016029_segmentation.png\n",
      "Processed ISIC_0000511_segmentation.png\n",
      "Processed ISIC_0010070_segmentation.png\n",
      "Processed ISIC_0013150_segmentation.png\n",
      "Processed ISIC_0014162_segmentation.png\n",
      "Processed ISIC_0000041_segmentation.png\n",
      "Processed ISIC_0001204_segmentation.png\n",
      "Processed ISIC_0011099_segmentation.png\n",
      "Processed ISIC_0013935_segmentation.png\n",
      "Processed ISIC_0010077_segmentation.png\n",
      "Processed ISIC_0000419_segmentation.png\n",
      "Processed ISIC_0000313_segmentation.png\n",
      "Processed ISIC_0011333_segmentation.png\n",
      "Processed ISIC_0014868_segmentation.png\n",
      "Processed ISIC_0016056_segmentation.png\n",
      "Processed ISIC_0000346_segmentation.png\n",
      "Processed ISIC_0000301_segmentation.png\n",
      "Processed ISIC_0000258_segmentation.png\n",
      "Processed ISIC_0015264_segmentation.png\n",
      "Processed ISIC_0012655_segmentation.png\n",
      "Processed ISIC_0013187_segmentation.png\n",
      "Processed ISIC_0014772_segmentation.png\n",
      "Processed ISIC_0014603_segmentation.png\n",
      "Processed ISIC_0010569_segmentation.png\n",
      "Processed ISIC_0009599_segmentation.png\n",
      "Processed ISIC_0000326_segmentation.png\n",
      "Processed ISIC_0000206_segmentation.png\n",
      "Processed ISIC_0011118_segmentation.png\n",
      "Processed ISIC_0015124_segmentation.png\n",
      "Processed ISIC_0014225_segmentation.png\n",
      "Processed ISIC_0013429_segmentation.png\n",
      "Processed ISIC_0014316_segmentation.png\n",
      "Processed ISIC_0015273_segmentation.png\n",
      "Processed ISIC_0013055_segmentation.png\n",
      "Processed ISIC_0014936_segmentation.png\n",
      "Processed ISIC_0012950_segmentation.png\n",
      "Processed ISIC_0012495_segmentation.png\n",
      "Processed ISIC_0012879_segmentation.png\n",
      "Processed ISIC_0010034_segmentation.png\n",
      "Processed ISIC_0013831_segmentation.png\n",
      "Processed ISIC_0012835_segmentation.png\n",
      "Processed ISIC_0013208_segmentation.png\n",
      "Processed ISIC_0000484_segmentation.png\n",
      "Processed ISIC_0000538_segmentation.png\n",
      "Processed ISIC_0010848_segmentation.png\n",
      "Processed ISIC_0010320_segmentation.png\n",
      "Processed ISIC_0000167_segmentation.png\n",
      "Processed ISIC_0000086_segmentation.png\n",
      "Processed ISIC_0000117_segmentation.png\n",
      "Processed ISIC_0014372_segmentation.png\n",
      "Processed ISIC_0010492_segmentation.png\n",
      "Processed ISIC_0001100_segmentation.png\n",
      "Processed ISIC_0014308_segmentation.png\n",
      "Processed ISIC_0014559_segmentation.png\n",
      "Processed ISIC_0013455_segmentation.png\n",
      "Processed ISIC_0000367_segmentation.png\n",
      "Processed ISIC_0014473_segmentation.png\n",
      "Processed ISIC_0011344_segmentation.png\n",
      "Processed ISIC_0013552_segmentation.png\n",
      "Processed ISIC_0015129_segmentation.png\n",
      "Processed ISIC_0010105_segmentation.png\n",
      "Processed ISIC_0014773_segmentation.png\n",
      "Processed ISIC_0010326_segmentation.png\n",
      "Processed ISIC_0014975_segmentation.png\n",
      "Processed ISIC_0013618_segmentation.png\n",
      "Processed ISIC_0014812_segmentation.png\n",
      "Processed ISIC_0010233_segmentation.png\n",
      "Processed ISIC_0007557_segmentation.png\n",
      "Processed ISIC_0010063_segmentation.png\n",
      "Processed ISIC_0012907_segmentation.png\n",
      "Processed ISIC_0014501_segmentation.png\n",
      "Processed ISIC_0000517_segmentation.png\n",
      "Processed ISIC_0013443_segmentation.png\n",
      "Processed ISIC_0014453_segmentation.png\n",
      "Processed ISIC_0002453_segmentation.png\n",
      "Processed ISIC_0012671_segmentation.png\n",
      "Processed ISIC_0014949_segmentation.png\n",
      "Processed ISIC_0013056_segmentation.png\n",
      "Processed ISIC_0013911_segmentation.png\n",
      "Processed ISIC_0011305_segmentation.png\n",
      "Processed ISIC_0010452_segmentation.png\n",
      "Processed ISIC_0014740_segmentation.png\n",
      "Processed ISIC_0012278_segmentation.png\n",
      "Processed ISIC_0010589_segmentation.png\n",
      "Processed ISIC_0012147_segmentation.png\n",
      "Processed ISIC_0013765_segmentation.png\n",
      "Processed ISIC_0015404_segmentation.png\n",
      "Processed ISIC_0015008_segmentation.png\n",
      "Processed ISIC_0012149_segmentation.png\n",
      "Processed ISIC_0010078_segmentation.png\n",
      "Processed ISIC_0000230_segmentation.png\n",
      "Processed ISIC_0012742_segmentation.png\n",
      "Processed ISIC_0010323_segmentation.png\n",
      "Processed ISIC_0010858_segmentation.png\n",
      "Processed ISIC_0000119_segmentation.png\n",
      "Processed ISIC_0014802_segmentation.png\n",
      "Processed ISIC_0011329_segmentation.png\n",
      "Processed ISIC_0014830_segmentation.png\n",
      "Processed ISIC_0000006_segmentation.png\n",
      "Processed ISIC_0015258_segmentation.png\n",
      "Processed ISIC_0012876_segmentation.png\n",
      "Processed ISIC_0014696_segmentation.png\n",
      "Processed ISIC_0012548_segmentation.png\n",
      "Processed ISIC_0010348_segmentation.png\n",
      "Processed ISIC_0002673_segmentation.png\n",
      "Processed ISIC_0015016_segmentation.png\n",
      "Processed ISIC_0000543_segmentation.png\n",
      "Processed ISIC_0014849_segmentation.png\n",
      "Processed ISIC_0010322_segmentation.png\n",
      "Processed ISIC_0014331_segmentation.png\n",
      "Processed ISIC_0012285_segmentation.png\n",
      "Processed ISIC_0000202_segmentation.png\n",
      "Processed ISIC_0000127_segmentation.png\n",
      "Processed ISIC_0001247_segmentation.png\n",
      "Processed ISIC_0014361_segmentation.png\n",
      "Processed ISIC_0013405_segmentation.png\n",
      "Processed ISIC_0011224_segmentation.png\n",
      "Processed ISIC_0013832_segmentation.png\n",
      "Processed ISIC_0009994_segmentation.png\n",
      "Processed ISIC_0001286_segmentation.png\n",
      "Processed ISIC_0015975_segmentation.png\n",
      "Processed ISIC_0013217_segmentation.png\n",
      "Processed ISIC_0014814_segmentation.png\n",
      "Processed ISIC_0014253_segmentation.png\n",
      "Processed ISIC_0000159_segmentation.png\n",
      "Processed ISIC_0015641_segmentation.png\n",
      "Processed ISIC_0013065_segmentation.png\n",
      "Processed ISIC_0012432_segmentation.png\n",
      "Processed ISIC_0015173_segmentation.png\n",
      "Processed ISIC_0015369_segmentation.png\n",
      "Processed ISIC_0013736_segmentation.png\n",
      "Processed ISIC_0000053_segmentation.png\n",
      "Processed ISIC_0014289_segmentation.png\n",
      "Processed ISIC_0009980_segmentation.png\n",
      "Processed ISIC_0009972_segmentation.png\n",
      "Processed ISIC_0009883_segmentation.png\n",
      "Processed ISIC_0000103_segmentation.png\n",
      "Processed ISIC_0012246_segmentation.png\n",
      "Processed ISIC_0014419_segmentation.png\n",
      "Processed ISIC_0009990_segmentation.png\n",
      "Processed ISIC_0015003_segmentation.png\n",
      "Processed ISIC_0014587_segmentation.png\n",
      "Processed ISIC_0010013_segmentation.png\n",
      "Processed ISIC_0013579_segmentation.png\n",
      "Processed ISIC_0010449_segmentation.png\n",
      "Processed ISIC_0002836_segmentation.png\n",
      "Processed ISIC_0016037_segmentation.png\n",
      "Processed ISIC_0014792_segmentation.png\n",
      "Processed ISIC_0014507_segmentation.png\n",
      "Processed ISIC_0015944_segmentation.png\n",
      "Processed ISIC_0014903_segmentation.png\n",
      "Processed ISIC_0013517_segmentation.png\n",
      "Processed ISIC_0012976_segmentation.png\n",
      "Processed ISIC_0014948_segmentation.png\n",
      "Processed ISIC_0000015_segmentation.png\n",
      "Processed ISIC_0009923_segmentation.png\n",
      "Processed ISIC_0014037_segmentation.png\n",
      "Processed ISIC_0000353_segmentation.png\n",
      "Processed ISIC_0012306_segmentation.png\n",
      "Processed ISIC_0010089_segmentation.png\n",
      "Processed ISIC_0015050_segmentation.png\n",
      "Processed ISIC_0012259_segmentation.png\n",
      "Processed ISIC_0000085_segmentation.png\n",
      "Processed ISIC_0009078_segmentation.png\n",
      "Processed ISIC_0016013_segmentation.png\n",
      "Processed ISIC_0015032_segmentation.png\n",
      "Processed ISIC_0009944_segmentation.png\n",
      "Processed ISIC_0016061_segmentation.png\n",
      "Processed ISIC_0001126_segmentation.png\n",
      "Processed ISIC_0014782_segmentation.png\n",
      "Processed ISIC_0000269_segmentation.png\n",
      "Processed ISIC_0012966_segmentation.png\n",
      "Processed ISIC_0014337_segmentation.png\n",
      "Processed ISIC_0012713_segmentation.png\n",
      "Processed ISIC_0014760_segmentation.png\n",
      "Processed ISIC_0013592_segmentation.png\n",
      "Processed ISIC_0015957_segmentation.png\n",
      "Processed ISIC_0014806_segmentation.png\n",
      "Processed ISIC_0016035_segmentation.png\n",
      "Processed ISIC_0013205_segmentation.png\n",
      "Processed ISIC_0014685_segmentation.png\n",
      "Processed ISIC_0012434_segmentation.png\n",
      "Processed ISIC_0000064_segmentation.png\n",
      "Processed ISIC_0014092_segmentation.png\n",
      "Processed ISIC_0009947_segmentation.png\n",
      "Processed ISIC_0014927_segmentation.png\n",
      "Processed ISIC_0013495_segmentation.png\n",
      "Processed ISIC_0000004_segmentation.png\n",
      "Processed ISIC_0006114_segmentation.png\n",
      "Processed ISIC_0000542_segmentation.png\n",
      "Processed ISIC_0000124_segmentation.png\n",
      "Processed ISIC_0014825_segmentation.png\n",
      "Processed ISIC_0006193_segmentation.png\n",
      "Processed ISIC_0000196_segmentation.png\n",
      "Processed ISIC_0013762_segmentation.png\n",
      "Processed ISIC_0000104_segmentation.png\n",
      "Processed ISIC_0009915_segmentation.png\n",
      "Processed ISIC_0000236_segmentation.png\n",
      "Processed ISIC_0012222_segmentation.png\n",
      "Processed ISIC_0013031_segmentation.png\n",
      "Processed ISIC_0000350_segmentation.png\n",
      "Processed ISIC_0014581_segmentation.png\n",
      "Processed ISIC_0012118_segmentation.png\n",
      "Processed ISIC_0012810_segmentation.png\n",
      "Processed ISIC_0009991_segmentation.png\n",
      "Processed ISIC_0013136_segmentation.png\n",
      "Processed ISIC_0013772_segmentation.png\n",
      "Processed ISIC_0014724_segmentation.png\n",
      "Processed ISIC_0014836_segmentation.png\n",
      "Processed ISIC_0000056_segmentation.png\n",
      "Processed ISIC_0013767_segmentation.png\n",
      "Processed ISIC_0000547_segmentation.png\n",
      "Processed ISIC_0000555_segmentation.png\n",
      "Processed ISIC_0013819_segmentation.png\n",
      "Processed ISIC_0013843_segmentation.png\n",
      "Processed ISIC_0016043_segmentation.png\n",
      "Processed ISIC_0013675_segmentation.png\n",
      "Processed ISIC_0013987_segmentation.png\n",
      "Processed ISIC_0000216_segmentation.png\n",
      "Processed ISIC_0009975_segmentation.png\n",
      "Processed ISIC_0013708_segmentation.png\n",
      "Processed ISIC_0000522_segmentation.png\n",
      "Processed ISIC_0008507_segmentation.png\n",
      "Processed ISIC_0000494_segmentation.png\n",
      "Processed ISIC_0012987_segmentation.png\n",
      "Processed ISIC_0011157_segmentation.png\n",
      "Processed ISIC_0013688_segmentation.png\n",
      "Processed ISIC_0014731_segmentation.png\n",
      "Processed ISIC_0014596_segmentation.png\n",
      "Processed ISIC_0011398_segmentation.png\n",
      "Processed ISIC_0012309_segmentation.png\n",
      "Processed ISIC_0011208_segmentation.png\n",
      "Processed ISIC_0012203_segmentation.png\n",
      "Processed ISIC_0012735_segmentation.png\n",
      "Processed ISIC_0014187_segmentation.png\n",
      "Processed ISIC_0000349_segmentation.png\n",
      "Processed ISIC_0015291_segmentation.png\n",
      "Processed ISIC_0014940_segmentation.png\n",
      "Processed ISIC_0012216_segmentation.png\n",
      "Processed ISIC_0012363_segmentation.png\n",
      "Processed ISIC_0013399_segmentation.png\n",
      "Processed ISIC_0013861_segmentation.png\n",
      "Processed ISIC_0001106_segmentation.png\n",
      "Processed ISIC_0013702_segmentation.png\n",
      "Processed ISIC_0011084_segmentation.png\n",
      "Processed ISIC_0015981_segmentation.png\n",
      "Processed ISIC_0000023_segmentation.png\n",
      "Processed ISIC_0015972_segmentation.png\n",
      "Processed ISIC_0015051_segmentation.png\n",
      "Processed ISIC_0014422_segmentation.png\n",
      "Processed ISIC_0000479_segmentation.png\n",
      "Processed ISIC_0014302_segmentation.png\n",
      "Processed ISIC_0002780_segmentation.png\n",
      "Processed ISIC_0000035_segmentation.png\n",
      "Processed ISIC_0015636_segmentation.png\n",
      "Processed ISIC_0014324_segmentation.png\n",
      "Processed ISIC_0012126_segmentation.png\n",
      "Processed ISIC_0000540_segmentation.png\n",
      "Processed ISIC_0015218_segmentation.png\n",
      "Processed ISIC_0014489_segmentation.png\n",
      "Processed ISIC_0013160_segmentation.png\n",
      "Processed ISIC_0014826_segmentation.png\n",
      "Processed ISIC_0012425_segmentation.png\n",
      "Processed ISIC_0012901_segmentation.png\n",
      "Processed ISIC_0011359_segmentation.png\n",
      "Processed ISIC_0016044_segmentation.png\n",
      "Processed ISIC_0000024_segmentation.png\n",
      "Processed ISIC_0000295_segmentation.png\n",
      "Processed ISIC_0000397_segmentation.png\n",
      "Processed ISIC_0015983_segmentation.png\n",
      "Processed ISIC_0013863_segmentation.png\n",
      "Processed ISIC_0010021_segmentation.png\n",
      "Processed ISIC_0015113_segmentation.png\n",
      "Processed ISIC_0009946_segmentation.png\n",
      "Processed ISIC_0007528_segmentation.png\n",
      "Processed ISIC_0015991_segmentation.png\n",
      "Processed ISIC_0010187_segmentation.png\n",
      "Processed ISIC_0000495_segmentation.png\n",
      "Processed ISIC_0014129_segmentation.png\n",
      "Processed ISIC_0000069_segmentation.png\n",
      "Processed ISIC_0015293_segmentation.png\n",
      "Processed ISIC_0015401_segmentation.png\n",
      "Processed ISIC_0015942_segmentation.png\n",
      "Processed ISIC_0002353_segmentation.png\n",
      "Processed ISIC_0000181_segmentation.png\n",
      "Processed ISIC_0015089_segmentation.png\n",
      "Processed ISIC_0010058_segmentation.png\n",
      "Processed ISIC_0014059_segmentation.png\n",
      "Processed ISIC_0014850_segmentation.png\n",
      "Processed ISIC_0012826_segmentation.png\n",
      "Processed ISIC_0012360_segmentation.png\n",
      "Processed ISIC_0000190_segmentation.png\n",
      "Processed ISIC_0014912_segmentation.png\n",
      "Processed ISIC_0015614_segmentation.png\n",
      "Processed ISIC_0015941_segmentation.png\n",
      "Processed ISIC_0012888_segmentation.png\n",
      "Processed ISIC_0010248_segmentation.png\n",
      "Processed ISIC_0015206_segmentation.png\n",
      "Processed ISIC_0011159_segmentation.png\n",
      "Processed ISIC_0016058_segmentation.png\n",
      "Processed ISIC_0015945_segmentation.png\n",
      "Processed ISIC_0001372_segmentation.png\n",
      "Processed ISIC_0012094_segmentation.png\n",
      "Processed ISIC_0013685_segmentation.png\n",
      "Processed ISIC_0011298_segmentation.png\n",
      "Processed ISIC_0000443_segmentation.png\n",
      "Processed ISIC_0000537_segmentation.png\n",
      "Processed ISIC_0008236_segmentation.png\n",
      "Processed ISIC_0015563_segmentation.png\n",
      "Processed ISIC_0012378_segmentation.png\n",
      "Processed ISIC_0011315_segmentation.png\n",
      "Processed ISIC_0012721_segmentation.png\n",
      "Processed ISIC_0014694_segmentation.png\n",
      "Processed ISIC_0013626_segmentation.png\n",
      "Processed ISIC_0010441_segmentation.png\n",
      "Processed ISIC_0013946_segmentation.png\n",
      "Processed ISIC_0012803_segmentation.png\n",
      "Processed ISIC_0007475_segmentation.png\n",
      "Processed ISIC_0012944_segmentation.png\n",
      "Processed ISIC_0004337_segmentation.png\n",
      "Processed ISIC_0012448_segmentation.png\n",
      "Processed ISIC_0000171_segmentation.png\n",
      "Processed ISIC_0008207_segmentation.png\n",
      "Processed ISIC_0013501_segmentation.png\n",
      "Processed ISIC_0013096_segmentation.png\n",
      "Processed ISIC_0016025_segmentation.png\n",
      "Processed ISIC_0000157_segmentation.png\n",
      "Processed ISIC_0010168_segmentation.png\n",
      "Processed ISIC_0000072_segmentation.png\n",
      "Processed ISIC_0000039_segmentation.png\n",
      "Processed ISIC_0011366_segmentation.png\n",
      "Processed ISIC_0013565_segmentation.png\n",
      "Processed ISIC_0009877_segmentation.png\n",
      "Processed ISIC_0012792_segmentation.png\n",
      "Processed ISIC_0000211_segmentation.png\n",
      "Processed ISIC_0014677_segmentation.png\n",
      "Processed ISIC_0010846_segmentation.png\n",
      "Processed ISIC_0011176_segmentation.png\n",
      "Processed ISIC_0013888_segmentation.png\n",
      "Processed ISIC_0013238_segmentation.png\n",
      "Processed ISIC_0013577_segmentation.png\n",
      "Processed ISIC_0010592_segmentation.png\n",
      "Processed ISIC_0012693_segmentation.png\n",
      "Processed ISIC_0011089_segmentation.png\n",
      "Processed ISIC_0010584_segmentation.png\n",
      "Processed ISIC_0015062_segmentation.png\n",
      "Processed ISIC_0009932_segmentation.png\n",
      "Processed ISIC_0013874_segmentation.png\n",
      "Processed ISIC_0014713_segmentation.png\n",
      "Processed ISIC_0010599_segmentation.png\n",
      "Processed ISIC_0011374_segmentation.png\n",
      "Processed ISIC_0015035_segmentation.png\n",
      "Processed ISIC_0013578_segmentation.png\n",
      "Processed ISIC_0015170_segmentation.png\n",
      "Processed ISIC_0011358_segmentation.png\n",
      "Processed ISIC_0009930_segmentation.png\n",
      "Processed ISIC_0012258_segmentation.png\n",
      "Processed ISIC_0012506_segmentation.png\n",
      "Processed ISIC_0000100_segmentation.png\n",
      "Processed ISIC_0009958_segmentation.png\n",
      "Processed ISIC_0015466_segmentation.png\n",
      "Processed ISIC_0002616_segmentation.png\n",
      "Processed ISIC_0015201_segmentation.png\n",
      "Processed ISIC_0014480_segmentation.png\n",
      "Processed ISIC_0015171_segmentation.png\n",
      "Processed ISIC_0004110_segmentation.png\n",
      "Processed ISIC_0014431_segmentation.png\n",
      "Processed ISIC_0013287_segmentation.png\n",
      "Processed ISIC_0015136_segmentation.png\n",
      "Processed ISIC_0015411_segmentation.png\n",
      "Processed ISIC_0000148_segmentation.png\n",
      "Processed ISIC_0002489_segmentation.png\n",
      "Processed ISIC_0011090_segmentation.png\n",
      "Processed ISIC_0014857_segmentation.png\n",
      "Processed ISIC_0013173_segmentation.png\n",
      "Processed ISIC_0013026_segmentation.png\n",
      "Processed ISIC_0012512_segmentation.png\n",
      "Processed ISIC_0011164_segmentation.png\n",
      "Processed ISIC_0014901_segmentation.png\n",
      "Processed ISIC_0000448_segmentation.png\n",
      "Processed ISIC_0014529_segmentation.png\n",
      "Processed ISIC_0015005_segmentation.png\n",
      "Processed ISIC_0014973_segmentation.png\n",
      "Processed ISIC_0015353_segmentation.png\n",
      "Processed ISIC_0015993_segmentation.png\n",
      "Processed ISIC_0015964_segmentation.png\n",
      "Processed ISIC_0012940_segmentation.png\n",
      "Processed ISIC_0010590_segmentation.png\n",
      "Processed ISIC_0010473_segmentation.png\n",
      "Processed ISIC_0012478_segmentation.png\n",
      "Processed ISIC_0014548_segmentation.png\n",
      "Processed ISIC_0000426_segmentation.png\n",
      "Processed ISIC_0014027_segmentation.png\n",
      "Processed ISIC_0001292_segmentation.png\n",
      "Processed ISIC_0013397_segmentation.png\n",
      "Processed ISIC_0013816_segmentation.png\n",
      "Processed ISIC_0015245_segmentation.png\n",
      "Processed ISIC_0000170_segmentation.png\n",
      "Processed ISIC_0012770_segmentation.png\n",
      "Processed ISIC_0000310_segmentation.png\n",
      "Processed ISIC_0013830_segmentation.png\n",
      "Processed ISIC_0009945_segmentation.png\n",
      "Processed ISIC_0009920_segmentation.png\n",
      "Processed ISIC_0010234_segmentation.png\n",
      "Processed ISIC_0014818_segmentation.png\n",
      "Processed ISIC_0000331_segmentation.png\n",
      "Processed ISIC_0011085_segmentation.png\n",
      "Processed ISIC_0000387_segmentation.png\n",
      "Processed ISIC_0011362_segmentation.png\n",
      "Processed ISIC_0015274_segmentation.png\n",
      "Processed ISIC_0011128_segmentation.png\n",
      "Processed ISIC_0011102_segmentation.png\n",
      "Processed ISIC_0015946_segmentation.png\n",
      "Processed ISIC_0012981_segmentation.png\n",
      "Processed ISIC_0014311_segmentation.png\n",
      "Processed ISIC_0013800_segmentation.png\n",
      "Processed ISIC_0013480_segmentation.png\n",
      "Processed ISIC_0000087_segmentation.png\n",
      "Processed ISIC_0000032_segmentation.png\n",
      "Processed ISIC_0014072_segmentation.png\n",
      "Processed ISIC_0000322_segmentation.png\n",
      "Processed ISIC_0000287_segmentation.png\n",
      "Processed ISIC_0009969_segmentation.png\n",
      "Processed ISIC_0001118_segmentation.png\n",
      "Processed ISIC_0003056_segmentation.png\n",
      "Processed ISIC_0014729_segmentation.png\n",
      "Processed ISIC_0011177_segmentation.png\n",
      "Processed ISIC_0000900_segmentation.png\n",
      "Processed ISIC_0013027_segmentation.png\n",
      "Processed ISIC_0012516_segmentation.png\n",
      "Processed ISIC_0012961_segmentation.png\n",
      "Processed ISIC_0010588_segmentation.png\n",
      "Processed ISIC_0014609_segmentation.png\n",
      "Processed ISIC_0014755_segmentation.png\n",
      "Processed ISIC_0009873_segmentation.png\n",
      "Processed ISIC_0011349_segmentation.png\n",
      "Processed ISIC_0000339_segmentation.png\n",
      "Processed ISIC_0010180_segmentation.png\n",
      "Processed ISIC_0000242_segmentation.png\n",
      "Processed ISIC_0014580_segmentation.png\n",
      "Processed ISIC_0012904_segmentation.png\n",
      "Processed ISIC_0014186_segmentation.png\n",
      "Processed ISIC_0000016_segmentation.png\n",
      "Processed ISIC_0013980_segmentation.png\n",
      "Processed ISIC_0009888_segmentation.png\n",
      "Processed ISIC_0015229_segmentation.png\n",
      "Processed ISIC_0014349_segmentation.png\n",
      "Processed ISIC_0012665_segmentation.png\n",
      "Processed ISIC_0010216_segmentation.png\n",
      "Processed ISIC_0000233_segmentation.png\n",
      "Processed ISIC_0014127_segmentation.png\n",
      "Processed ISIC_0000293_segmentation.png\n",
      "Processed ISIC_0013032_segmentation.png\n",
      "Processed ISIC_0015176_segmentation.png\n",
      "Processed ISIC_0000197_segmentation.png\n",
      "Processed ISIC_0014643_segmentation.png\n",
      "Processed ISIC_0013277_segmentation.png\n",
      "Processed ISIC_0007141_segmentation.png\n",
      "Processed ISIC_0013302_segmentation.png\n",
      "Processed ISIC_0000038_segmentation.png\n",
      "Processed ISIC_0010861_segmentation.png\n",
      "Processed ISIC_0011166_segmentation.png\n",
      "Processed ISIC_0015163_segmentation.png\n",
      "Processed ISIC_0013094_segmentation.png\n",
      "Processed ISIC_0013805_segmentation.png\n",
      "Processed ISIC_0000544_segmentation.png\n",
      "Processed ISIC_0014001_segmentation.png\n",
      "Processed ISIC_0015130_segmentation.png\n",
      "Processed ISIC_0000275_segmentation.png\n",
      "Processed ISIC_0010244_segmentation.png\n",
      "Processed ISIC_0009992_segmentation.png\n",
      "Processed ISIC_0011205_segmentation.png\n",
      "Processed ISIC_0011139_segmentation.png\n",
      "Processed ISIC_0000122_segmentation.png\n",
      "Processed ISIC_0014327_segmentation.png\n",
      "Processed ISIC_0015355_segmentation.png\n",
      "Processed ISIC_0014131_segmentation.png\n",
      "Processed ISIC_0014470_segmentation.png\n",
      "Processed ISIC_0013035_segmentation.png\n",
      "Processed ISIC_0013216_segmentation.png\n",
      "Processed ISIC_0013839_segmentation.png\n",
      "Processed ISIC_0010061_segmentation.png\n",
      "Processed ISIC_0011083_segmentation.png\n",
      "Processed ISIC_0014610_segmentation.png\n",
      "Processed ISIC_0013664_segmentation.png\n",
      "Processed ISIC_0012551_segmentation.png\n",
      "Processed ISIC_0016070_segmentation.png\n",
      "Processed ISIC_0013023_segmentation.png\n",
      "Processed ISIC_0010498_segmentation.png\n",
      "Processed ISIC_0014434_segmentation.png\n",
      "Processed ISIC_0015110_segmentation.png\n",
      "Processed ISIC_0015313_segmentation.png\n",
      "Processed ISIC_0010439_segmentation.png\n",
      "Processed ISIC_0000510_segmentation.png\n",
      "Processed ISIC_0000222_segmentation.png\n",
      "Processed ISIC_0011137_segmentation.png\n",
      "Processed ISIC_0000092_segmentation.png\n",
      "Processed ISIC_0009188_segmentation.png\n",
      "Processed ISIC_0016023_segmentation.png\n",
      "Processed ISIC_0015949_segmentation.png\n",
      "Processed ISIC_0014160_segmentation.png\n",
      "Processed ISIC_0014173_segmentation.png\n",
      "Processed ISIC_0013737_segmentation.png\n",
      "Processed ISIC_0014089_segmentation.png\n",
      "Processed ISIC_0011155_segmentation.png\n",
      "Processed ISIC_0013970_segmentation.png\n",
      "Processed ISIC_0012417_segmentation.png\n",
      "Processed ISIC_0000128_segmentation.png\n",
      "Processed ISIC_0013230_segmentation.png\n",
      "Processed ISIC_0000460_segmentation.png\n",
      "Processed ISIC_0013527_segmentation.png\n",
      "Processed ISIC_0015037_segmentation.png\n",
      "Processed ISIC_0002439_segmentation.png\n",
      "Processed ISIC_0014809_segmentation.png\n",
      "Processed ISIC_0000220_segmentation.png\n",
      "Processed ISIC_0010477_segmentation.png\n",
      "Processed ISIC_0010604_segmentation.png\n",
      "Processed ISIC_0000469_segmentation.png\n",
      "Processed ISIC_0005548_segmentation.png\n",
      "Processed ISIC_0011156_segmentation.png\n",
      "Processed ISIC_0013549_segmentation.png\n",
      "Processed ISIC_0008116_segmentation.png\n",
      "Processed ISIC_0000474_segmentation.png\n",
      "Processed ISIC_0011326_segmentation.png\n",
      "Processed ISIC_0000300_segmentation.png\n",
      "Processed ISIC_0012253_segmentation.png\n",
      "Processed ISIC_0014114_segmentation.png\n",
      "Processed ISIC_0000325_segmentation.png\n",
      "Processed ISIC_0012813_segmentation.png\n",
      "Processed ISIC_0014979_segmentation.png\n",
      "Processed ISIC_0012786_segmentation.png\n",
      "Processed ISIC_0014428_segmentation.png\n",
      "Processed ISIC_0015298_segmentation.png\n",
      "Processed ISIC_0000193_segmentation.png\n",
      "Processed ISIC_0010565_segmentation.png\n",
      "Processed ISIC_0012871_segmentation.png\n",
      "Processed ISIC_0013227_segmentation.png\n",
      "Processed ISIC_0013044_segmentation.png\n",
      "Processed ISIC_0016012_segmentation.png\n",
      "Processed ISIC_0009901_segmentation.png\n",
      "Processed ISIC_0002647_segmentation.png\n",
      "Processed ISIC_0014274_segmentation.png\n",
      "Processed ISIC_0010018_segmentation.png\n",
      "Processed ISIC_0000027_segmentation.png\n",
      "Processed ISIC_0002885_segmentation.png\n",
      "Processed ISIC_0014546_segmentation.png\n",
      "Processed ISIC_0010445_segmentation.png\n",
      "Processed ISIC_0015071_segmentation.png\n",
      "Processed ISIC_0012511_segmentation.png\n",
      "Processed ISIC_0014542_segmentation.png\n",
      "Processed ISIC_0015223_segmentation.png\n",
      "Processed ISIC_0010351_segmentation.png\n",
      "Processed ISIC_0012673_segmentation.png\n",
      "Processed ISIC_0012156_segmentation.png\n",
      "Processed ISIC_0012660_segmentation.png\n",
      "Processed ISIC_0011115_segmentation.png\n",
      "Processed ISIC_0014908_segmentation.png\n",
      "Processed ISIC_0010562_segmentation.png\n",
      "Processed ISIC_0013709_segmentation.png\n",
      "Processed ISIC_0010456_segmentation.png\n",
      "Processed ISIC_0013360_segmentation.png\n",
      "Processed ISIC_0013867_segmentation.png\n",
      "Processed ISIC_0000187_segmentation.png\n",
      "Processed ISIC_0015997_segmentation.png\n",
      "Processed ISIC_0003539_segmentation.png\n",
      "Processed ISIC_0000427_segmentation.png\n",
      "Processed ISIC_0000395_segmentation.png\n",
      "Processed ISIC_0012793_segmentation.png\n",
      "Processed ISIC_0005666_segmentation.png\n",
      "Processed ISIC_0012298_segmentation.png\n",
      "Processed ISIC_0012351_segmentation.png\n",
      "Processed ISIC_0011165_segmentation.png\n",
      "Processed ISIC_0010227_segmentation.png\n",
      "Processed ISIC_0012342_segmentation.png\n",
      "Processed ISIC_0009935_segmentation.png\n",
      "Processed ISIC_0015953_segmentation.png\n",
      "Processed ISIC_0015156_segmentation.png\n",
      "Processed ISIC_0013417_segmentation.png\n",
      "Processed ISIC_0014778_segmentation.png\n",
      "Processed ISIC_0010572_segmentation.png\n",
      "Processed ISIC_0000208_segmentation.png\n",
      "Processed ISIC_0009933_segmentation.png\n",
      "Processed ISIC_0012503_segmentation.png\n",
      "Processed ISIC_0013656_segmentation.png\n",
      "Processed ISIC_0013783_segmentation.png\n",
      "Processed ISIC_0000329_segmentation.png\n",
      "Processed ISIC_0009974_segmentation.png\n",
      "Processed ISIC_0000020_segmentation.png\n",
      "Processed ISIC_0013615_segmentation.png\n",
      "Processed ISIC_0009948_segmentation.png\n",
      "Processed ISIC_0014197_segmentation.png\n",
      "Processed ISIC_0010337_segmentation.png\n",
      "Processed ISIC_0015631_segmentation.png\n",
      "Processed ISIC_0012413_segmentation.png\n",
      "Processed ISIC_0014794_segmentation.png\n",
      "Processed ISIC_0011393_segmentation.png\n",
      "Processed ISIC_0000465_segmentation.png\n",
      "Processed ISIC_0000425_segmentation.png\n",
      "Processed ISIC_0012455_segmentation.png\n",
      "Processed ISIC_0000324_segmentation.png\n",
      "Processed ISIC_0015958_segmentation.png\n",
      "Processed ISIC_0015149_segmentation.png\n",
      "Processed ISIC_0000225_segmentation.png\n",
      "Processed ISIC_0012526_segmentation.png\n",
      "Processed ISIC_0013712_segmentation.png\n",
      "Processed ISIC_0015207_segmentation.png\n",
      "Processed ISIC_0013090_segmentation.png\n",
      "Processed ISIC_0014157_segmentation.png\n",
      "Processed ISIC_0015046_segmentation.png\n",
      "Processed ISIC_0014753_segmentation.png\n",
      "Processed ISIC_0015976_segmentation.png\n",
      "Processed ISIC_0013652_segmentation.png\n",
      "Processed ISIC_0014150_segmentation.png\n",
      "Processed ISIC_0013603_segmentation.png\n",
      "Processed ISIC_0000278_segmentation.png\n",
      "Processed ISIC_0015443_segmentation.png\n",
      "Processed ISIC_0012804_segmentation.png\n",
      "Processed ISIC_0015284_segmentation.png\n",
      "Processed ISIC_0014869_segmentation.png\n",
      "Processed ISIC_0001262_segmentation.png\n",
      "Processed ISIC_0009965_segmentation.png\n",
      "Processed ISIC_0012384_segmentation.png\n",
      "Processed ISIC_0015360_segmentation.png\n",
      "Processed ISIC_0012256_segmentation.png\n",
      "Processed ISIC_0014174_segmentation.png\n",
      "Processed ISIC_0000163_segmentation.png\n",
      "Processed ISIC_0010598_segmentation.png\n",
      "Processed ISIC_0013568_segmentation.png\n",
      "Processed ISIC_0000341_segmentation.png\n",
      "Processed ISIC_0012517_segmentation.png\n",
      "Processed ISIC_0000253_segmentation.png\n",
      "Processed ISIC_0000529_segmentation.png\n",
      "Processed ISIC_0006021_segmentation.png\n",
      "Processed ISIC_0016007_segmentation.png\n",
      "Processed ISIC_0011225_segmentation.png\n",
      "Processed ISIC_0014942_segmentation.png\n",
      "Processed ISIC_0015155_segmentation.png\n",
      "Processed ISIC_0014049_segmentation.png\n",
      "Processed ISIC_0014808_segmentation.png\n",
      "Processed ISIC_0000160_segmentation.png\n",
      "Processed ISIC_0000265_segmentation.png\n",
      "Processed ISIC_0014576_segmentation.png\n",
      "Processed ISIC_0012939_segmentation.png\n",
      "Processed ISIC_0014394_segmentation.png\n",
      "Processed ISIC_0010339_segmentation.png\n",
      "Processed ISIC_0013129_segmentation.png\n",
      "Processed ISIC_0012442_segmentation.png\n",
      "Processed ISIC_0000110_segmentation.png\n",
      "Processed ISIC_0013229_segmentation.png\n",
      "Processed ISIC_0013798_segmentation.png\n",
      "Processed ISIC_0010466_segmentation.png\n",
      "Processed ISIC_0013134_segmentation.png\n",
      "Processed ISIC_0013601_segmentation.png\n",
      "Processed ISIC_0012654_segmentation.png\n",
      "Processed ISIC_0012390_segmentation.png\n",
      "Processed ISIC_0015202_segmentation.png\n",
      "Processed ISIC_0000082_segmentation.png\n",
      "Processed ISIC_0012334_segmentation.png\n",
      "Processed ISIC_0011343_segmentation.png\n",
      "Processed ISIC_0014572_segmentation.png\n",
      "Processed ISIC_0010571_segmentation.png\n",
      "Processed ISIC_0011339_segmentation.png\n",
      "Processed ISIC_0014386_segmentation.png\n",
      "Processed ISIC_0013310_segmentation.png\n",
      "Processed ISIC_0015150_segmentation.png\n",
      "Processed ISIC_0014513_segmentation.png\n",
      "Processed ISIC_0013600_segmentation.png\n",
      "Processed ISIC_0010023_segmentation.png\n",
      "Processed ISIC_0010169_segmentation.png\n",
      "Processed ISIC_0011170_segmentation.png\n",
      "Processed ISIC_0009914_segmentation.png\n",
      "Processed ISIC_0013235_segmentation.png\n",
      "Processed ISIC_0001769_segmentation.png\n",
      "Processed ISIC_0000234_segmentation.png\n",
      "Processed ISIC_0015617_segmentation.png\n",
      "Processed ISIC_0005639_segmentation.png\n",
      "Processed ISIC_0012299_segmentation.png\n",
      "Processed ISIC_0015244_segmentation.png\n",
      "Processed ISIC_0000493_segmentation.png\n",
      "Processed ISIC_0014692_segmentation.png\n",
      "Processed ISIC_0011387_segmentation.png\n",
      "Processed ISIC_0012211_segmentation.png\n",
      "Processed ISIC_0009758_segmentation.png\n",
      "Processed ISIC_0012281_segmentation.png\n",
      "Processed ISIC_0011334_segmentation.png\n",
      "Processed ISIC_0012316_segmentation.png\n",
      "Processed ISIC_0000500_segmentation.png\n",
      "Processed ISIC_0002107_segmentation.png\n",
      "Processed ISIC_0000380_segmentation.png\n",
      "Processed ISIC_0010334_segmentation.png\n",
      "Processed ISIC_0014754_segmentation.png\n",
      "Processed ISIC_0011378_segmentation.png\n",
      "Processed ISIC_0000520_segmentation.png\n",
      "Processed ISIC_0013747_segmentation.png\n",
      "Processed ISIC_0001181_segmentation.png\n",
      "Processed ISIC_0014099_segmentation.png\n",
      "Processed ISIC_0014680_segmentation.png\n",
      "Processed ISIC_0010024_segmentation.png\n",
      "Processed ISIC_0014108_segmentation.png\n",
      "Processed ISIC_0014834_segmentation.png\n",
      "Processed ISIC_0014989_segmentation.png\n",
      "Processed ISIC_0010236_segmentation.png\n",
      "Processed ISIC_0002206_segmentation.png\n",
      "Processed ISIC_0015483_segmentation.png\n",
      "Processed ISIC_0013414_segmentation.png\n",
      "Processed ISIC_0000066_segmentation.png\n",
      "Processed ISIC_0014832_segmentation.png\n",
      "Processed ISIC_0012878_segmentation.png\n",
      "Processed ISIC_0014723_segmentation.png\n",
      "Processed ISIC_0000162_segmentation.png\n",
      "Processed ISIC_0014486_segmentation.png\n",
      "Processed ISIC_0000518_segmentation.png\n",
      "Processed ISIC_0000132_segmentation.png\n",
      "Processed ISIC_0015951_segmentation.png\n",
      "Processed ISIC_0014974_segmentation.png\n",
      "Processed ISIC_0014829_segmentation.png\n",
      "Processed ISIC_0011385_segmentation.png\n",
      "Processed ISIC_0015973_segmentation.png\n",
      "Processed ISIC_0015971_segmentation.png\n",
      "Processed ISIC_0014518_segmentation.png\n",
      "Processed ISIC_0000418_segmentation.png\n",
      "Processed ISIC_0010487_segmentation.png\n",
      "Processed ISIC_0011168_segmentation.png\n",
      "Processed ISIC_0012679_segmentation.png\n",
      "Processed ISIC_0000201_segmentation.png\n",
      "Processed ISIC_0015960_segmentation.png\n",
      "Processed ISIC_0015146_segmentation.png\n",
      "Processed ISIC_0013684_segmentation.png\n",
      "Processed ISIC_0000532_segmentation.png\n",
      "Processed ISIC_0012469_segmentation.png\n",
      "Processed ISIC_0012744_segmentation.png\n",
      "Processed ISIC_0000343_segmentation.png\n",
      "Processed ISIC_0000554_segmentation.png\n",
      "Processed ISIC_0000094_segmentation.png\n",
      "Processed ISIC_0010053_segmentation.png\n",
      "Processed ISIC_0000239_segmentation.png\n",
      "Processed ISIC_0014707_segmentation.png\n",
      "Processed ISIC_0015019_segmentation.png\n",
      "Processed ISIC_0013983_segmentation.png\n",
      "Processed ISIC_0011082_segmentation.png\n",
      "Processed ISIC_0009960_segmentation.png\n",
      "Processed ISIC_0015174_segmentation.png\n",
      "Processed ISIC_0013643_segmentation.png\n",
      "Processed ISIC_0013898_segmentation.png\n",
      "Processed ISIC_0012213_segmentation.png\n",
      "Processed ISIC_0014779_segmentation.png\n",
      "Processed ISIC_0015161_segmentation.png\n",
      "Processed ISIC_0015994_segmentation.png\n",
      "Processed ISIC_0000307_segmentation.png\n",
      "Processed ISIC_0012684_segmentation.png\n",
      "Processed ISIC_0010175_segmentation.png\n",
      "Processed ISIC_0000327_segmentation.png\n",
      "Processed ISIC_0015256_segmentation.png\n",
      "Processed ISIC_0013606_segmentation.png\n",
      "Processed ISIC_0000533_segmentation.png\n",
      "Processed ISIC_0001185_segmentation.png\n",
      "Processed ISIC_0011127_segmentation.png\n",
      "Processed ISIC_0000009_segmentation.png\n",
      "Processed ISIC_0013201_segmentation.png\n",
      "Processed ISIC_0009891_segmentation.png\n",
      "Processed ISIC_0010330_segmentation.png\n",
      "Processed ISIC_0015270_segmentation.png\n",
      "Processed ISIC_0014941_segmentation.png\n",
      "Processed ISIC_0011163_segmentation.png\n",
      "Processed ISIC_0009921_segmentation.png\n",
      "Processed ISIC_0009987_segmentation.png\n",
      "Processed ISIC_0012496_segmentation.png\n",
      "Processed ISIC_0010488_segmentation.png\n",
      "Processed ISIC_0013070_segmentation.png\n",
      "Processed ISIC_0012710_segmentation.png\n",
      "Processed ISIC_0000065_segmentation.png\n",
      "Processed ISIC_0013635_segmentation.png\n",
      "Processed ISIC_0012990_segmentation.png\n",
      "Processed ISIC_0013232_segmentation.png\n",
      "Processed ISIC_0000060_segmentation.png\n",
      "Processed ISIC_0000071_segmentation.png\n",
      "Processed ISIC_0014684_segmentation.png\n",
      "Processed ISIC_0012358_segmentation.png\n",
      "Processed ISIC_0013599_segmentation.png\n",
      "Processed ISIC_0013428_segmentation.png\n",
      "Processed ISIC_0014872_segmentation.png\n",
      "Processed ISIC_0016046_segmentation.png\n",
      "Processed ISIC_0000260_segmentation.png\n",
      "Processed ISIC_0014169_segmentation.png\n",
      "Processed ISIC_0014687_segmentation.png\n",
      "Processed ISIC_0013342_segmentation.png\n",
      "Processed ISIC_0014803_segmentation.png\n",
      "Processed ISIC_0014955_segmentation.png\n",
      "Processed ISIC_0000410_segmentation.png\n",
      "Processed ISIC_0012356_segmentation.png\n",
      "Processed ISIC_0016068_segmentation.png\n",
      "Processed ISIC_0013879_segmentation.png\n",
      "Processed ISIC_0000525_segmentation.png\n",
      "Processed ISIC_0010553_segmentation.png\n",
      "Processed ISIC_0014926_segmentation.png\n",
      "Processed ISIC_0012435_segmentation.png\n",
      "Processed ISIC_0000506_segmentation.png\n",
      "Processed ISIC_0007344_segmentation.png\n",
      "Processed ISIC_0013817_segmentation.png\n",
      "Processed ISIC_0014851_segmentation.png\n",
      "Processed ISIC_0009939_segmentation.png\n",
      "Processed ISIC_0012844_segmentation.png\n",
      "Processed ISIC_0010174_segmentation.png\n",
      "Processed ISIC_0007760_segmentation.png\n",
      "Processed ISIC_0010177_segmentation.png\n",
      "Processed ISIC_0014438_segmentation.png\n",
      "Processed ISIC_0013114_segmentation.png\n",
      "Processed ISIC_0000179_segmentation.png\n",
      "Processed ISIC_0013580_segmentation.png\n",
      "Processed ISIC_0013842_segmentation.png\n",
      "Processed ISIC_0008347_segmentation.png\n",
      "Processed ISIC_0016036_segmentation.png\n",
      "Processed ISIC_0010075_segmentation.png\n",
      "Processed ISIC_0014835_segmentation.png\n",
      "Processed ISIC_0013988_segmentation.png\n",
      "Processed ISIC_0010073_segmentation.png\n",
      "Processed ISIC_0010056_segmentation.png\n",
      "Processed ISIC_0009925_segmentation.png\n",
      "Processed ISIC_0014410_segmentation.png\n",
      "Processed ISIC_0000231_segmentation.png\n",
      "Processed ISIC_0001213_segmentation.png\n",
      "Processed ISIC_0011322_segmentation.png\n",
      "Processed ISIC_0013554_segmentation.png\n",
      "Processed ISIC_0014139_segmentation.png\n",
      "Processed ISIC_0000115_segmentation.png\n",
      "Processed ISIC_0014238_segmentation.png\n",
      "Processed ISIC_0014171_segmentation.png\n",
      "Processed ISIC_0002975_segmentation.png\n",
      "Processed ISIC_0001212_segmentation.png\n",
      "Processed ISIC_0014217_segmentation.png\n",
      "Processed ISIC_0000091_segmentation.png\n",
      "Processed ISIC_0000531_segmentation.png\n",
      "Processed ISIC_0014883_segmentation.png\n",
      "Processed ISIC_0011123_segmentation.png\n",
      "Processed ISIC_0016052_segmentation.png\n",
      "Processed ISIC_0010010_segmentation.png\n",
      "Processed ISIC_0015219_segmentation.png\n",
      "Processed ISIC_0000444_segmentation.png\n",
      "Processed ISIC_0013203_segmentation.png\n",
      "Processed ISIC_0010340_segmentation.png\n",
      "Processed ISIC_0012487_segmentation.png\n",
      "Processed ISIC_0012700_segmentation.png\n",
      "Processed ISIC_0013518_segmentation.png\n",
      "Processed ISIC_0011101_segmentation.png\n",
      "Processed ISIC_0014558_segmentation.png\n",
      "Processed ISIC_0014392_segmentation.png\n",
      "Processed ISIC_0015980_segmentation.png\n",
      "Processed ISIC_0014605_segmentation.png\n",
      "Processed ISIC_0015593_segmentation.png\n",
      "Processed ISIC_0013178_segmentation.png\n",
      "Processed ISIC_0012656_segmentation.png\n",
      "Processed ISIC_0014708_segmentation.png\n",
      "Processed ISIC_0000185_segmentation.png\n",
      "Processed ISIC_0013948_segmentation.png\n",
      "Processed ISIC_0014891_segmentation.png\n",
      "Processed ISIC_0015582_segmentation.png\n",
      "Processed ISIC_0009297_segmentation.png\n",
      "Processed ISIC_0014535_segmentation.png\n",
      "Processed ISIC_0013835_segmentation.png\n",
      "Processed ISIC_0000403_segmentation.png\n",
      "Processed ISIC_0000182_segmentation.png\n",
      "Processed ISIC_0015937_segmentation.png\n",
      "Processed ISIC_0012898_segmentation.png\n",
      "Processed ISIC_0014545_segmentation.png\n",
      "Processed ISIC_0000184_segmentation.png\n",
      "Processed ISIC_0000096_segmentation.png\n",
      "Processed ISIC_0014795_segmentation.png\n",
      "Processed ISIC_0014964_segmentation.png\n",
      "Processed ISIC_0005187_segmentation.png\n",
      "Processed ISIC_0000078_segmentation.png\n",
      "Processed ISIC_0015440_segmentation.png\n",
      "Processed ISIC_0012672_segmentation.png\n",
      "Processed ISIC_0012657_segmentation.png\n",
      "Processed ISIC_0010576_segmentation.png\n",
      "Processed ISIC_0011390_segmentation.png\n",
      "Processed ISIC_0000221_segmentation.png\n",
      "Processed ISIC_0012266_segmentation.png\n",
      "Processed ISIC_0013071_segmentation.png\n",
      "Processed ISIC_0014077_segmentation.png\n",
      "Processed ISIC_0000049_segmentation.png\n",
      "Processed ISIC_0015485_segmentation.png\n",
      "Processed ISIC_0011098_segmentation.png\n",
      "Processed ISIC_0001163_segmentation.png\n",
      "Processed ISIC_0014797_segmentation.png\n",
      "Processed ISIC_0000457_segmentation.png\n",
      "Processed ISIC_0000442_segmentation.png\n",
      "Processed ISIC_0014739_segmentation.png\n",
      "Processed ISIC_0015056_segmentation.png\n",
      "Processed ISIC_0010357_segmentation.png\n",
      "Processed ISIC_0000067_segmentation.png\n",
      "Processed ISIC_0010069_segmentation.png\n",
      "Processed ISIC_0011300_segmentation.png\n",
      "Processed ISIC_0013325_segmentation.png\n",
      "Processed ISIC_0012223_segmentation.png\n",
      "Processed ISIC_0014080_segmentation.png\n",
      "Processed ISIC_0010581_segmentation.png\n",
      "Processed ISIC_0016072_segmentation.png\n",
      "Processed ISIC_0012177_segmentation.png\n",
      "Processed ISIC_0000058_segmentation.png\n",
      "Processed ISIC_0013865_segmentation.png\n",
      "Processed ISIC_0000463_segmentation.png\n",
      "Processed ISIC_0016034_segmentation.png\n",
      "Processed ISIC_0001960_segmentation.png\n",
      "Processed ISIC_0012666_segmentation.png\n",
      "Processed ISIC_0009298_segmentation.png\n",
      "Processed ISIC_0000240_segmentation.png\n",
      "Processed ISIC_0000247_segmentation.png\n",
      "Processed ISIC_0012250_segmentation.png\n",
      "Processed ISIC_0010189_segmentation.png\n",
      "Processed ISIC_0013836_segmentation.png\n",
      "Processed ISIC_0012741_segmentation.png\n",
      "Processed ISIC_0014286_segmentation.png\n",
      "Processed ISIC_0000264_segmentation.png\n",
      "Processed ISIC_0013896_segmentation.png\n",
      "Processed ISIC_0000449_segmentation.png\n",
      "Processed ISIC_0012167_segmentation.png\n",
      "Processed ISIC_0012227_segmentation.png\n",
      "Processed ISIC_0015956_segmentation.png\n",
      "Processed ISIC_0012475_segmentation.png\n",
      "Processed ISIC_0015965_segmentation.png\n",
      "Processed ISIC_0001190_segmentation.png\n",
      "Processed ISIC_0010235_segmentation.png\n",
      "Processed ISIC_0013997_segmentation.png\n",
      "Processed ISIC_0010205_segmentation.png\n",
      "Processed ISIC_0013219_segmentation.png\n",
      "Processed ISIC_0011373_segmentation.png\n",
      "Processed ISIC_0014013_segmentation.png\n",
      "Processed ISIC_0011367_segmentation.png\n",
      "Processed ISIC_0012323_segmentation.png\n",
      "Processed ISIC_0012235_segmentation.png\n",
      "Processed ISIC_0000121_segmentation.png\n",
      "Processed ISIC_0014821_segmentation.png\n",
      "Processed ISIC_0009950_segmentation.png\n",
      "Processed ISIC_0015559_segmentation.png\n",
      "Processed ISIC_0000447_segmentation.png\n",
      "Processed ISIC_0016017_segmentation.png\n",
      "Processed ISIC_0016066_segmentation.png\n",
      "Processed ISIC_0000471_segmentation.png\n",
      "Processed ISIC_0012685_segmentation.png\n",
      "Processed ISIC_0013982_segmentation.png\n",
      "Processed ISIC_0011204_segmentation.png\n",
      "Processed ISIC_0013356_segmentation.png\n",
      "Processed ISIC_0013427_segmentation.png\n",
      "Processed ISIC_0010463_segmentation.png\n",
      "Processed ISIC_0008029_segmentation.png\n",
      "Processed ISIC_0012271_segmentation.png\n",
      "Processed ISIC_0015023_segmentation.png\n",
      "Processed ISIC_0009889_segmentation.png\n",
      "Processed ISIC_0014156_segmentation.png\n",
      "Processed ISIC_0014958_segmentation.png\n",
      "Processed ISIC_0015193_segmentation.png\n",
      "Processed ISIC_0013813_segmentation.png\n",
      "Processed ISIC_0016042_segmentation.png\n",
      "Processed ISIC_0010183_segmentation.png\n",
      "Processed ISIC_0013104_segmentation.png\n",
      "Processed ISIC_0000095_segmentation.png\n",
      "Processed ISIC_0001275_segmentation.png\n",
      "Processed ISIC_0013782_segmentation.png\n",
      "Processed ISIC_0010231_segmentation.png\n",
      "Processed ISIC_0000198_segmentation.png\n",
      "Processed ISIC_0013815_segmentation.png\n",
      "Processed ISIC_0000514_segmentation.png\n",
      "Processed ISIC_0013910_segmentation.png\n",
      "Processed ISIC_0000112_segmentation.png\n",
      "Processed ISIC_0000311_segmentation.png\n",
      "Processed ISIC_0014800_segmentation.png\n",
      "Processed ISIC_0009970_segmentation.png\n",
      "Processed ISIC_0000361_segmentation.png\n",
      "Processed ISIC_0015412_segmentation.png\n",
      "Processed ISIC_0012773_segmentation.png\n",
      "Processed ISIC_0000496_segmentation.png\n",
      "Processed ISIC_0013121_segmentation.png\n",
      "Processed ISIC_0015309_segmentation.png\n",
      "Processed ISIC_0010239_segmentation.png\n",
      "Processed ISIC_0013433_segmentation.png\n",
      "Processed ISIC_0013248_segmentation.png\n",
      "Processed ISIC_0011140_segmentation.png\n",
      "Processed ISIC_0010570_segmentation.png\n",
      "Processed ISIC_0008879_segmentation.png\n",
      "Processed ISIC_0014178_segmentation.png\n",
      "Processed ISIC_0000261_segmentation.png\n",
      "Processed ISIC_0010350_segmentation.png\n",
      "Processed ISIC_0012381_segmentation.png\n",
      "Processed ISIC_0010603_segmentation.png\n",
      "Processed ISIC_0011135_segmentation.png\n",
      "Processed ISIC_0009954_segmentation.png\n",
      "Processed ISIC_0013862_segmentation.png\n",
      "Processed ISIC_0013967_segmentation.png\n",
      "Processed ISIC_0015969_segmentation.png\n",
      "Processed ISIC_0007796_segmentation.png\n",
      "Processed ISIC_0000364_segmentation.png\n",
      "Processed ISIC_0000192_segmentation.png\n",
      "Processed ISIC_0010483_segmentation.png\n",
      "Processed ISIC_0000111_segmentation.png\n",
      "Processed ISIC_0014815_segmentation.png\n",
      "Processed ISIC_0013721_segmentation.png\n",
      "Processed ISIC_0012705_segmentation.png\n",
      "Processed ISIC_0000213_segmentation.png\n",
      "Processed ISIC_0013667_segmentation.png\n",
      "Processed ISIC_0015157_segmentation.png\n",
      "Processed ISIC_0014541_segmentation.png\n",
      "Processed ISIC_0000515_segmentation.png\n",
      "Processed ISIC_0014720_segmentation.png\n",
      "Processed ISIC_0000451_segmentation.png\n",
      "Processed ISIC_0014189_segmentation.png\n",
      "Processed ISIC_0000513_segmentation.png\n",
      "Processed ISIC_0013411_segmentation.png\n",
      "Processed ISIC_0000519_segmentation.png\n",
      "Processed ISIC_0010022_segmentation.png\n",
      "Processed ISIC_0013010_segmentation.png\n",
      "Processed ISIC_0000255_segmentation.png\n",
      "Processed ISIC_0012661_segmentation.png\n",
      "Processed ISIC_0013220_segmentation.png\n",
      "Processed ISIC_0010380_segmentation.png\n",
      "Processed ISIC_0014601_segmentation.png\n",
      "Processed ISIC_0004115_segmentation.png\n",
      "Processed ISIC_0015250_segmentation.png\n",
      "Processed ISIC_0000306_segmentation.png\n",
      "Processed ISIC_0008552_segmentation.png\n",
      "Processed ISIC_0009993_segmentation.png\n",
      "Processed ISIC_0012395_segmentation.png\n",
      "Processed ISIC_0008785_segmentation.png\n",
      "Processed ISIC_0000126_segmentation.png\n",
      "Processed ISIC_0016000_segmentation.png\n",
      "Processed ISIC_0014931_segmentation.png\n",
      "Processed ISIC_0013438_segmentation.png\n",
      "Processed ISIC_0012134_segmentation.png\n",
      "Processed ISIC_0013320_segmentation.png\n",
      "Processed ISIC_0010333_segmentation.png\n",
      "Processed ISIC_0004168_segmentation.png\n",
      "Processed ISIC_0000210_segmentation.png\n",
      "Processed ISIC_0015142_segmentation.png\n",
      "Processed ISIC_0009917_segmentation.png\n",
      "Processed ISIC_0015544_segmentation.png\n",
      "Processed ISIC_0013922_segmentation.png\n",
      "Processed ISIC_0014661_segmentation.png\n",
      "Processed ISIC_0014854_segmentation.png\n",
      "Processed ISIC_0009533_segmentation.png\n",
      "Processed ISIC_0013695_segmentation.png\n",
      "Processed ISIC_0008998_segmentation.png\n",
      "Processed ISIC_0012335_segmentation.png\n",
      "Processed ISIC_0000141_segmentation.png\n",
      "Processed ISIC_0016003_segmentation.png\n",
      "Processed ISIC_0000314_segmentation.png\n",
      "Processed ISIC_0010455_segmentation.png\n",
      "Processed ISIC_0014632_segmentation.png\n",
      "Processed ISIC_0014922_segmentation.png\n",
      "Processed ISIC_0014640_segmentation.png\n",
      "Processed ISIC_0012332_segmentation.png\n",
      "Processed ISIC_0011129_segmentation.png\n",
      "Processed ISIC_0014144_segmentation.png\n",
      "Processed ISIC_0014994_segmentation.png\n",
      "Processed ISIC_0001142_segmentation.png\n",
      "Processed ISIC_0013039_segmentation.png\n",
      "Processed ISIC_0013181_segmentation.png\n",
      "Processed ISIC_0013908_segmentation.png\n",
      "Processed ISIC_0010849_segmentation.png\n",
      "Processed ISIC_0013558_segmentation.png\n",
      "Processed ISIC_0000047_segmentation.png\n",
      "Processed ISIC_0013929_segmentation.png\n",
      "Processed ISIC_0000212_segmentation.png\n",
      "Processed ISIC_0010554_segmentation.png\n",
      "Processed ISIC_0015998_segmentation.png\n",
      "Processed ISIC_0013801_segmentation.png\n",
      "Processed ISIC_0002806_segmentation.png\n",
      "Processed ISIC_0010318_segmentation.png\n",
      "Processed ISIC_0000549_segmentation.png\n",
      "Processed ISIC_0014666_segmentation.png\n",
      "Processed ISIC_0013393_segmentation.png\n",
      "Processed ISIC_0012677_segmentation.png\n",
      "Processed ISIC_0012230_segmentation.png\n",
      "Processed ISIC_0010029_segmentation.png\n",
      "Processed ISIC_0011210_segmentation.png\n",
      "Processed ISIC_0013778_segmentation.png\n",
      "Processed ISIC_0012116_segmentation.png\n",
      "Processed ISIC_0000133_segmentation.png\n",
      "Processed ISIC_0015241_segmentation.png\n",
      "Processed ISIC_0014929_segmentation.png\n",
      "Processed ISIC_0011317_segmentation.png\n",
      "Processed ISIC_0014062_segmentation.png\n",
      "Processed ISIC_0016038_segmentation.png\n",
      "Processed ISIC_0012877_segmentation.png\n",
      "Processed ISIC_0000279_segmentation.png\n",
      "Processed ISIC_0014730_segmentation.png\n",
      "Processed ISIC_0013672_segmentation.png\n",
      "Processed ISIC_0014543_segmentation.png\n",
      "Processed ISIC_0009928_segmentation.png\n",
      "Processed ISIC_0000507_segmentation.png\n",
      "Processed ISIC_0014290_segmentation.png\n",
      "Processed ISIC_0016006_segmentation.png\n",
      "Processed ISIC_0013383_segmentation.png\n",
      "Processed ISIC_0000379_segmentation.png\n",
      "Processed ISIC_0010854_segmentation.png\n",
      "Processed ISIC_0013146_segmentation.png\n",
      "Processed ISIC_0011110_segmentation.png\n",
      "Processed ISIC_0013109_segmentation.png\n",
      "Processed ISIC_0014716_segmentation.png\n",
      "Processed ISIC_0013456_segmentation.png\n",
      "Processed ISIC_0000491_segmentation.png\n",
      "Processed ISIC_0015040_segmentation.png\n",
      "Processed ISIC_0012949_segmentation.png\n",
      "Processed ISIC_0000042_segmentation.png\n",
      "Processed ISIC_0012719_segmentation.png\n",
      "Processed ISIC_0011124_segmentation.png\n",
      "Processed ISIC_0004309_segmentation.png\n",
      "Processed ISIC_0013371_segmentation.png\n",
      "Processed ISIC_0004985_segmentation.png\n",
      "Processed ISIC_0015999_segmentation.png\n",
      "Processed ISIC_0012325_segmentation.png\n",
      "Processed ISIC_0012999_segmentation.png\n",
      "Processed ISIC_0012682_segmentation.png\n",
      "Processed ISIC_0000028_segmentation.png\n",
      "Processed ISIC_0012777_segmentation.png\n",
      "Processed ISIC_0013733_segmentation.png\n",
      "Processed ISIC_0001216_segmentation.png\n",
      "Processed ISIC_0000063_segmentation.png\n",
      "Processed ISIC_0012143_segmentation.png\n",
      "Processed ISIC_0013163_segmentation.png\n",
      "Processed ISIC_0013048_segmentation.png\n",
      "Processed ISIC_0011107_segmentation.png\n",
      "Processed ISIC_0013984_segmentation.png\n",
      "Processed ISIC_0013315_segmentation.png\n",
      "Processed ISIC_0013766_segmentation.png\n",
      "Processed ISIC_0012544_segmentation.png\n",
      "Processed ISIC_0000164_segmentation.png\n",
      "Processed ISIC_0014382_segmentation.png\n",
      "Processed ISIC_0012658_segmentation.png\n",
      "Processed ISIC_0013713_segmentation.png\n",
      "Processed ISIC_0011130_segmentation.png\n",
      "Processed ISIC_0012683_segmentation.png\n",
      "Processed ISIC_0014943_segmentation.png\n",
      "Processed ISIC_0005787_segmentation.png\n",
      "Processed ISIC_0013166_segmentation.png\n",
      "Processed ISIC_0008145_segmentation.png\n",
      "Processed ISIC_0000340_segmentation.png\n",
      "Processed ISIC_0012164_segmentation.png\n",
      "Processed ISIC_0000154_segmentation.png\n",
      "Processed ISIC_0000524_segmentation.png\n",
      "Processed ISIC_0000040_segmentation.png\n",
      "Processed ISIC_0014633_segmentation.png\n",
      "Processed ISIC_0012675_segmentation.png\n",
      "Processed ISIC_0000381_segmentation.png\n",
      "Processed ISIC_0015436_segmentation.png\n",
      "Processed ISIC_0000503_segmentation.png\n",
      "Processed ISIC_0011117_segmentation.png\n",
      "Processed ISIC_0014785_segmentation.png\n",
      "Processed ISIC_0000101_segmentation.png\n",
      "Processed ISIC_0012447_segmentation.png\n",
      "Processed ISIC_0013222_segmentation.png\n",
      "Processed ISIC_0011301_segmentation.png\n",
      "Processed ISIC_0014457_segmentation.png\n",
      "Processed ISIC_0010186_segmentation.png\n",
      "Processed ISIC_0010171_segmentation.png\n",
      "Processed ISIC_0011363_segmentation.png\n",
      "Processed ISIC_0015216_segmentation.png\n",
      "Processed ISIC_0000044_segmentation.png\n",
      "Processed ISIC_0000099_segmentation.png\n",
      "Processed ISIC_0000534_segmentation.png\n",
      "Processed ISIC_0012720_segmentation.png\n",
      "Processed ISIC_0010255_segmentation.png\n",
      "Processed ISIC_0000342_segmentation.png\n",
      "Processed ISIC_0010494_segmentation.png\n",
      "Processed ISIC_0015568_segmentation.png\n",
      "Processed ISIC_0010267_segmentation.png\n",
      "Processed ISIC_0012232_segmentation.png\n",
      "Processed ISIC_0010587_segmentation.png\n",
      "Processed ISIC_0010591_segmentation.png\n",
      "Processed ISIC_0015986_segmentation.png\n",
      "Processed ISIC_0008992_segmentation.png\n",
      "Processed ISIC_0015283_segmentation.png\n",
      "Processed ISIC_0013473_segmentation.png\n",
      "Processed ISIC_0012880_segmentation.png\n",
      "Processed ISIC_0014775_segmentation.png\n",
      "Processed ISIC_0015255_segmentation.png\n",
      "Processed ISIC_0013561_segmentation.png\n",
      "Processed ISIC_0015464_segmentation.png\n",
      "Processed ISIC_0013072_segmentation.png\n",
      "Processed ISIC_0011213_segmentation.png\n",
      "Processed ISIC_0009165_segmentation.png\n",
      "Processed ISIC_0001184_segmentation.png\n",
      "Processed ISIC_0000129_segmentation.png\n",
      "Processed ISIC_0013596_segmentation.png\n",
      "Processed ISIC_0003308_segmentation.png\n",
      "Processed ISIC_0013696_segmentation.png\n",
      "Processed ISIC_0013585_segmentation.png\n",
      "Processed ISIC_0016045_segmentation.png\n",
      "Processed ISIC_0013917_segmentation.png\n",
      "Processed ISIC_0014094_segmentation.png\n",
      "Processed ISIC_0013897_segmentation.png\n",
      "Processed ISIC_0014600_segmentation.png\n",
      "Processed ISIC_0011382_segmentation.png\n",
      "Processed ISIC_0011219_segmentation.png\n",
      "Processed ISIC_0000487_segmentation.png\n",
      "Processed ISIC_0016028_segmentation.png\n",
      "Processed ISIC_0000477_segmentation.png\n",
      "Processed ISIC_0014190_segmentation.png\n",
      "Processed ISIC_0014945_segmentation.png\n",
      "Processed ISIC_0013197_segmentation.png\n",
      "Processed ISIC_0013491_segmentation.png\n",
      "Processed ISIC_0000508_segmentation.png\n",
      "Processed ISIC_0013828_segmentation.png\n",
      "Processed ISIC_0014998_segmentation.png\n",
      "Processed ISIC_0013196_segmentation.png\n",
      "Processed ISIC_0013597_segmentation.png\n",
      "Processed ISIC_0014688_segmentation.png\n",
      "Processed ISIC_0013128_segmentation.png\n",
      "Processed ISIC_0006612_segmentation.png\n",
      "Processed ISIC_0000123_segmentation.png\n",
      "Processed ISIC_0002251_segmentation.png\n",
      "Processed ISIC_0000022_segmentation.png\n",
      "Processed ISIC_0010228_segmentation.png\n",
      "Processed ISIC_0009962_segmentation.png\n",
      "Processed ISIC_0010379_segmentation.png\n",
      "Processed ISIC_0010201_segmentation.png\n",
      "Processed ISIC_0000055_segmentation.png\n",
      "Processed ISIC_0003657_segmentation.png\n",
      "Processed ISIC_0013052_segmentation.png\n",
      "Processed ISIC_0013891_segmentation.png\n",
      "Processed ISIC_0006815_segmentation.png\n",
      "Processed ISIC_0012248_segmentation.png\n",
      "Processed ISIC_0000097_segmentation.png\n",
      "Processed ISIC_0010856_segmentation.png\n",
      "Processed ISIC_0012653_segmentation.png\n",
      "Processed ISIC_0013758_segmentation.png\n",
      "Processed ISIC_0010213_segmentation.png\n",
      "Processed ISIC_0011088_segmentation.png\n",
      "Processed ISIC_0014658_segmentation.png\n",
      "Processed ISIC_0014221_segmentation.png\n",
      "Processed ISIC_0012260_segmentation.png\n",
      "Processed ISIC_0015208_segmentation.png\n",
      "Processed ISIC_0010064_segmentation.png\n",
      "Processed ISIC_0000489_segmentation.png\n",
      "Processed ISIC_0010212_segmentation.png\n",
      "Processed ISIC_0010182_segmentation.png\n",
      "Processed ISIC_0012884_segmentation.png\n",
      "Processed ISIC_0001442_segmentation.png\n",
      "Processed ISIC_0015312_segmentation.png\n",
      "Processed ISIC_0014725_segmentation.png\n",
      "Processed ISIC_0000012_segmentation.png\n",
      "Processed ISIC_0014623_segmentation.png\n",
      "Processed ISIC_0001152_segmentation.png\n",
      "Processed ISIC_0001296_segmentation.png\n",
      "Processed ISIC_0009899_segmentation.png\n",
      "Processed ISIC_0011361_segmentation.png\n",
      "Processed ISIC_0014667_segmentation.png\n",
      "Processed ISIC_0014181_segmentation.png\n",
      "Processed ISIC_0012873_segmentation.png\n",
      "Processed ISIC_0000074_segmentation.png\n",
      "Processed ISIC_0016008_segmentation.png\n",
      "Processed ISIC_0015127_segmentation.png\n",
      "Processed ISIC_0013789_segmentation.png\n",
      "Processed ISIC_0012090_segmentation.png\n",
      "Processed ISIC_0010088_segmentation.png\n",
      "Processed ISIC_0010336_segmentation.png\n",
      "Processed ISIC_0010496_segmentation.png\n",
      "Processed ISIC_0014066_segmentation.png\n",
      "Processed ISIC_0015447_segmentation.png\n",
      "Processed ISIC_0000492_segmentation.png\n",
      "Processed ISIC_0014397_segmentation.png\n",
      "Processed ISIC_0014957_segmentation.png\n",
      "Processed ISIC_0012539_segmentation.png\n",
      "Processed ISIC_0014158_segmentation.png\n",
      "Processed ISIC_0009978_segmentation.png\n",
      "Processed ISIC_0012127_segmentation.png\n",
      "Processed ISIC_0015009_segmentation.png\n",
      "Processed ISIC_0013330_segmentation.png\n",
      "Processed ISIC_0000366_segmentation.png\n",
      "Processed ISIC_0010086_segmentation.png\n",
      "Processed ISIC_0013796_segmentation.png\n",
      "Processed ISIC_0009927_segmentation.png\n",
      "Processed ISIC_0000368_segmentation.png\n",
      "Processed ISIC_0014925_segmentation.png\n",
      "Processed ISIC_0011384_segmentation.png\n",
      "Processed ISIC_0013490_segmentation.png\n",
      "Processed ISIC_0014299_segmentation.png\n",
      "Processed ISIC_0015368_segmentation.png\n",
      "Processed ISIC_0015139_segmentation.png\n",
      "Processed ISIC_0012238_segmentation.png\n",
      "Processed ISIC_0000120_segmentation.png\n",
      "Processed ISIC_0012284_segmentation.png\n",
      "Processed ISIC_0010443_segmentation.png\n",
      "Processed ISIC_0013192_segmentation.png\n",
      "Processed ISIC_0000018_segmentation.png\n",
      "Processed ISIC_0013942_segmentation.png\n",
      "Processed ISIC_0002246_segmentation.png\n",
      "Processed ISIC_0013335_segmentation.png\n",
      "Processed ISIC_0013024_segmentation.png\n",
      "Processed ISIC_0000455_segmentation.png\n",
      "Processed ISIC_0009881_segmentation.png\n",
      "Processed ISIC_0012678_segmentation.png\n",
      "Processed ISIC_0014255_segmentation.png\n",
      "Processed ISIC_0014574_segmentation.png\n",
      "Processed ISIC_0012690_segmentation.png\n",
      "Processed ISIC_0013001_segmentation.png\n",
      "Processed ISIC_0012704_segmentation.png\n",
      "Processed ISIC_0000480_segmentation.png\n",
      "Processed ISIC_0012105_segmentation.png\n",
      "Processed ISIC_0012207_segmentation.png\n",
      "Processed ISIC_0010335_segmentation.png\n",
      "Processed ISIC_0009898_segmentation.png\n",
      "Processed ISIC_0013378_segmentation.png\n",
      "Processed ISIC_0015125_segmentation.png\n",
      "Processed ISIC_0015390_segmentation.png\n",
      "Processed ISIC_0016024_segmentation.png\n",
      "Processed ISIC_0012208_segmentation.png\n",
      "Processed ISIC_0013806_segmentation.png\n",
      "Processed ISIC_0014765_segmentation.png\n",
      "Processed ISIC_0015403_segmentation.png\n",
      "Processed ISIC_0012086_segmentation.png\n",
      "Processed ISIC_0014475_segmentation.png\n",
      "Processed ISIC_0000138_segmentation.png\n",
      "Processed ISIC_0016057_segmentation.png\n",
      "Processed ISIC_0000025_segmentation.png\n",
      "Processed ISIC_0014537_segmentation.png\n",
      "Processed ISIC_0009949_segmentation.png\n",
      "Processed ISIC_0000107_segmentation.png\n",
      "Processed ISIC_0014844_segmentation.png\n",
      "Processed ISIC_0014820_segmentation.png\n",
      "Processed ISIC_0000166_segmentation.png\n",
      "Processed ISIC_0010857_segmentation.png\n",
      "Processed ISIC_0000140_segmentation.png\n",
      "Processed ISIC_0009934_segmentation.png\n",
      "Processed ISIC_0015603_segmentation.png\n",
      "Processed ISIC_0011114_segmentation.png\n",
      "Processed ISIC_0013425_segmentation.png\n",
      "Processed ISIC_0012547_segmentation.png\n",
      "Processed ISIC_0015939_segmentation.png\n",
      "Processed ISIC_0011097_segmentation.png\n",
      "Processed ISIC_0012676_segmentation.png\n",
      "Processed ISIC_0000413_segmentation.png\n",
      "Processed ISIC_0000145_segmentation.png\n",
      "Processed ISIC_0014628_segmentation.png\n",
      "Processed ISIC_0014490_segmentation.png\n",
      "Processed ISIC_0010347_segmentation.png\n",
      "Processed ISIC_0012102_segmentation.png\n",
      "Processed ISIC_0009909_segmentation.png\n",
      "Processed ISIC_0007038_segmentation.png\n",
      "Processed ISIC_0007322_segmentation.png\n",
      "Processed ISIC_0013803_segmentation.png\n",
      "Processed ISIC_0010459_segmentation.png\n",
      "Processed ISIC_0012245_segmentation.png\n",
      "Processed ISIC_0012357_segmentation.png\n",
      "Processed ISIC_0002093_segmentation.png\n",
      "Processed ISIC_0013636_segmentation.png\n",
      "Processed ISIC_0000535_segmentation.png\n",
      "Processed ISIC_0014693_segmentation.png\n",
      "Processed ISIC_0015109_segmentation.png\n",
      "Processed ISIC_0010028_segmentation.png\n",
      "Processed ISIC_0013639_segmentation.png\n",
      "Processed ISIC_0013274_segmentation.png\n",
      "Processed ISIC_0013120_segmentation.png\n",
      "Processed ISIC_0013795_segmentation.png\n",
      "Processed ISIC_0010552_segmentation.png\n",
      "Processed ISIC_0012282_segmentation.png\n",
      "Processed ISIC_0010448_segmentation.png\n",
      "Processed ISIC_0012233_segmentation.png\n",
      "Processed ISIC_0000161_segmentation.png\n",
      "Processed ISIC_0015276_segmentation.png\n",
      "Processed ISIC_0011397_segmentation.png\n",
      "Processed ISIC_0014317_segmentation.png\n",
      "Processed ISIC_0010596_segmentation.png\n",
      "Processed ISIC_0014044_segmentation.png\n",
      "Processed ISIC_0005555_segmentation.png\n",
      "Processed ISIC_0001267_segmentation.png\n",
      "Processed ISIC_0013212_segmentation.png\n",
      "Processed ISIC_0010358_segmentation.png\n",
      "Processed ISIC_0014248_segmentation.png\n",
      "Processed ISIC_0014748_segmentation.png\n",
      "Processed ISIC_0014919_segmentation.png\n",
      "Processed ISIC_0000434_segmentation.png\n",
      "Processed ISIC_0014846_segmentation.png\n",
      "Processed ISIC_0015481_segmentation.png\n",
      "Processed ISIC_0014968_segmentation.png\n",
      "Processed ISIC_0011220_segmentation.png\n",
      "Processed ISIC_0014904_segmentation.png\n",
      "Processed ISIC_0012711_segmentation.png\n",
      "Processed ISIC_0000330_segmentation.png\n",
      "Processed ISIC_0014433_segmentation.png\n",
      "Processed ISIC_0013691_segmentation.png\n",
      "Processed ISIC_0009880_segmentation.png\n",
      "Processed ISIC_0009201_segmentation.png\n",
      "Processed ISIC_0014506_segmentation.png\n",
      "Processed ISIC_0013398_segmentation.png\n",
      "Processed ISIC_0001191_segmentation.png\n",
      "Processed ISIC_0000075_segmentation.png\n",
      "Processed ISIC_0012674_segmentation.png\n",
      "Processed ISIC_0012739_segmentation.png\n",
      "Processed ISIC_0007332_segmentation.png\n",
      "Processed ISIC_0014790_segmentation.png\n",
      "Processed ISIC_0013294_segmentation.png\n",
      "Processed ISIC_0013678_segmentation.png\n",
      "Processed ISIC_0013242_segmentation.png\n",
      "Processed ISIC_0010054_segmentation.png\n",
      "Processed ISIC_0013112_segmentation.png\n",
      "Processed ISIC_0010015_segmentation.png\n",
      "Processed ISIC_0002459_segmentation.png\n",
      "Processed ISIC_0015179_segmentation.png\n",
      "Processed ISIC_0000203_segmentation.png\n",
      "Processed ISIC_0016019_segmentation.png\n",
      "Processed ISIC_0013189_segmentation.png\n",
      "Processed ISIC_0012887_segmentation.png\n",
      "Processed ISIC_0010225_segmentation.png\n",
      "Processed ISIC_0000142_segmentation.png\n",
      "Processed ISIC_0000150_segmentation.png\n",
      "Processed ISIC_0012333_segmentation.png\n",
      "Processed ISIC_0012400_segmentation.png\n",
      "Processed ISIC_0002976_segmentation.png\n",
      "Processed ISIC_0011081_segmentation.png\n",
      "Processed ISIC_0014133_segmentation.png\n",
      "Processed ISIC_0013995_segmentation.png\n",
      "Processed ISIC_0021714_segmentation.png\n",
      "Processed ISIC_0015590_segmentation.png\n",
      "Processed ISIC_0017398_segmentation.png\n",
      "Processed ISIC_0019334_segmentation.png\n",
      "Processed ISIC_0020233_segmentation.png\n",
      "Processed ISIC_0020861_segmentation.png\n",
      "Processed ISIC_0012585_segmentation.png\n",
      "Processed ISIC_0021202_segmentation.png\n",
      "Processed ISIC_0022221_segmentation.png\n",
      "Processed ISIC_0021449_segmentation.png\n",
      "Processed ISIC_0012627_segmentation.png\n",
      "Processed ISIC_0023936_segmentation.png\n",
      "Processed ISIC_0018179_segmentation.png\n",
      "Processed ISIC_0017474_segmentation.png\n",
      "Processed ISIC_0036073_segmentation.png\n",
      "Processed ISIC_0021152_segmentation.png\n",
      "Processed ISIC_0019309_segmentation.png\n",
      "Processed ISIC_0036333_segmentation.png\n",
      "Processed ISIC_0036206_segmentation.png\n",
      "Processed ISIC_0023508_segmentation.png\n",
      "Processed ISIC_0018556_segmentation.png\n",
      "Processed ISIC_0021251_segmentation.png\n",
      "Processed ISIC_0012633_segmentation.png\n",
      "Processed ISIC_0018248_segmentation.png\n",
      "Processed ISIC_0018521_segmentation.png\n",
      "Processed ISIC_0019794_segmentation.png\n",
      "Processed ISIC_0036236_segmentation.png\n",
      "Processed ISIC_0022039_segmentation.png\n",
      "Processed ISIC_0021914_segmentation.png\n",
      "Processed ISIC_0017399_segmentation.png\n",
      "Processed ISIC_0015518_segmentation.png\n",
      "Processed ISIC_0023904_segmentation.png\n",
      "Processed ISIC_0012576_segmentation.png\n",
      "Processed ISIC_0020953_segmentation.png\n",
      "Processed ISIC_0017460_segmentation.png\n",
      "Processed ISIC_0017341_segmentation.png\n",
      "Processed ISIC_0018680_segmentation.png\n",
      "Processed ISIC_0036281_segmentation.png\n",
      "Processed ISIC_0023924_segmentation.png\n",
      "Processed ISIC_0021158_segmentation.png\n",
      "Processed ISIC_0036101_segmentation.png\n",
      "Processed ISIC_0015370_segmentation.png\n",
      "Processed ISIC_0022192_segmentation.png\n",
      "Processed ISIC_0024135_segmentation.png\n",
      "Processed ISIC_0021762_segmentation.png\n",
      "Processed ISIC_0023678_segmentation.png\n",
      "Processed ISIC_0015480_segmentation.png\n",
      "Processed ISIC_0036306_segmentation.png\n",
      "Processed ISIC_0012346_segmentation.png\n",
      "Processed ISIC_0023900_segmentation.png\n",
      "Processed ISIC_0018611_segmentation.png\n",
      "Processed ISIC_0022657_segmentation.png\n",
      "Processed ISIC_0022029_segmentation.png\n",
      "Processed ISIC_0021041_segmentation.png\n",
      "Processed ISIC_0016804_segmentation.png\n",
      "Processed ISIC_0036247_segmentation.png\n",
      "Processed ISIC_0021904_segmentation.png\n",
      "Processed ISIC_0017702_segmentation.png\n",
      "Processed ISIC_0017755_segmentation.png\n",
      "Processed ISIC_0036321_segmentation.png\n",
      "Processed ISIC_0020418_segmentation.png\n",
      "Processed ISIC_0019723_segmentation.png\n",
      "Processed ISIC_0036098_segmentation.png\n",
      "Processed ISIC_0036237_segmentation.png\n",
      "Processed ISIC_0036085_segmentation.png\n",
      "Processed ISIC_0015492_segmentation.png\n",
      "Processed ISIC_0022738_segmentation.png\n",
      "Processed ISIC_0018472_segmentation.png\n",
      "Processed ISIC_0023371_segmentation.png\n",
      "Processed ISIC_0018111_segmentation.png\n",
      "Processed ISIC_0018375_segmentation.png\n",
      "Processed ISIC_0012255_segmentation.png\n",
      "Processed ISIC_0015634_segmentation.png\n",
      "Processed ISIC_0023628_segmentation.png\n",
      "Processed ISIC_0016714_segmentation.png\n",
      "Processed ISIC_0020999_segmentation.png\n",
      "Processed ISIC_0036328_segmentation.png\n",
      "Processed ISIC_0015351_segmentation.png\n",
      "Processed ISIC_0022147_segmentation.png\n",
      "Processed ISIC_0021037_segmentation.png\n",
      "Processed ISIC_0015294_segmentation.png\n",
      "Processed ISIC_0021504_segmentation.png\n",
      "Processed ISIC_0015552_segmentation.png\n",
      "Processed ISIC_0019883_segmentation.png\n",
      "Processed ISIC_0023831_segmentation.png\n",
      "Processed ISIC_0036291_segmentation.png\n",
      "Processed ISIC_0012643_segmentation.png\n",
      "Processed ISIC_0036174_segmentation.png\n",
      "Processed ISIC_0020893_segmentation.png\n",
      "Processed ISIC_0015462_segmentation.png\n",
      "Processed ISIC_0021816_segmentation.png\n",
      "Processed ISIC_0012623_segmentation.png\n",
      "Processed ISIC_0016351_segmentation.png\n",
      "Processed ISIC_0036121_segmentation.png\n",
      "Processed ISIC_0023755_segmentation.png\n",
      "Processed ISIC_0036147_segmentation.png\n",
      "Processed ISIC_0021448_segmentation.png\n",
      "Processed ISIC_0021990_segmentation.png\n",
      "Processed ISIC_0019049_segmentation.png\n",
      "Processed ISIC_0036240_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "# convert to format that mmseg recognise\n",
    "# we assign value = 0 as background, value = 1 as class 1 which is lesion\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mask_dir = 'ISIC/annotations/training'\n",
    "\n",
    "for mask_file in os.listdir(mask_dir):\n",
    "    if mask_file.endswith('.png'):\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #mask[mask == 0] = 0\n",
    "        mask[mask == 255] = 1\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "        print(f\"Processed {mask_file}\")\n",
    "\n",
    "mask_dir = 'ISIC/annotations/validation'\n",
    "\n",
    "for mask_file in os.listdir(mask_dir):\n",
    "    if mask_file.endswith('.png'):\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #mask[mask == 0] = 0\n",
    "        mask[mask == 255] = 1\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "        print(f\"Processed {mask_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We download the pre-trained checkpoints for inference and finetuning.\n",
    "!mkdir ./checkpoint\n",
    "!mkdir ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing mask2former_r50_8xb2-160k_ade20k-512x512...\n",
      "\u001b[2Kdownloading \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 MiB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[32mSuccessfully downloaded mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth to /home/test/carasml/segmentation/Mask2former/mmsegmentation/checkpoint\u001b[0m\n",
      "\u001b[32mSuccessfully dumped mask2former_r50_8xb2-160k_ade20k-512x512.py to /home/test/carasml/segmentation/Mask2former/mmsegmentation/checkpoint\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mim download mmsegmentation --config mask2former_r50_8xb2-160k_ade20k-512x512 --dest ./checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mydataset data format\n",
    "config = \"\"\"\n",
    "from mmseg.registry import DATASETS\n",
    "from .basesegdataset import BaseSegDataset\n",
    "\n",
    "@DATASETS.register_module() \n",
    "class mydataset(BaseSegDataset):\n",
    "    METAINFO = {\n",
    "        'classes': ['background','lesion'], # first one is background, and second and so on are our classes\n",
    "        'palette': [[0, 0, 0], [0, 255, 0]], # assign color to visualize\n",
    "    } \n",
    "    def __init__(self, **kwargs): \n",
    "        super(mydataset, self).__init__( \n",
    "            img_suffix='.jpg', # suffix of image\n",
    "            seg_map_suffix='_segmentation.png', # suffix of segmentation annotation\n",
    "            reduce_zero_label=False, \n",
    "            **kwargs) \n",
    "\"\"\"\n",
    "# here we create the config file\n",
    "with open('./mmseg/datasets/mydataset.py', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mydataset to dataset format. after running this, reload the kernal\n",
    "config = \"\"\"\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "# yapf: disable\n",
    "from .ade import ADE20KDataset\n",
    "from .basesegdataset import BaseCDDataset, BaseSegDataset\n",
    "from .bdd100k import BDD100KDataset\n",
    "from .chase_db1 import ChaseDB1Dataset\n",
    "from .cityscapes import CityscapesDataset\n",
    "from .coco_stuff import COCOStuffDataset\n",
    "from .dark_zurich import DarkZurichDataset\n",
    "from .dataset_wrappers import MultiImageMixDataset\n",
    "from .decathlon import DecathlonDataset\n",
    "from .drive import DRIVEDataset\n",
    "from .dsdl import DSDLSegDataset\n",
    "from .hrf import HRFDataset\n",
    "from .isaid import iSAIDDataset\n",
    "from .isprs import ISPRSDataset\n",
    "from .levir import LEVIRCDDataset\n",
    "from .lip import LIPDataset\n",
    "from .loveda import LoveDADataset\n",
    "from .mapillary import MapillaryDataset_v1, MapillaryDataset_v2\n",
    "from .night_driving import NightDrivingDataset\n",
    "from .nyu import NYUDataset\n",
    "from .pascal_context import PascalContextDataset, PascalContextDataset59\n",
    "from .potsdam import PotsdamDataset\n",
    "from .refuge import REFUGEDataset\n",
    "from .stare import STAREDataset\n",
    "from .synapse import SynapseDataset\n",
    "from .mydataset import mydataset # register mydataset\n",
    "# yapf: disable\n",
    "from .transforms import (CLAHE, AdjustGamma, Albu, BioMedical3DPad,\n",
    "                         BioMedical3DRandomCrop, BioMedical3DRandomFlip,\n",
    "                         BioMedicalGaussianBlur, BioMedicalGaussianNoise,\n",
    "                         BioMedicalRandomGamma, ConcatCDInput, GenerateEdge,\n",
    "                         LoadAnnotations, LoadBiomedicalAnnotation,\n",
    "                         LoadBiomedicalData, LoadBiomedicalImageFromFile,\n",
    "                         LoadImageFromNDArray, LoadMultipleRSImageFromFile,\n",
    "                         LoadSingleRSImageFromFile, PackSegInputs,\n",
    "                         PhotoMetricDistortion, RandomCrop, RandomCutOut,\n",
    "                         RandomMosaic, RandomRotate, RandomRotFlip, Rerange,\n",
    "                         ResizeShortestEdge, ResizeToMultiple, RGB2Gray,\n",
    "                         SegRescale)\n",
    "from .voc import PascalVOCDataset\n",
    "\n",
    "# yapf: enable\n",
    "__all__ = [\n",
    "    'BaseSegDataset', 'BioMedical3DRandomCrop', 'BioMedical3DRandomFlip',\n",
    "    'CityscapesDataset', 'PascalVOCDataset', 'ADE20KDataset',\n",
    "    'PascalContextDataset', 'PascalContextDataset59', 'ChaseDB1Dataset',\n",
    "    'DRIVEDataset', 'HRFDataset', 'STAREDataset', 'DarkZurichDataset',\n",
    "    'NightDrivingDataset', 'COCOStuffDataset', 'LoveDADataset',\n",
    "    'MultiImageMixDataset', 'iSAIDDataset', 'ISPRSDataset', 'PotsdamDataset',\n",
    "    'LoadAnnotations', 'RandomCrop', 'SegRescale', 'PhotoMetricDistortion',\n",
    "    'RandomRotate', 'AdjustGamma', 'CLAHE', 'Rerange', 'RGB2Gray',\n",
    "    'RandomCutOut', 'RandomMosaic', 'PackSegInputs', 'ResizeToMultiple',\n",
    "    'LoadImageFromNDArray', 'LoadBiomedicalImageFromFile',\n",
    "    'LoadBiomedicalAnnotation', 'LoadBiomedicalData', 'GenerateEdge',\n",
    "    'DecathlonDataset', 'LIPDataset', 'ResizeShortestEdge',\n",
    "    'BioMedicalGaussianNoise', 'BioMedicalGaussianBlur',\n",
    "    'BioMedicalRandomGamma', 'BioMedical3DPad', 'RandomRotFlip',\n",
    "    'SynapseDataset', 'REFUGEDataset', 'MapillaryDataset_v1',\n",
    "    'MapillaryDataset_v2', 'Albu', 'LEVIRCDDataset',\n",
    "    'LoadMultipleRSImageFromFile', 'LoadSingleRSImageFromFile',\n",
    "    'ConcatCDInput', 'BaseCDDataset', 'DSDLSegDataset', 'BDD100KDataset',\n",
    "    'NYUDataset', 'mydataset' # register mydataset\n",
    "]\n",
    "\"\"\"\n",
    "# here we create the config file, you may rename it\n",
    "with open('./mmseg/datasets/__init__.py', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    test_cfg=dict(size_divisor=32),\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/ade/ADEChallengeData2016'\n",
      "dataset_type = 'ADE20KDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False, interval=5000, save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        deep_stem=False,\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='SyncBN'),\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=32),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        enforce_decoder_input_project=False,\n",
      "        feat_channels=256,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        loss_cls=dict(\n",
      "            class_weight=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                0.1,\n",
      "            ],\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=False),\n",
      "        loss_dice=dict(\n",
      "            activate=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0,\n",
      "            naive_dice=True,\n",
      "            reduction='mean',\n",
      "            type='mmdet.DiceLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_mask=dict(\n",
      "            loss_weight=5.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=150,\n",
      "        num_queries=100,\n",
      "        num_transformer_feat_level=3,\n",
      "        out_channels=256,\n",
      "        pixel_decoder=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                init_cfg=None,\n",
      "                layer_cfg=dict(\n",
      "                    ffn_cfg=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2),\n",
      "                    self_attn_cfg=dict(\n",
      "                        batch_first=True,\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        im2col_step=64,\n",
      "                        init_cfg=None,\n",
      "                        norm_cfg=None,\n",
      "                        num_heads=8,\n",
      "                        num_levels=3,\n",
      "                        num_points=4)),\n",
      "                num_layers=6),\n",
      "            init_cfg=None,\n",
      "            norm_cfg=dict(num_groups=32, type='GN'),\n",
      "            num_outs=3,\n",
      "            positional_encoding=dict(normalize=True, num_feats=128),\n",
      "            type='mmdet.MSDeformAttnPixelDecoder'),\n",
      "        positional_encoding=dict(normalize=True, num_feats=128),\n",
      "        strides=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='mmdet.ClassificationCost', weight=2.0),\n",
      "                    dict(\n",
      "                        type='mmdet.CrossEntropyLossCost',\n",
      "                        use_sigmoid=True,\n",
      "                        weight=5.0),\n",
      "                    dict(\n",
      "                        eps=1.0,\n",
      "                        pred_act=True,\n",
      "                        type='mmdet.DiceCost',\n",
      "                        weight=5.0),\n",
      "                ],\n",
      "                type='mmdet.HungarianAssigner'),\n",
      "            importance_sample_ratio=0.75,\n",
      "            num_points=12544,\n",
      "            oversample_ratio=3.0,\n",
      "            sampler=dict(type='mmdet.MaskPseudoSampler')),\n",
      "        transformer_decoder=dict(\n",
      "            init_cfg=None,\n",
      "            layer_cfg=dict(\n",
      "                cross_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0),\n",
      "                ffn_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    add_identity=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_drop=0.0,\n",
      "                    num_fcs=2),\n",
      "                self_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0)),\n",
      "            num_layers=9,\n",
      "            return_intermediate=True),\n",
      "        type='Mask2FormerHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "num_classes = 150\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=0.0001,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            backbone=dict(decay_mult=1.0, lr_mult=0.1),\n",
      "            level_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),\n",
      "        norm_decay_mult=0.0),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(\n",
      "    betas=(\n",
      "        0.9,\n",
      "        0.999,\n",
      "    ),\n",
      "    eps=1e-08,\n",
      "    lr=0.0001,\n",
      "    type='AdamW',\n",
      "    weight_decay=0.05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=160000, type='IterBasedTrainLoop', val_interval=5000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                max_size=2048,\n",
      "                resize_type='ResizeShortestEdge',\n",
      "                scales=[\n",
      "                    256,\n",
      "                    307,\n",
      "                    358,\n",
      "                    409,\n",
      "                    460,\n",
      "                    512,\n",
      "                    563,\n",
      "                    614,\n",
      "                    665,\n",
      "                    716,\n",
      "                    768,\n",
      "                    819,\n",
      "                    870,\n",
      "                    921,\n",
      "                    972,\n",
      "                    1024,\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        max_size=2048,\n",
      "        resize_type='ResizeShortestEdge',\n",
      "        scales=[\n",
      "            256,\n",
      "            307,\n",
      "            358,\n",
      "            409,\n",
      "            460,\n",
      "            512,\n",
      "            563,\n",
      "            614,\n",
      "            665,\n",
      "            716,\n",
      "            768,\n",
      "            819,\n",
      "            870,\n",
      "            921,\n",
      "            972,\n",
      "            1024,\n",
      "        ],\n",
      "        type='RandomChoiceResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('configs/mask2former/mask2former_r50_8xb2-160k_ade20k-512x512.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    test_cfg=dict(size_divisor=32),\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'ISIC'\n",
      "dataset_type = 'mydataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False, interval=5000, save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = './checkpoint/mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        deep_stem=False,\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='SyncBN'),\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=32),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        enforce_decoder_input_project=False,\n",
      "        feat_channels=256,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        loss_cls=dict(\n",
      "            class_weight=[\n",
      "                1,\n",
      "                1,\n",
      "                0,\n",
      "            ],\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=False),\n",
      "        loss_dice=dict(\n",
      "            activate=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0,\n",
      "            naive_dice=True,\n",
      "            reduction='mean',\n",
      "            type='mmdet.DiceLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_mask=dict(\n",
      "            loss_weight=5.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=2,\n",
      "        num_queries=100,\n",
      "        num_transformer_feat_level=3,\n",
      "        out_channels=256,\n",
      "        pixel_decoder=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                init_cfg=None,\n",
      "                layer_cfg=dict(\n",
      "                    ffn_cfg=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2),\n",
      "                    self_attn_cfg=dict(\n",
      "                        batch_first=True,\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        im2col_step=64,\n",
      "                        init_cfg=None,\n",
      "                        norm_cfg=None,\n",
      "                        num_heads=8,\n",
      "                        num_levels=3,\n",
      "                        num_points=4)),\n",
      "                num_layers=6),\n",
      "            init_cfg=None,\n",
      "            norm_cfg=dict(num_groups=32, type='GN'),\n",
      "            num_outs=3,\n",
      "            positional_encoding=dict(normalize=True, num_feats=128),\n",
      "            type='mmdet.MSDeformAttnPixelDecoder'),\n",
      "        positional_encoding=dict(normalize=True, num_feats=128),\n",
      "        strides=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='mmdet.ClassificationCost', weight=2.0),\n",
      "                    dict(\n",
      "                        type='mmdet.CrossEntropyLossCost',\n",
      "                        use_sigmoid=True,\n",
      "                        weight=5.0),\n",
      "                    dict(\n",
      "                        eps=1.0,\n",
      "                        pred_act=True,\n",
      "                        type='mmdet.DiceCost',\n",
      "                        weight=5.0),\n",
      "                ],\n",
      "                type='mmdet.HungarianAssigner'),\n",
      "            importance_sample_ratio=0.75,\n",
      "            num_points=12544,\n",
      "            oversample_ratio=3.0,\n",
      "            sampler=dict(type='mmdet.MaskPseudoSampler')),\n",
      "        transformer_decoder=dict(\n",
      "            init_cfg=None,\n",
      "            layer_cfg=dict(\n",
      "                cross_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0),\n",
      "                ffn_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    add_identity=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_drop=0.0,\n",
      "                    num_fcs=2),\n",
      "                self_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0)),\n",
      "            num_layers=9,\n",
      "            return_intermediate=True),\n",
      "        type='Mask2FormerHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "num_classes = 2\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=6.25e-06,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            backbone=dict(decay_mult=1.0, lr_mult=0.1),\n",
      "            level_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),\n",
      "        norm_decay_mult=0.0),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(\n",
      "    betas=(\n",
      "        0.9,\n",
      "        0.999,\n",
      "    ),\n",
      "    eps=1e-08,\n",
      "    lr=6.25e-06,\n",
      "    type='AdamW',\n",
      "    weight_decay=0.05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=32000,\n",
      "        eta_min=0,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=32000, type='IterBasedTrainLoop', val_interval=1000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                max_size=2048,\n",
      "                resize_type='ResizeShortestEdge',\n",
      "                scales=[\n",
      "                    256,\n",
      "                    307,\n",
      "                    358,\n",
      "                    409,\n",
      "                    460,\n",
      "                    512,\n",
      "                    563,\n",
      "                    614,\n",
      "                    665,\n",
      "                    716,\n",
      "                    768,\n",
      "                    819,\n",
      "                    870,\n",
      "                    921,\n",
      "                    972,\n",
      "                    1024,\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "            dict(\n",
      "                keymap=dict(gt_seg_map='mask', img='image'),\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        border_mode=4,\n",
      "                        interpolation=1,\n",
      "                        p=0.5,\n",
      "                        rotate=(\n",
      "                            -180,\n",
      "                            180,\n",
      "                        ),\n",
      "                        scale=(\n",
      "                            0.8,\n",
      "                            1.1,\n",
      "                        ),\n",
      "                        translate_percent=(\n",
      "                            -0.05,\n",
      "                            0.05,\n",
      "                        ),\n",
      "                        type='Affine'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                hue_shift_limit=10,\n",
      "                                p=1.0,\n",
      "                                sat_shift_limit=10,\n",
      "                                type='HueSaturationValue',\n",
      "                                val_shift_limit=10),\n",
      "                            dict(\n",
      "                                brightness_limit=0.1,\n",
      "                                contrast_limit=0.1,\n",
      "                                p=1.0,\n",
      "                                type='RandomBrightnessContrast'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                            dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                ],\n",
      "                type='Albu'),\n",
      "            dict(type='ConvertMaskFromAlbu'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'img_shape',\n",
      "                    'img',\n",
      "                    'gt_seg_map',\n",
      "                ),\n",
      "                type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        max_size=2048,\n",
      "        resize_type='ResizeShortestEdge',\n",
      "        scales=[\n",
      "            256,\n",
      "            307,\n",
      "            358,\n",
      "            409,\n",
      "            460,\n",
      "            512,\n",
      "            563,\n",
      "            614,\n",
      "            665,\n",
      "            716,\n",
      "            768,\n",
      "            819,\n",
      "            870,\n",
      "            921,\n",
      "            972,\n",
      "            1024,\n",
      "        ],\n",
      "        type='RandomChoiceResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "    dict(\n",
      "        keymap=dict(gt_seg_map='mask', img='image'),\n",
      "        transforms=[\n",
      "            dict(\n",
      "                border_mode=4,\n",
      "                interpolation=1,\n",
      "                p=0.5,\n",
      "                rotate=(\n",
      "                    -180,\n",
      "                    180,\n",
      "                ),\n",
      "                scale=(\n",
      "                    0.8,\n",
      "                    1.1,\n",
      "                ),\n",
      "                translate_percent=(\n",
      "                    -0.05,\n",
      "                    0.05,\n",
      "                ),\n",
      "                type='Affine'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        hue_shift_limit=10,\n",
      "                        p=1.0,\n",
      "                        sat_shift_limit=10,\n",
      "                        type='HueSaturationValue',\n",
      "                        val_shift_limit=10),\n",
      "                    dict(\n",
      "                        brightness_limit=0.1,\n",
      "                        contrast_limit=0.1,\n",
      "                        p=1.0,\n",
      "                        type='RandomBrightnessContrast'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                    dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "        ],\n",
      "        type='Albu'),\n",
      "    dict(type='ConvertMaskFromAlbu'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'img_shape',\n",
      "            'img',\n",
      "            'gt_seg_map',\n",
      "        ),\n",
      "        type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for configs explanation, you can refer to\n",
    "# https://mmsegmentation.readthedocs.io/en/latest/user_guides/1_config.html\n",
    "# for more augmentation, you can refer to\n",
    "# https://mmsegmentation.readthedocs.io/en/latest/advanced_guides/transforms.html\n",
    "import cv2\n",
    "\n",
    "cfg.num_classes = 2 # background + 1 class\n",
    "cfg.model.decode_head.num_classes = 2 \n",
    "cfg.model.decode_head.loss_cls.class_weight = [1,1,0] # num_class + 1 (the extra one is for something else, may set to 0.1)\n",
    "cfg.data_root = 'ISIC'\n",
    "cfg.dataset_type = 'mydataset'\n",
    "cfg.load_from = './checkpoint/mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth'\n",
    "\n",
    "cfg.train_dataloader.dataset.data_root='ISIC'\n",
    "cfg.train_dataloader.dataset.type='mydataset'\n",
    "cfg.train_dataloader.dataset.pipeline[1].reduce_zero_label = False\n",
    "cfg.train_pipeline[1].reduce_zero_label = False\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "cfg.test_dataloader.dataset.data_root='ISIC'\n",
    "cfg.test_dataloader.dataset.type='mydataset'\n",
    "cfg.test_dataloader.dataset.pipeline[2].reduce_zero_label = False\n",
    "cfg.test_pipeline[2].reduce_zero_label = False\n",
    "\n",
    "cfg.val_dataloader = cfg.test_dataloader\n",
    "cfg.param_scheduler[0].end = int(cfg.param_scheduler[0].end/5)\n",
    "cfg.train_cfg.max_iters = int(cfg.train_cfg.max_iters/5)\n",
    "cfg.train_cfg.val_interval = int(cfg.train_cfg.val_interval/5)\n",
    "cfg.optim_wrapper.optimizer.lr = 0.0001/16\n",
    "cfg.optimizer.lr = 0.0001/16\n",
    "\n",
    "cfg.work_dir = './work_dirs'\n",
    "\n",
    "add_aug = dict(\n",
    "    type='Albu',\n",
    "    transforms=[\n",
    "        dict(\n",
    "            type='Affine',\n",
    "            scale=(0.8, 1.1),  \n",
    "            translate_percent=(-0.05, 0.05),\n",
    "            rotate=(-180, 180), \n",
    "            interpolation=1,\n",
    "            border_mode=cv2.BORDER_REFLECT_101,\n",
    "            p=0.5),\n",
    "        dict(\n",
    "            type='OneOf',\n",
    "            transforms=[\n",
    "                dict(type='HueSaturationValue', p=1.0,\n",
    "                    hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10\n",
    "                ),\n",
    "                dict(type='RandomBrightnessContrast', p=1.0,\n",
    "                    brightness_limit=0.1, contrast_limit=0.1 \n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        dict(\n",
    "            type='OneOf',\n",
    "            transforms=[\n",
    "                dict(type='ElasticTransform', border_mode=cv2.BORDER_REFLECT_101, p=1.0),\n",
    "                dict(type='GridDistortion', border_mode=cv2.BORDER_REFLECT_101, p=1.0),\n",
    "            ],\n",
    "            p=0.5),\n",
    "    ],\n",
    "    keymap={\n",
    "        'img': 'image',\n",
    "        'gt_seg_map': 'mask',\n",
    "    },\n",
    ")\n",
    "pre = dict(type='ConvertMaskForAlbu',num_classes=8)\n",
    "post = dict(type='ConvertMaskFromAlbu')\n",
    "\n",
    "# Find PackInputs index and insert before it\n",
    "for i, transform in enumerate(cfg.train_pipeline):\n",
    "    if transform['type'] == 'PackSegInputs':\n",
    "        cfg.train_pipeline.insert(i, post)\n",
    "        cfg.train_pipeline.insert(i, add_aug)\n",
    "        cfg.train_pipeline.insert(i, pre)\n",
    "        break\n",
    "cfg.train_pipeline[-1].meta_keys = ('img_path', 'img_shape', 'img', 'gt_seg_map')\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 17:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 892332615\n",
      "    GPU 0: NVIDIA GeForce RTX 5090\n",
      "    CUDA_HOME: /usr/local/cuda-12.8/\n",
      "    NVCC: Cuda compilation tools, release 12.8, V12.8.93\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.7.0+cu128\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120;-gencode;arch=compute_120,code=compute_120\n",
      "  - CuDNN 90.7.1\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=134179474539648ba7dee1317959529fbd0e7f89, CUDA_VERSION=12.8, CUDNN_VERSION=9.7.1, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.7.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.22.0+cu128\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 892332615\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/02 17:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    test_cfg=dict(size_divisor=32),\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'ISIC'\n",
      "dataset_type = 'mydataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False, interval=5000, save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = './checkpoint/mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        deep_stem=False,\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='SyncBN'),\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=32),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        enforce_decoder_input_project=False,\n",
      "        feat_channels=256,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        loss_cls=dict(\n",
      "            class_weight=[\n",
      "                1,\n",
      "                1,\n",
      "                0,\n",
      "            ],\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=False),\n",
      "        loss_dice=dict(\n",
      "            activate=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0,\n",
      "            naive_dice=True,\n",
      "            reduction='mean',\n",
      "            type='mmdet.DiceLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_mask=dict(\n",
      "            loss_weight=5.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=2,\n",
      "        num_queries=100,\n",
      "        num_transformer_feat_level=3,\n",
      "        out_channels=256,\n",
      "        pixel_decoder=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                init_cfg=None,\n",
      "                layer_cfg=dict(\n",
      "                    ffn_cfg=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2),\n",
      "                    self_attn_cfg=dict(\n",
      "                        batch_first=True,\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        im2col_step=64,\n",
      "                        init_cfg=None,\n",
      "                        norm_cfg=None,\n",
      "                        num_heads=8,\n",
      "                        num_levels=3,\n",
      "                        num_points=4)),\n",
      "                num_layers=6),\n",
      "            init_cfg=None,\n",
      "            norm_cfg=dict(num_groups=32, type='GN'),\n",
      "            num_outs=3,\n",
      "            positional_encoding=dict(normalize=True, num_feats=128),\n",
      "            type='mmdet.MSDeformAttnPixelDecoder'),\n",
      "        positional_encoding=dict(normalize=True, num_feats=128),\n",
      "        strides=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='mmdet.ClassificationCost', weight=2.0),\n",
      "                    dict(\n",
      "                        type='mmdet.CrossEntropyLossCost',\n",
      "                        use_sigmoid=True,\n",
      "                        weight=5.0),\n",
      "                    dict(\n",
      "                        eps=1.0,\n",
      "                        pred_act=True,\n",
      "                        type='mmdet.DiceCost',\n",
      "                        weight=5.0),\n",
      "                ],\n",
      "                type='mmdet.HungarianAssigner'),\n",
      "            importance_sample_ratio=0.75,\n",
      "            num_points=12544,\n",
      "            oversample_ratio=3.0,\n",
      "            sampler=dict(type='mmdet.MaskPseudoSampler')),\n",
      "        transformer_decoder=dict(\n",
      "            init_cfg=None,\n",
      "            layer_cfg=dict(\n",
      "                cross_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0),\n",
      "                ffn_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    add_identity=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_drop=0.0,\n",
      "                    num_fcs=2),\n",
      "                self_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0)),\n",
      "            num_layers=9,\n",
      "            return_intermediate=True),\n",
      "        type='Mask2FormerHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "num_classes = 2\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=6.25e-06,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            backbone=dict(decay_mult=1.0, lr_mult=0.1),\n",
      "            level_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),\n",
      "        norm_decay_mult=0.0),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(\n",
      "    betas=(\n",
      "        0.9,\n",
      "        0.999,\n",
      "    ),\n",
      "    eps=1e-08,\n",
      "    lr=6.25e-06,\n",
      "    type='AdamW',\n",
      "    weight_decay=0.05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=32000,\n",
      "        eta_min=0,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=32000, type='IterBasedTrainLoop', val_interval=1000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                max_size=2048,\n",
      "                resize_type='ResizeShortestEdge',\n",
      "                scales=[\n",
      "                    256,\n",
      "                    307,\n",
      "                    358,\n",
      "                    409,\n",
      "                    460,\n",
      "                    512,\n",
      "                    563,\n",
      "                    614,\n",
      "                    665,\n",
      "                    716,\n",
      "                    768,\n",
      "                    819,\n",
      "                    870,\n",
      "                    921,\n",
      "                    972,\n",
      "                    1024,\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "            dict(\n",
      "                keymap=dict(gt_seg_map='mask', img='image'),\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        border_mode=4,\n",
      "                        interpolation=1,\n",
      "                        p=0.5,\n",
      "                        rotate=(\n",
      "                            -180,\n",
      "                            180,\n",
      "                        ),\n",
      "                        scale=(\n",
      "                            0.8,\n",
      "                            1.1,\n",
      "                        ),\n",
      "                        translate_percent=(\n",
      "                            -0.05,\n",
      "                            0.05,\n",
      "                        ),\n",
      "                        type='Affine'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                hue_shift_limit=10,\n",
      "                                p=1.0,\n",
      "                                sat_shift_limit=10,\n",
      "                                type='HueSaturationValue',\n",
      "                                val_shift_limit=10),\n",
      "                            dict(\n",
      "                                brightness_limit=0.1,\n",
      "                                contrast_limit=0.1,\n",
      "                                p=1.0,\n",
      "                                type='RandomBrightnessContrast'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                            dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                ],\n",
      "                type='Albu'),\n",
      "            dict(type='ConvertMaskFromAlbu'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'img_shape',\n",
      "                    'img',\n",
      "                    'gt_seg_map',\n",
      "                ),\n",
      "                type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        max_size=2048,\n",
      "        resize_type='ResizeShortestEdge',\n",
      "        scales=[\n",
      "            256,\n",
      "            307,\n",
      "            358,\n",
      "            409,\n",
      "            460,\n",
      "            512,\n",
      "            563,\n",
      "            614,\n",
      "            665,\n",
      "            716,\n",
      "            768,\n",
      "            819,\n",
      "            870,\n",
      "            921,\n",
      "            972,\n",
      "            1024,\n",
      "        ],\n",
      "        type='RandomChoiceResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "    dict(\n",
      "        keymap=dict(gt_seg_map='mask', img='image'),\n",
      "        transforms=[\n",
      "            dict(\n",
      "                border_mode=4,\n",
      "                interpolation=1,\n",
      "                p=0.5,\n",
      "                rotate=(\n",
      "                    -180,\n",
      "                    180,\n",
      "                ),\n",
      "                scale=(\n",
      "                    0.8,\n",
      "                    1.1,\n",
      "                ),\n",
      "                translate_percent=(\n",
      "                    -0.05,\n",
      "                    0.05,\n",
      "                ),\n",
      "                type='Affine'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        hue_shift_limit=10,\n",
      "                        p=1.0,\n",
      "                        sat_shift_limit=10,\n",
      "                        type='HueSaturationValue',\n",
      "                        val_shift_limit=10),\n",
      "                    dict(\n",
      "                        brightness_limit=0.1,\n",
      "                        contrast_limit=0.1,\n",
      "                        p=1.0,\n",
      "                        type='RandomBrightnessContrast'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                    dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "        ],\n",
      "        type='Albu'),\n",
      "    dict(type='ConvertMaskFromAlbu'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'img_shape',\n",
      "            'img',\n",
      "            'gt_seg_map',\n",
      "        ),\n",
      "        type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmengine/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 17:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/02 17:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmsegmentation/mmseg/datasets/transforms/loading.py:83: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv1.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv2.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv3.weight:lr=6.25e-07\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_embed.weight:lr=6.25e-06\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_feat.weight:lr=6.25e-06\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.level_embed.weight:lr=6.25e-06\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0\n",
      "07/02 17:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0\n",
      "07/02 17:01:22 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "07/02 17:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "07/02 17:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "07/02 17:01:23 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "Loads checkpoint by local backend from path: ./checkpoint/mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for decode_head.cls_embed.weight: copying a param with shape torch.Size([151, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).\n",
      "size mismatch for decode_head.cls_embed.bias: copying a param with shape torch.Size([151]) from checkpoint, the shape in current model is torch.Size([3]).\n",
      "07/02 17:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ./checkpoint/mask2former_r50_8xb2-160k_ade20k-512x512_20221204_000055-2d1f55f1.pth\n",
      "07/02 17:01:23 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/02 17:01:23 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "07/02 17:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 17:01:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [   50/32000]  base_lr: 6.2414e-06 lr: 6.2414e-07  eta: 1:39:53  time: 0.1579  data_time: 0.0090  memory: 12128  grad_norm: 863.9637  loss: 36.3697  decode.loss_cls: 0.5256  decode.loss_mask: 1.7140  decode.loss_dice: 1.1027  decode.d0.loss_cls: 1.5995  decode.d0.loss_mask: 2.1300  decode.d0.loss_dice: 1.4356  decode.d1.loss_cls: 1.1681  decode.d1.loss_mask: 1.7371  decode.d1.loss_dice: 1.1500  decode.d2.loss_cls: 0.9377  decode.d2.loss_mask: 1.6881  decode.d2.loss_dice: 1.0914  decode.d3.loss_cls: 0.8376  decode.d3.loss_mask: 1.6378  decode.d3.loss_dice: 1.0909  decode.d4.loss_cls: 0.6875  decode.d4.loss_mask: 1.5853  decode.d4.loss_dice: 1.0463  decode.d5.loss_cls: 0.5322  decode.d5.loss_mask: 1.6583  decode.d5.loss_dice: 1.0825  decode.d6.loss_cls: 0.4967  decode.d6.loss_mask: 1.6741  decode.d6.loss_dice: 1.1072  decode.d7.loss_cls: 0.5101  decode.d7.loss_mask: 1.6868  decode.d7.loss_dice: 1.1027  decode.d8.loss_cls: 0.5140  decode.d8.loss_mask: 1.7573  decode.d8.loss_dice: 1.0827\n",
      "07/02 17:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  100/32000]  base_lr: 6.2326e-06 lr: 6.2326e-07  eta: 1:31:28  time: 0.1593  data_time: 0.0097  memory: 5152  grad_norm: 894.9217  loss: 29.6905  decode.loss_cls: 0.3166  decode.loss_mask: 1.4576  decode.loss_dice: 0.9926  decode.d0.loss_cls: 1.3082  decode.d0.loss_mask: 1.8087  decode.d0.loss_dice: 1.1941  decode.d1.loss_cls: 0.7992  decode.d1.loss_mask: 1.5011  decode.d1.loss_dice: 0.9885  decode.d2.loss_cls: 0.5470  decode.d2.loss_mask: 1.4676  decode.d2.loss_dice: 0.9992  decode.d3.loss_cls: 0.4373  decode.d3.loss_mask: 1.3861  decode.d3.loss_dice: 0.9463  decode.d4.loss_cls: 0.4108  decode.d4.loss_mask: 1.4425  decode.d4.loss_dice: 0.9631  decode.d5.loss_cls: 0.3346  decode.d5.loss_mask: 1.4590  decode.d5.loss_dice: 0.9435  decode.d6.loss_cls: 0.2765  decode.d6.loss_mask: 1.4413  decode.d6.loss_dice: 0.9256  decode.d7.loss_cls: 0.2670  decode.d7.loss_mask: 1.4136  decode.d7.loss_dice: 0.9331  decode.d8.loss_cls: 0.2848  decode.d8.loss_mask: 1.4880  decode.d8.loss_dice: 0.9571\n",
      "07/02 17:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  150/32000]  base_lr: 6.2238e-06 lr: 6.2238e-07  eta: 1:28:31  time: 0.1570  data_time: 0.0075  memory: 5154  grad_norm: 634.0063  loss: 26.2979  decode.loss_cls: 0.1980  decode.loss_mask: 1.3094  decode.loss_dice: 0.8618  decode.d0.loss_cls: 1.2242  decode.d0.loss_mask: 1.7307  decode.d0.loss_dice: 1.0637  decode.d1.loss_cls: 0.5998  decode.d1.loss_mask: 1.3665  decode.d1.loss_dice: 0.8972  decode.d2.loss_cls: 0.4124  decode.d2.loss_mask: 1.3209  decode.d2.loss_dice: 0.8806  decode.d3.loss_cls: 0.3530  decode.d3.loss_mask: 1.3089  decode.d3.loss_dice: 0.8567  decode.d4.loss_cls: 0.2932  decode.d4.loss_mask: 1.3529  decode.d4.loss_dice: 0.8714  decode.d5.loss_cls: 0.2508  decode.d5.loss_mask: 1.3394  decode.d5.loss_dice: 0.8367  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 1.3305  decode.d6.loss_dice: 0.8368  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 1.2834  decode.d7.loss_dice: 0.8108  decode.d8.loss_cls: 0.1987  decode.d8.loss_mask: 1.2868  decode.d8.loss_dice: 0.8113\n",
      "07/02 17:01:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  200/32000]  base_lr: 6.2150e-06 lr: 6.2150e-07  eta: 1:26:55  time: 0.1575  data_time: 0.0079  memory: 5152  grad_norm: 628.4558  loss: 25.4869  decode.loss_cls: 0.0757  decode.loss_mask: 1.3808  decode.loss_dice: 0.8288  decode.d0.loss_cls: 1.1712  decode.d0.loss_mask: 1.7182  decode.d0.loss_dice: 1.0364  decode.d1.loss_cls: 0.4524  decode.d1.loss_mask: 1.4212  decode.d1.loss_dice: 0.8975  decode.d2.loss_cls: 0.2848  decode.d2.loss_mask: 1.4159  decode.d2.loss_dice: 0.8501  decode.d3.loss_cls: 0.1603  decode.d3.loss_mask: 1.3645  decode.d3.loss_dice: 0.8605  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 1.3777  decode.d4.loss_dice: 0.8789  decode.d5.loss_cls: 0.1038  decode.d5.loss_mask: 1.3374  decode.d5.loss_dice: 0.8634  decode.d6.loss_cls: 0.0830  decode.d6.loss_mask: 1.3423  decode.d6.loss_dice: 0.8518  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 1.3596  decode.d7.loss_dice: 0.8451  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 1.3570  decode.d8.loss_dice: 0.8457\n",
      "07/02 17:02:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  250/32000]  base_lr: 6.2062e-06 lr: 6.2062e-07  eta: 1:25:56  time: 0.1556  data_time: 0.0083  memory: 5152  grad_norm: 697.6940  loss: 27.1144  decode.loss_cls: 0.0517  decode.loss_mask: 1.5408  decode.loss_dice: 0.9676  decode.d0.loss_cls: 1.1443  decode.d0.loss_mask: 1.8413  decode.d0.loss_dice: 1.1546  decode.d1.loss_cls: 0.3726  decode.d1.loss_mask: 1.5687  decode.d1.loss_dice: 1.0063  decode.d2.loss_cls: 0.1926  decode.d2.loss_mask: 1.5148  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 0.1112  decode.d3.loss_mask: 1.4304  decode.d3.loss_dice: 0.9322  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 1.4231  decode.d4.loss_dice: 0.9155  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 1.4842  decode.d5.loss_dice: 0.9493  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 1.4855  decode.d6.loss_dice: 0.9284  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 1.5102  decode.d7.loss_dice: 0.9128  decode.d8.loss_cls: 0.0413  decode.d8.loss_mask: 1.4919  decode.d8.loss_dice: 0.9663\n",
      "07/02 17:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  300/32000]  base_lr: 6.1974e-06 lr: 6.1974e-07  eta: 1:25:22  time: 0.1577  data_time: 0.0089  memory: 5153  grad_norm: 552.3345  loss: 24.4808  decode.loss_cls: 0.0512  decode.loss_mask: 1.3070  decode.loss_dice: 0.8479  decode.d0.loss_cls: 0.9845  decode.d0.loss_mask: 1.5802  decode.d0.loss_dice: 1.0675  decode.d1.loss_cls: 0.3499  decode.d1.loss_mask: 1.3394  decode.d1.loss_dice: 0.9205  decode.d2.loss_cls: 0.2166  decode.d2.loss_mask: 1.2535  decode.d2.loss_dice: 0.8825  decode.d3.loss_cls: 0.1716  decode.d3.loss_mask: 1.2934  decode.d3.loss_dice: 0.9876  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 1.2544  decode.d4.loss_dice: 0.9380  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 1.2601  decode.d5.loss_dice: 0.9134  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 1.2713  decode.d6.loss_dice: 0.8579  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 1.2975  decode.d7.loss_dice: 0.8623  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 1.3310  decode.d8.loss_dice: 0.8713\n",
      "07/02 17:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  350/32000]  base_lr: 6.1886e-06 lr: 6.1886e-07  eta: 1:24:57  time: 0.1596  data_time: 0.0090  memory: 5152  grad_norm: 566.6004  loss: 22.1964  decode.loss_cls: 0.1137  decode.loss_mask: 1.1942  decode.loss_dice: 0.7778  decode.d0.loss_cls: 0.8713  decode.d0.loss_mask: 1.4394  decode.d0.loss_dice: 0.9372  decode.d1.loss_cls: 0.2672  decode.d1.loss_mask: 1.2023  decode.d1.loss_dice: 0.8345  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 1.1422  decode.d2.loss_dice: 0.7640  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 1.1522  decode.d3.loss_dice: 0.7772  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 1.1943  decode.d4.loss_dice: 0.7768  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 1.1806  decode.d5.loss_dice: 0.7685  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 1.1783  decode.d6.loss_dice: 0.7349  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 1.2062  decode.d7.loss_dice: 0.7392  decode.d8.loss_cls: 0.1113  decode.d8.loss_mask: 1.2020  decode.d8.loss_dice: 0.7730\n",
      "07/02 17:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  400/32000]  base_lr: 6.1798e-06 lr: 6.1798e-07  eta: 1:24:30  time: 0.1538  data_time: 0.0078  memory: 5154  grad_norm: 553.4697  loss: 21.1883  decode.loss_cls: 0.0607  decode.loss_mask: 1.0442  decode.loss_dice: 0.7719  decode.d0.loss_cls: 0.8052  decode.d0.loss_mask: 1.3945  decode.d0.loss_dice: 0.9868  decode.d1.loss_cls: 0.2764  decode.d1.loss_mask: 1.0875  decode.d1.loss_dice: 0.8334  decode.d2.loss_cls: 0.1705  decode.d2.loss_mask: 1.0755  decode.d2.loss_dice: 0.8236  decode.d3.loss_cls: 0.0962  decode.d3.loss_mask: 1.1268  decode.d3.loss_dice: 0.8072  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 1.1107  decode.d4.loss_dice: 0.7742  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 1.1202  decode.d5.loss_dice: 0.7677  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 1.1348  decode.d6.loss_dice: 0.8035  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 1.0822  decode.d7.loss_dice: 0.7798  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 1.0677  decode.d8.loss_dice: 0.7811\n",
      "07/02 17:02:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  450/32000]  base_lr: 6.1710e-06 lr: 6.1710e-07  eta: 1:24:05  time: 0.1572  data_time: 0.0087  memory: 5152  grad_norm: 411.1291  loss: 18.2545  decode.loss_cls: 0.0960  decode.loss_mask: 0.9245  decode.loss_dice: 0.6856  decode.d0.loss_cls: 0.8906  decode.d0.loss_mask: 1.1932  decode.d0.loss_dice: 0.8569  decode.d1.loss_cls: 0.2411  decode.d1.loss_mask: 0.9509  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 0.9122  decode.d2.loss_dice: 0.6721  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.8833  decode.d3.loss_dice: 0.6468  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 0.8913  decode.d4.loss_dice: 0.6849  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 0.9043  decode.d5.loss_dice: 0.6827  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.9036  decode.d6.loss_dice: 0.6926  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.8952  decode.d7.loss_dice: 0.6670  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.9152  decode.d8.loss_dice: 0.6584\n",
      "07/02 17:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  500/32000]  base_lr: 6.1622e-06 lr: 6.1622e-07  eta: 1:23:39  time: 0.1539  data_time: 0.0077  memory: 5152  grad_norm: 481.8118  loss: 22.6947  decode.loss_cls: 0.0273  decode.loss_mask: 1.3797  decode.loss_dice: 0.7970  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 1.6134  decode.d0.loss_dice: 0.9349  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 1.3263  decode.d1.loss_dice: 0.7811  decode.d2.loss_cls: 0.1111  decode.d2.loss_mask: 1.2733  decode.d2.loss_dice: 0.7678  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 1.2709  decode.d3.loss_dice: 0.7971  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 1.2674  decode.d4.loss_dice: 0.7828  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 1.3162  decode.d5.loss_dice: 0.7888  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 1.2932  decode.d6.loss_dice: 0.7705  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 1.3015  decode.d7.loss_dice: 0.7744  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 1.3589  decode.d8.loss_dice: 0.7813\n",
      "07/02 17:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  550/32000]  base_lr: 6.1534e-06 lr: 6.1534e-07  eta: 1:23:16  time: 0.1539  data_time: 0.0076  memory: 5153  grad_norm: 566.2834  loss: 24.3246  decode.loss_cls: 0.0970  decode.loss_mask: 1.3625  decode.loss_dice: 0.8941  decode.d0.loss_cls: 0.8016  decode.d0.loss_mask: 1.5478  decode.d0.loss_dice: 1.0439  decode.d1.loss_cls: 0.2775  decode.d1.loss_mask: 1.2854  decode.d1.loss_dice: 0.8874  decode.d2.loss_cls: 0.1950  decode.d2.loss_mask: 1.3519  decode.d2.loss_dice: 0.8475  decode.d3.loss_cls: 0.1477  decode.d3.loss_mask: 1.3141  decode.d3.loss_dice: 0.8779  decode.d4.loss_cls: 0.1079  decode.d4.loss_mask: 1.3270  decode.d4.loss_dice: 0.8680  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 1.3399  decode.d5.loss_dice: 0.8632  decode.d6.loss_cls: 0.0837  decode.d6.loss_mask: 1.3578  decode.d6.loss_dice: 0.8457  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 1.3677  decode.d7.loss_dice: 0.8575  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 1.3425  decode.d8.loss_dice: 0.8128\n",
      "07/02 17:02:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  600/32000]  base_lr: 6.1446e-06 lr: 6.1446e-07  eta: 1:23:11  time: 0.1565  data_time: 0.0090  memory: 5153  grad_norm: 454.7758  loss: 22.2070  decode.loss_cls: 0.0225  decode.loss_mask: 1.3004  decode.loss_dice: 0.7651  decode.d0.loss_cls: 0.7816  decode.d0.loss_mask: 1.5731  decode.d0.loss_dice: 0.9436  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 1.2687  decode.d1.loss_dice: 0.8196  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 1.2773  decode.d2.loss_dice: 0.7923  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 1.2648  decode.d3.loss_dice: 0.8129  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 1.3020  decode.d4.loss_dice: 0.7932  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 1.2337  decode.d5.loss_dice: 0.7623  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 1.2289  decode.d6.loss_dice: 0.7339  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 1.3015  decode.d7.loss_dice: 0.7648  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 1.2737  decode.d8.loss_dice: 0.7905\n",
      "07/02 17:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  650/32000]  base_lr: 6.1358e-06 lr: 6.1358e-07  eta: 1:22:58  time: 0.1575  data_time: 0.0092  memory: 5153  grad_norm: 389.8182  loss: 19.5250  decode.loss_cls: 0.0383  decode.loss_mask: 1.0503  decode.loss_dice: 0.7270  decode.d0.loss_cls: 0.7587  decode.d0.loss_mask: 1.2168  decode.d0.loss_dice: 0.9976  decode.d1.loss_cls: 0.1420  decode.d1.loss_mask: 0.9787  decode.d1.loss_dice: 0.7494  decode.d2.loss_cls: 0.1111  decode.d2.loss_mask: 0.9760  decode.d2.loss_dice: 0.7156  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 1.0033  decode.d3.loss_dice: 0.7447  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.9977  decode.d4.loss_dice: 0.7408  decode.d5.loss_cls: 0.0676  decode.d5.loss_mask: 1.0279  decode.d5.loss_dice: 0.7752  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 1.0361  decode.d6.loss_dice: 0.7591  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 1.0365  decode.d7.loss_dice: 0.7341  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 1.0273  decode.d8.loss_dice: 0.7335\n",
      "07/02 17:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  700/32000]  base_lr: 6.1270e-06 lr: 6.1270e-07  eta: 1:22:45  time: 0.1572  data_time: 0.0088  memory: 5152  grad_norm: 527.4335  loss: 19.3935  decode.loss_cls: 0.0128  decode.loss_mask: 1.1377  decode.loss_dice: 0.6816  decode.d0.loss_cls: 0.7471  decode.d0.loss_mask: 1.3203  decode.d0.loss_dice: 0.7868  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 1.1090  decode.d1.loss_dice: 0.7021  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 1.0869  decode.d2.loss_dice: 0.6607  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 1.1108  decode.d3.loss_dice: 0.7047  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 1.0809  decode.d4.loss_dice: 0.7024  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 1.0883  decode.d5.loss_dice: 0.6952  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 1.1420  decode.d6.loss_dice: 0.7092  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 1.1323  decode.d7.loss_dice: 0.6828  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 1.1174  decode.d8.loss_dice: 0.6770\n",
      "07/02 17:03:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  750/32000]  base_lr: 6.1182e-06 lr: 6.1182e-07  eta: 1:22:34  time: 0.1568  data_time: 0.0087  memory: 5152  grad_norm: 365.9506  loss: 17.6369  decode.loss_cls: 0.0325  decode.loss_mask: 0.9654  decode.loss_dice: 0.6039  decode.d0.loss_cls: 0.7061  decode.d0.loss_mask: 1.1943  decode.d0.loss_dice: 0.7862  decode.d1.loss_cls: 0.0889  decode.d1.loss_mask: 1.0187  decode.d1.loss_dice: 0.6640  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 1.0361  decode.d2.loss_dice: 0.6310  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 1.0250  decode.d3.loss_dice: 0.6761  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 1.0044  decode.d4.loss_dice: 0.6504  decode.d5.loss_cls: 0.0202  decode.d5.loss_mask: 0.9961  decode.d5.loss_dice: 0.6665  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.9504  decode.d6.loss_dice: 0.6065  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.9570  decode.d7.loss_dice: 0.5892  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.9567  decode.d8.loss_dice: 0.5914\n",
      "07/02 17:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  800/32000]  base_lr: 6.1094e-06 lr: 6.1094e-07  eta: 1:22:20  time: 0.1552  data_time: 0.0082  memory: 5154  grad_norm: 343.1171  loss: 17.9011  decode.loss_cls: 0.0315  decode.loss_mask: 0.9402  decode.loss_dice: 0.6430  decode.d0.loss_cls: 0.5838  decode.d0.loss_mask: 1.1678  decode.d0.loss_dice: 0.8504  decode.d1.loss_cls: 0.1514  decode.d1.loss_mask: 0.9342  decode.d1.loss_dice: 0.7236  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.9390  decode.d2.loss_dice: 0.6902  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 0.6514  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.9779  decode.d4.loss_dice: 0.6694  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.9778  decode.d5.loss_dice: 0.6689  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.9282  decode.d6.loss_dice: 0.6796  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.9794  decode.d7.loss_dice: 0.6566  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.9763  decode.d8.loss_dice: 0.6749\n",
      "07/02 17:03:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  850/32000]  base_lr: 6.1006e-06 lr: 6.1006e-07  eta: 1:22:12  time: 0.1578  data_time: 0.0087  memory: 5152  grad_norm: 409.2229  loss: 20.4930  decode.loss_cls: 0.0378  decode.loss_mask: 1.1415  decode.loss_dice: 0.6891  decode.d0.loss_cls: 0.6753  decode.d0.loss_mask: 1.4295  decode.d0.loss_dice: 0.9665  decode.d1.loss_cls: 0.1613  decode.d1.loss_mask: 1.1864  decode.d1.loss_dice: 0.7503  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 1.1695  decode.d2.loss_dice: 0.7135  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 1.1679  decode.d3.loss_dice: 0.7636  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 1.1639  decode.d4.loss_dice: 0.7466  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 1.1331  decode.d5.loss_dice: 0.7123  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 1.1345  decode.d6.loss_dice: 0.6963  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 1.1407  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 1.1597  decode.d8.loss_dice: 0.6905\n",
      "07/02 17:03:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  900/32000]  base_lr: 6.0917e-06 lr: 6.0917e-07  eta: 1:22:02  time: 0.1574  data_time: 0.0088  memory: 5153  grad_norm: 396.8986  loss: 18.1485  decode.loss_cls: 0.0164  decode.loss_mask: 0.9716  decode.loss_dice: 0.7060  decode.d0.loss_cls: 0.6016  decode.d0.loss_mask: 1.2170  decode.d0.loss_dice: 0.8258  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 1.0148  decode.d1.loss_dice: 0.7036  decode.d2.loss_cls: 0.0384  decode.d2.loss_mask: 0.9941  decode.d2.loss_dice: 0.6803  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.9771  decode.d3.loss_dice: 0.6541  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.9609  decode.d4.loss_dice: 0.6480  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.9545  decode.d5.loss_dice: 0.6802  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 1.0327  decode.d6.loss_dice: 0.7176  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 1.0519  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 1.0031  decode.d8.loss_dice: 0.7438\n",
      "07/02 17:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  950/32000]  base_lr: 6.0829e-06 lr: 6.0829e-07  eta: 1:21:53  time: 0.1573  data_time: 0.0088  memory: 5152  grad_norm: 419.0626  loss: 20.3744  decode.loss_cls: 0.0153  decode.loss_mask: 1.1191  decode.loss_dice: 0.7946  decode.d0.loss_cls: 0.5589  decode.d0.loss_mask: 1.3786  decode.d0.loss_dice: 0.8809  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 1.1782  decode.d1.loss_dice: 0.8180  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 1.1296  decode.d2.loss_dice: 0.7720  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 1.1555  decode.d3.loss_dice: 0.7839  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 1.0953  decode.d4.loss_dice: 0.7491  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 1.0672  decode.d5.loss_dice: 0.7846  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 1.1531  decode.d6.loss_dice: 0.8178  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 1.1249  decode.d7.loss_dice: 0.8036  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 1.1358  decode.d8.loss_dice: 0.8033\n",
      "07/02 17:04:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:04:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1000/32000]  base_lr: 6.0741e-06 lr: 6.0741e-07  eta: 1:21:42  time: 0.1548  data_time: 0.0078  memory: 5153  grad_norm: 375.2390  loss: 20.1498  decode.loss_cls: 0.0158  decode.loss_mask: 1.0600  decode.loss_dice: 0.7903  decode.d0.loss_cls: 0.6118  decode.d0.loss_mask: 1.3957  decode.d0.loss_dice: 0.9445  decode.d1.loss_cls: 0.1025  decode.d1.loss_mask: 1.0703  decode.d1.loss_dice: 0.8461  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 1.0566  decode.d2.loss_dice: 0.8266  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 1.0653  decode.d3.loss_dice: 0.8714  decode.d4.loss_cls: 0.0260  decode.d4.loss_mask: 1.0517  decode.d4.loss_dice: 0.7962  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 1.0524  decode.d5.loss_dice: 0.8364  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 1.0266  decode.d6.loss_dice: 0.8342  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 1.0496  decode.d7.loss_dice: 0.7900  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 1.0441  decode.d8.loss_dice: 0.8018\n",
      "07/02 17:04:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:03  time: 0.0211  data_time: 0.0021  memory: 9531  \n",
      "07/02 17:04:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0288  data_time: 0.0063  memory: 9331  \n",
      "07/02 17:04:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:04:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 86.99 | 96.18 |\n",
      "|   lesion   | 60.74 | 67.81 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:04:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 89.1700  mIoU: 73.8700  mAcc: 82.0000  data_time: 0.0108  time: 0.0705\n",
      "07/02 17:04:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 73.8700 mIoU at 1000 iter is saved to best_mIoU_iter_1000.pth.\n",
      "07/02 17:04:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1050/32000]  base_lr: 6.0653e-06 lr: 6.0653e-07  eta: 1:21:48  time: 0.1553  data_time: 0.0086  memory: 5161  grad_norm: 339.1398  loss: 19.9493  decode.loss_cls: 0.0614  decode.loss_mask: 1.0881  decode.loss_dice: 0.7209  decode.d0.loss_cls: 0.7247  decode.d0.loss_mask: 1.4150  decode.d0.loss_dice: 0.7991  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 1.0745  decode.d1.loss_dice: 0.6753  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 1.1452  decode.d2.loss_dice: 0.7130  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 1.1257  decode.d3.loss_dice: 0.7178  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 1.1281  decode.d4.loss_dice: 0.7222  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 1.0981  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 1.0990  decode.d6.loss_dice: 0.7147  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 1.0804  decode.d7.loss_dice: 0.7258  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 1.0982  decode.d8.loss_dice: 0.7171\n",
      "07/02 17:04:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1100/32000]  base_lr: 6.0565e-06 lr: 6.0565e-07  eta: 1:21:43  time: 0.1793  data_time: 0.0098  memory: 5153  grad_norm: 310.0726  loss: 18.7037  decode.loss_cls: 0.0322  decode.loss_mask: 1.0109  decode.loss_dice: 0.7147  decode.d0.loss_cls: 0.5725  decode.d0.loss_mask: 1.2584  decode.d0.loss_dice: 0.7783  decode.d1.loss_cls: 0.1324  decode.d1.loss_mask: 1.0144  decode.d1.loss_dice: 0.7346  decode.d2.loss_cls: 0.0275  decode.d2.loss_mask: 1.0113  decode.d2.loss_dice: 0.7391  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 1.0636  decode.d3.loss_dice: 0.7430  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 1.0436  decode.d4.loss_dice: 0.7392  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 1.0095  decode.d5.loss_dice: 0.7244  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.9817  decode.d6.loss_dice: 0.7279  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 1.0297  decode.d7.loss_dice: 0.7260  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 1.0141  decode.d8.loss_dice: 0.7160\n",
      "07/02 17:04:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1150/32000]  base_lr: 6.0477e-06 lr: 6.0477e-07  eta: 1:21:31  time: 0.1574  data_time: 0.0102  memory: 5153  grad_norm: 344.9208  loss: 15.9269  decode.loss_cls: 0.0135  decode.loss_mask: 0.8769  decode.loss_dice: 0.5664  decode.d0.loss_cls: 0.4629  decode.d0.loss_mask: 1.1807  decode.d0.loss_dice: 0.7483  decode.d1.loss_cls: 0.0496  decode.d1.loss_mask: 0.9070  decode.d1.loss_dice: 0.5728  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.9408  decode.d2.loss_dice: 0.5943  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.9001  decode.d3.loss_dice: 0.6274  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.9396  decode.d4.loss_dice: 0.6237  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.9086  decode.d5.loss_dice: 0.5928  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.8721  decode.d6.loss_dice: 0.5598  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.8687  decode.d7.loss_dice: 0.5742  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.8983  decode.d8.loss_dice: 0.5600\n",
      "07/02 17:04:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1200/32000]  base_lr: 6.0388e-06 lr: 6.0388e-07  eta: 1:21:21  time: 0.1568  data_time: 0.0092  memory: 5153  grad_norm: 283.3088  loss: 17.8721  decode.loss_cls: 0.0049  decode.loss_mask: 0.9990  decode.loss_dice: 0.6667  decode.d0.loss_cls: 0.4611  decode.d0.loss_mask: 1.2632  decode.d0.loss_dice: 0.8320  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 1.0135  decode.d1.loss_dice: 0.6938  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 1.0106  decode.d2.loss_dice: 0.6681  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 1.0203  decode.d3.loss_dice: 0.6696  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 1.0191  decode.d4.loss_dice: 0.6774  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.9789  decode.d5.loss_dice: 0.6512  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 1.0287  decode.d6.loss_dice: 0.6859  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 1.0204  decode.d7.loss_dice: 0.6803  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 1.0221  decode.d8.loss_dice: 0.6819\n",
      "07/02 17:04:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1250/32000]  base_lr: 6.0300e-06 lr: 6.0300e-07  eta: 1:21:10  time: 0.1537  data_time: 0.0075  memory: 5153  grad_norm: 394.3929  loss: 17.9694  decode.loss_cls: 0.0314  decode.loss_mask: 0.9732  decode.loss_dice: 0.6546  decode.d0.loss_cls: 0.5241  decode.d0.loss_mask: 1.2097  decode.d0.loss_dice: 0.7737  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 1.0268  decode.d1.loss_dice: 0.6965  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 1.0404  decode.d2.loss_dice: 0.6751  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.9976  decode.d3.loss_dice: 0.6855  decode.d4.loss_cls: 0.0304  decode.d4.loss_mask: 1.0498  decode.d4.loss_dice: 0.6898  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.9825  decode.d5.loss_dice: 0.6778  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 1.0206  decode.d6.loss_dice: 0.6591  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 1.0194  decode.d7.loss_dice: 0.6575  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.9603  decode.d8.loss_dice: 0.6662\n",
      "07/02 17:04:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1300/32000]  base_lr: 6.0212e-06 lr: 6.0212e-07  eta: 1:21:00  time: 0.1559  data_time: 0.0097  memory: 5153  grad_norm: 304.7907  loss: 16.2693  decode.loss_cls: 0.0066  decode.loss_mask: 0.9506  decode.loss_dice: 0.5579  decode.d0.loss_cls: 0.4935  decode.d0.loss_mask: 1.2199  decode.d0.loss_dice: 0.7363  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.9782  decode.d1.loss_dice: 0.6012  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.9240  decode.d2.loss_dice: 0.5724  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.9548  decode.d3.loss_dice: 0.5880  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.9739  decode.d4.loss_dice: 0.5686  decode.d5.loss_cls: 0.0286  decode.d5.loss_mask: 0.9536  decode.d5.loss_dice: 0.5629  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.9338  decode.d6.loss_dice: 0.5788  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.9215  decode.d7.loss_dice: 0.5403  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.9127  decode.d8.loss_dice: 0.5402\n",
      "07/02 17:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1350/32000]  base_lr: 6.0124e-06 lr: 6.0124e-07  eta: 1:20:52  time: 0.1542  data_time: 0.0081  memory: 5153  grad_norm: 314.9257  loss: 20.0572  decode.loss_cls: 0.3726  decode.loss_mask: 0.9945  decode.loss_dice: 0.6289  decode.d0.loss_cls: 0.4856  decode.d0.loss_mask: 1.3457  decode.d0.loss_dice: 0.7989  decode.d1.loss_cls: 0.1699  decode.d1.loss_mask: 1.0734  decode.d1.loss_dice: 0.6690  decode.d2.loss_cls: 0.2095  decode.d2.loss_mask: 1.0425  decode.d2.loss_dice: 0.6427  decode.d3.loss_cls: 0.3070  decode.d3.loss_mask: 1.0265  decode.d3.loss_dice: 0.6368  decode.d4.loss_cls: 0.2492  decode.d4.loss_mask: 0.9917  decode.d4.loss_dice: 0.6352  decode.d5.loss_cls: 0.3117  decode.d5.loss_mask: 1.0087  decode.d5.loss_dice: 0.6281  decode.d6.loss_cls: 0.3265  decode.d6.loss_mask: 0.9937  decode.d6.loss_dice: 0.6289  decode.d7.loss_cls: 0.3273  decode.d7.loss_mask: 0.9994  decode.d7.loss_dice: 0.6282  decode.d8.loss_cls: 0.3386  decode.d8.loss_mask: 0.9806  decode.d8.loss_dice: 0.6061\n",
      "07/02 17:05:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1400/32000]  base_lr: 6.0035e-06 lr: 6.0035e-07  eta: 1:20:41  time: 0.1550  data_time: 0.0085  memory: 5152  grad_norm: 325.2387  loss: 18.6917  decode.loss_cls: 0.0347  decode.loss_mask: 1.0712  decode.loss_dice: 0.6566  decode.d0.loss_cls: 0.5763  decode.d0.loss_mask: 1.3050  decode.d0.loss_dice: 0.8201  decode.d1.loss_cls: 0.0920  decode.d1.loss_mask: 1.1131  decode.d1.loss_dice: 0.6961  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 1.0351  decode.d2.loss_dice: 0.6784  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 1.0223  decode.d3.loss_dice: 0.6440  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 1.0602  decode.d4.loss_dice: 0.6589  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 1.0604  decode.d5.loss_dice: 0.6829  decode.d6.loss_cls: 0.0365  decode.d6.loss_mask: 1.0414  decode.d6.loss_dice: 0.6581  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 1.0684  decode.d7.loss_dice: 0.6372  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 1.0938  decode.d8.loss_dice: 0.6513\n",
      "07/02 17:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1450/32000]  base_lr: 5.9947e-06 lr: 5.9947e-07  eta: 1:20:35  time: 0.1555  data_time: 0.0089  memory: 5153  grad_norm: 276.4905  loss: 14.9640  decode.loss_cls: 0.0043  decode.loss_mask: 0.8559  decode.loss_dice: 0.5249  decode.d0.loss_cls: 0.3771  decode.d0.loss_mask: 1.1367  decode.d0.loss_dice: 0.6952  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.8851  decode.d1.loss_dice: 0.5500  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.8801  decode.d2.loss_dice: 0.5389  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.8844  decode.d3.loss_dice: 0.5485  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 0.5375  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.8829  decode.d5.loss_dice: 0.5444  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.8568  decode.d6.loss_dice: 0.5208  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.8610  decode.d7.loss_dice: 0.5295  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.8507  decode.d8.loss_dice: 0.5233\n",
      "07/02 17:05:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1500/32000]  base_lr: 5.9859e-06 lr: 5.9859e-07  eta: 1:20:26  time: 0.1570  data_time: 0.0095  memory: 5153  grad_norm: 338.6656  loss: 16.9207  decode.loss_cls: 0.0092  decode.loss_mask: 1.0087  decode.loss_dice: 0.5964  decode.d0.loss_cls: 0.3415  decode.d0.loss_mask: 1.2276  decode.d0.loss_dice: 0.7227  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.9924  decode.d1.loss_dice: 0.5931  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 1.0305  decode.d2.loss_dice: 0.6078  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 1.0182  decode.d3.loss_dice: 0.5907  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 1.0355  decode.d4.loss_dice: 0.5992  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 1.0098  decode.d5.loss_dice: 0.6129  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.9935  decode.d6.loss_dice: 0.6194  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 1.0114  decode.d7.loss_dice: 0.5936  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 1.0296  decode.d8.loss_dice: 0.6117\n",
      "07/02 17:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1550/32000]  base_lr: 5.9770e-06 lr: 5.9770e-07  eta: 1:20:16  time: 0.1560  data_time: 0.0090  memory: 5153  grad_norm: 316.5599  loss: 16.2827  decode.loss_cls: 0.0026  decode.loss_mask: 0.9393  decode.loss_dice: 0.5654  decode.d0.loss_cls: 0.3754  decode.d0.loss_mask: 1.1904  decode.d0.loss_dice: 0.7095  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 1.0060  decode.d1.loss_dice: 0.5861  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.9276  decode.d2.loss_dice: 0.5884  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.9656  decode.d3.loss_dice: 0.5911  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.9621  decode.d4.loss_dice: 0.5734  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.9679  decode.d5.loss_dice: 0.5948  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.9658  decode.d6.loss_dice: 0.5833  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.9441  decode.d7.loss_dice: 0.5736  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.9463  decode.d8.loss_dice: 0.5702\n",
      "07/02 17:05:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1600/32000]  base_lr: 5.9682e-06 lr: 5.9682e-07  eta: 1:20:05  time: 0.1551  data_time: 0.0085  memory: 5153  grad_norm: 352.0717  loss: 18.2918  decode.loss_cls: 0.0062  decode.loss_mask: 1.0206  decode.loss_dice: 0.6314  decode.d0.loss_cls: 0.4371  decode.d0.loss_mask: 1.3000  decode.d0.loss_dice: 0.8691  decode.d1.loss_cls: 0.0596  decode.d1.loss_mask: 1.0988  decode.d1.loss_dice: 0.7271  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 1.0655  decode.d2.loss_dice: 0.6722  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 1.0499  decode.d3.loss_dice: 0.6693  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 1.0621  decode.d4.loss_dice: 0.6646  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 1.0708  decode.d5.loss_dice: 0.6829  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 1.0865  decode.d6.loss_dice: 0.6361  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 1.0636  decode.d7.loss_dice: 0.6392  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 1.0686  decode.d8.loss_dice: 0.6241\n",
      "07/02 17:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1650/32000]  base_lr: 5.9594e-06 lr: 5.9594e-07  eta: 1:19:55  time: 0.1554  data_time: 0.0089  memory: 5154  grad_norm: 300.3158  loss: 16.7843  decode.loss_cls: 0.0036  decode.loss_mask: 0.9572  decode.loss_dice: 0.5915  decode.d0.loss_cls: 0.4239  decode.d0.loss_mask: 1.2451  decode.d0.loss_dice: 0.8049  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 1.0278  decode.d1.loss_dice: 0.6550  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 1.0382  decode.d2.loss_dice: 0.6630  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.9881  decode.d3.loss_dice: 0.6250  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.9833  decode.d4.loss_dice: 0.6076  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 0.5935  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.9269  decode.d6.loss_dice: 0.5963  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.9254  decode.d7.loss_dice: 0.5803  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.9350  decode.d8.loss_dice: 0.5893\n",
      "07/02 17:05:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1700/32000]  base_lr: 5.9505e-06 lr: 5.9505e-07  eta: 1:19:44  time: 0.1546  data_time: 0.0086  memory: 5154  grad_norm: 247.6305  loss: 15.3740  decode.loss_cls: 0.0040  decode.loss_mask: 0.8662  decode.loss_dice: 0.5328  decode.d0.loss_cls: 0.4276  decode.d0.loss_mask: 1.0817  decode.d0.loss_dice: 0.6571  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.9486  decode.d1.loss_dice: 0.5921  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.9534  decode.d2.loss_dice: 0.5929  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.9416  decode.d3.loss_dice: 0.5926  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.9212  decode.d4.loss_dice: 0.5889  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.8728  decode.d5.loss_dice: 0.5833  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.8439  decode.d6.loss_dice: 0.5177  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.8504  decode.d7.loss_dice: 0.5141  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.8770  decode.d8.loss_dice: 0.5166\n",
      "07/02 17:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1750/32000]  base_lr: 5.9417e-06 lr: 5.9417e-07  eta: 1:19:34  time: 0.1562  data_time: 0.0086  memory: 5154  grad_norm: 337.3474  loss: 18.6724  decode.loss_cls: 0.0051  decode.loss_mask: 1.0746  decode.loss_dice: 0.6851  decode.d0.loss_cls: 0.4141  decode.d0.loss_mask: 1.2445  decode.d0.loss_dice: 0.8314  decode.d1.loss_cls: 0.0453  decode.d1.loss_mask: 1.1095  decode.d1.loss_dice: 0.7629  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 1.0719  decode.d2.loss_dice: 0.7374  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 1.0872  decode.d3.loss_dice: 0.7179  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 1.1079  decode.d4.loss_dice: 0.7198  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 1.0823  decode.d5.loss_dice: 0.6711  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 1.0316  decode.d6.loss_dice: 0.6797  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 1.0424  decode.d7.loss_dice: 0.6979  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 1.0593  decode.d8.loss_dice: 0.6971\n",
      "07/02 17:06:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1800/32000]  base_lr: 5.9329e-06 lr: 5.9329e-07  eta: 1:19:24  time: 0.1552  data_time: 0.0084  memory: 5153  grad_norm: 266.2456  loss: 15.9694  decode.loss_cls: 0.0049  decode.loss_mask: 0.8940  decode.loss_dice: 0.5563  decode.d0.loss_cls: 0.3329  decode.d0.loss_mask: 1.1899  decode.d0.loss_dice: 0.7104  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.9860  decode.d1.loss_dice: 0.6448  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.9618  decode.d2.loss_dice: 0.5949  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.9187  decode.d3.loss_dice: 0.6013  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.9463  decode.d4.loss_dice: 0.5869  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.9201  decode.d5.loss_dice: 0.5946  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.9151  decode.d6.loss_dice: 0.5861  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.8877  decode.d7.loss_dice: 0.5602  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.9005  decode.d8.loss_dice: 0.5701\n",
      "07/02 17:06:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1850/32000]  base_lr: 5.9240e-06 lr: 5.9240e-07  eta: 1:19:14  time: 0.1550  data_time: 0.0084  memory: 5153  grad_norm: 353.4550  loss: 16.8686  decode.loss_cls: 0.0179  decode.loss_mask: 0.9662  decode.loss_dice: 0.5913  decode.d0.loss_cls: 0.3845  decode.d0.loss_mask: 1.1910  decode.d0.loss_dice: 0.6758  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 1.0425  decode.d1.loss_dice: 0.6504  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 1.0012  decode.d2.loss_dice: 0.6397  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 1.0063  decode.d3.loss_dice: 0.6251  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.9932  decode.d4.loss_dice: 0.6243  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.9555  decode.d5.loss_dice: 0.6018  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 0.9537  decode.d6.loss_dice: 0.5879  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.9484  decode.d7.loss_dice: 0.5701  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.9392  decode.d8.loss_dice: 0.5953\n",
      "07/02 17:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1900/32000]  base_lr: 5.9152e-06 lr: 5.9152e-07  eta: 1:19:05  time: 0.1562  data_time: 0.0097  memory: 5153  grad_norm: 288.4304  loss: 17.3339  decode.loss_cls: 0.0037  decode.loss_mask: 1.0580  decode.loss_dice: 0.5808  decode.d0.loss_cls: 0.3503  decode.d0.loss_mask: 1.3362  decode.d0.loss_dice: 0.7172  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 1.0672  decode.d1.loss_dice: 0.6261  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 1.0681  decode.d2.loss_dice: 0.6035  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 1.0646  decode.d3.loss_dice: 0.5992  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 1.0606  decode.d4.loss_dice: 0.6312  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 1.0407  decode.d5.loss_dice: 0.6265  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 1.0140  decode.d6.loss_dice: 0.5764  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 1.0302  decode.d7.loss_dice: 0.5897  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 1.0180  decode.d8.loss_dice: 0.5855\n",
      "07/02 17:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1950/32000]  base_lr: 5.9063e-06 lr: 5.9063e-07  eta: 1:18:57  time: 0.1556  data_time: 0.0096  memory: 5153  grad_norm: 263.1141  loss: 15.3259  decode.loss_cls: 0.0141  decode.loss_mask: 0.8737  decode.loss_dice: 0.5375  decode.d0.loss_cls: 0.3983  decode.d0.loss_mask: 1.0920  decode.d0.loss_dice: 0.6800  decode.d1.loss_cls: 0.1037  decode.d1.loss_mask: 0.9209  decode.d1.loss_dice: 0.5994  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.8753  decode.d2.loss_dice: 0.5477  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 0.5691  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.8701  decode.d4.loss_dice: 0.5689  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.8588  decode.d5.loss_dice: 0.5437  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.8659  decode.d6.loss_dice: 0.5270  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.8711  decode.d7.loss_dice: 0.5286  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.8579  decode.d8.loss_dice: 0.5265\n",
      "07/02 17:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2000/32000]  base_lr: 5.8975e-06 lr: 5.8975e-07  eta: 1:18:48  time: 0.1563  data_time: 0.0095  memory: 5153  grad_norm: 329.8978  loss: 19.7669  decode.loss_cls: 0.0077  decode.loss_mask: 1.1602  decode.loss_dice: 0.6965  decode.d0.loss_cls: 0.4351  decode.d0.loss_mask: 1.3784  decode.d0.loss_dice: 0.8213  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 1.1952  decode.d1.loss_dice: 0.7527  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 1.2128  decode.d2.loss_dice: 0.7060  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 1.2309  decode.d3.loss_dice: 0.7116  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 1.2104  decode.d4.loss_dice: 0.7258  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 1.1768  decode.d5.loss_dice: 0.7147  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 1.1329  decode.d6.loss_dice: 0.6877  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 1.1540  decode.d7.loss_dice: 0.6929  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 1.1427  decode.d8.loss_dice: 0.6959\n",
      "07/02 17:06:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0215  data_time: 0.0022  memory: 2165  \n",
      "07/02 17:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0289  data_time: 0.0063  memory: 1073  \n",
      "07/02 17:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 88.03 | 95.63 |\n",
      "|   lesion   | 65.04 |  73.7 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 90.2100  mIoU: 76.5400  mAcc: 84.6600  data_time: 0.0114  time: 0.0368\n",
      "07/02 17:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_1000.pth is removed\n",
      "07/02 17:06:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 76.5400 mIoU at 2000 iter is saved to best_mIoU_iter_2000.pth.\n",
      "07/02 17:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2050/32000]  base_lr: 5.8886e-06 lr: 5.8886e-07  eta: 1:18:47  time: 0.1570  data_time: 0.0091  memory: 5154  grad_norm: 360.8798  loss: 20.6965  decode.loss_cls: 0.0112  decode.loss_mask: 1.2205  decode.loss_dice: 0.6891  decode.d0.loss_cls: 0.4583  decode.d0.loss_mask: 1.4257  decode.d0.loss_dice: 0.8685  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 1.2671  decode.d1.loss_dice: 0.7686  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 1.2320  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 1.2462  decode.d3.loss_dice: 0.7329  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 1.2086  decode.d4.loss_dice: 0.7299  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 1.2647  decode.d5.loss_dice: 0.7422  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 1.2650  decode.d6.loss_dice: 0.7213  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 1.2653  decode.d7.loss_dice: 0.7092  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 1.2292  decode.d8.loss_dice: 0.7101\n",
      "07/02 17:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2100/32000]  base_lr: 5.8798e-06 lr: 5.8798e-07  eta: 1:18:37  time: 0.1540  data_time: 0.0076  memory: 5152  grad_norm: 309.8793  loss: 17.1603  decode.loss_cls: 0.0080  decode.loss_mask: 0.9546  decode.loss_dice: 0.5973  decode.d0.loss_cls: 0.3680  decode.d0.loss_mask: 1.2568  decode.d0.loss_dice: 0.7940  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 1.0239  decode.d1.loss_dice: 0.6786  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 1.0087  decode.d2.loss_dice: 0.6310  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 1.0137  decode.d3.loss_dice: 0.6697  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.9873  decode.d4.loss_dice: 0.6360  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.9549  decode.d5.loss_dice: 0.6362  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.9690  decode.d6.loss_dice: 0.6244  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.9637  decode.d7.loss_dice: 0.6050  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 1.0004  decode.d8.loss_dice: 0.6219\n",
      "07/02 17:07:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2150/32000]  base_lr: 5.8709e-06 lr: 5.8709e-07  eta: 1:18:27  time: 0.1544  data_time: 0.0076  memory: 5153  grad_norm: 263.8140  loss: 16.0654  decode.loss_cls: 0.0053  decode.loss_mask: 0.9124  decode.loss_dice: 0.5581  decode.d0.loss_cls: 0.3302  decode.d0.loss_mask: 1.1691  decode.d0.loss_dice: 0.7112  decode.d1.loss_cls: 0.0871  decode.d1.loss_mask: 0.9029  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.9127  decode.d2.loss_dice: 0.5862  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.9200  decode.d3.loss_dice: 0.6102  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.9331  decode.d4.loss_dice: 0.5773  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.9374  decode.d5.loss_dice: 0.5694  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.9457  decode.d6.loss_dice: 0.6074  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.9323  decode.d7.loss_dice: 0.5873  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.9469  decode.d8.loss_dice: 0.6041\n",
      "07/02 17:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2200/32000]  base_lr: 5.8621e-06 lr: 5.8621e-07  eta: 1:18:17  time: 0.1536  data_time: 0.0070  memory: 5154  grad_norm: 270.0269  loss: 13.6216  decode.loss_cls: 0.0054  decode.loss_mask: 0.7360  decode.loss_dice: 0.4847  decode.d0.loss_cls: 0.3534  decode.d0.loss_mask: 0.9854  decode.d0.loss_dice: 0.6759  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.7802  decode.d1.loss_dice: 0.5411  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.7814  decode.d2.loss_dice: 0.5095  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.7638  decode.d3.loss_dice: 0.5178  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.7575  decode.d4.loss_dice: 0.5303  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.7766  decode.d5.loss_dice: 0.5052  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.7700  decode.d6.loss_dice: 0.4924  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.7555  decode.d7.loss_dice: 0.4676  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.7438  decode.d8.loss_dice: 0.4929\n",
      "07/02 17:07:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2250/32000]  base_lr: 5.8532e-06 lr: 5.8532e-07  eta: 1:18:08  time: 0.1560  data_time: 0.0085  memory: 5154  grad_norm: 261.3558  loss: 16.8948  decode.loss_cls: 0.0116  decode.loss_mask: 0.9798  decode.loss_dice: 0.5868  decode.d0.loss_cls: 0.3268  decode.d0.loss_mask: 1.2282  decode.d0.loss_dice: 0.6967  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 1.0281  decode.d1.loss_dice: 0.6642  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 1.0306  decode.d2.loss_dice: 0.6348  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 1.0317  decode.d3.loss_dice: 0.6217  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.9897  decode.d4.loss_dice: 0.5898  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.9708  decode.d5.loss_dice: 0.5930  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.9726  decode.d6.loss_dice: 0.5860  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.9712  decode.d7.loss_dice: 0.5970  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.9731  decode.d8.loss_dice: 0.5938\n",
      "07/02 17:07:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2300/32000]  base_lr: 5.8444e-06 lr: 5.8444e-07  eta: 1:17:59  time: 0.1551  data_time: 0.0077  memory: 5153  grad_norm: 294.2426  loss: 17.7939  decode.loss_cls: 0.0083  decode.loss_mask: 0.9590  decode.loss_dice: 0.6496  decode.d0.loss_cls: 0.3567  decode.d0.loss_mask: 1.3101  decode.d0.loss_dice: 0.8107  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 1.0816  decode.d1.loss_dice: 0.7118  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 1.0687  decode.d2.loss_dice: 0.7302  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 1.0030  decode.d3.loss_dice: 0.6975  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.9977  decode.d4.loss_dice: 0.7048  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.9787  decode.d5.loss_dice: 0.6772  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.9941  decode.d6.loss_dice: 0.6544  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.9819  decode.d7.loss_dice: 0.6582  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.9745  decode.d8.loss_dice: 0.6667\n",
      "07/02 17:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2350/32000]  base_lr: 5.8355e-06 lr: 5.8355e-07  eta: 1:17:49  time: 0.1558  data_time: 0.0082  memory: 5153  grad_norm: 236.3703  loss: 14.2089  decode.loss_cls: 0.0538  decode.loss_mask: 0.8000  decode.loss_dice: 0.4947  decode.d0.loss_cls: 0.3328  decode.d0.loss_mask: 1.0918  decode.d0.loss_dice: 0.6079  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.8521  decode.d1.loss_dice: 0.5274  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.8013  decode.d2.loss_dice: 0.4801  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.8616  decode.d3.loss_dice: 0.5199  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 0.5230  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.8268  decode.d5.loss_dice: 0.5168  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.8164  decode.d6.loss_dice: 0.4952  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.8123  decode.d7.loss_dice: 0.4949  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.8350  decode.d8.loss_dice: 0.4910\n",
      "07/02 17:07:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2400/32000]  base_lr: 5.8267e-06 lr: 5.8267e-07  eta: 1:17:40  time: 0.1550  data_time: 0.0078  memory: 5153  grad_norm: 230.8496  loss: 14.7005  decode.loss_cls: 0.0019  decode.loss_mask: 0.8430  decode.loss_dice: 0.5412  decode.d0.loss_cls: 0.2117  decode.d0.loss_mask: 1.0714  decode.d0.loss_dice: 0.6324  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.8684  decode.d1.loss_dice: 0.5745  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.8407  decode.d2.loss_dice: 0.5389  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.8968  decode.d3.loss_dice: 0.5675  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.9002  decode.d4.loss_dice: 0.5554  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.8578  decode.d5.loss_dice: 0.5549  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.8474  decode.d6.loss_dice: 0.5639  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.8505  decode.d7.loss_dice: 0.5274  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.8396  decode.d8.loss_dice: 0.5463\n",
      "07/02 17:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2450/32000]  base_lr: 5.8178e-06 lr: 5.8178e-07  eta: 1:17:31  time: 0.1539  data_time: 0.0072  memory: 5153  grad_norm: 221.7848  loss: 12.5606  decode.loss_cls: 0.0016  decode.loss_mask: 0.6818  decode.loss_dice: 0.4379  decode.d0.loss_cls: 0.2928  decode.d0.loss_mask: 0.9954  decode.d0.loss_dice: 0.6272  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.8026  decode.d1.loss_dice: 0.5475  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.7752  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.7218  decode.d3.loss_dice: 0.4643  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.7105  decode.d4.loss_dice: 0.4573  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.6961  decode.d5.loss_dice: 0.4450  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.6866  decode.d6.loss_dice: 0.4309  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.6889  decode.d7.loss_dice: 0.4351  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.6872  decode.d8.loss_dice: 0.4396\n",
      "07/02 17:08:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2500/32000]  base_lr: 5.8089e-06 lr: 5.8089e-07  eta: 1:17:21  time: 0.1528  data_time: 0.0064  memory: 5153  grad_norm: 293.4792  loss: 17.4963  decode.loss_cls: 0.0080  decode.loss_mask: 1.0222  decode.loss_dice: 0.6529  decode.d0.loss_cls: 0.3505  decode.d0.loss_mask: 1.2678  decode.d0.loss_dice: 0.7927  decode.d1.loss_cls: 0.0453  decode.d1.loss_mask: 1.0462  decode.d1.loss_dice: 0.6711  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 1.0108  decode.d2.loss_dice: 0.6361  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 1.0220  decode.d3.loss_dice: 0.6845  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.9920  decode.d4.loss_dice: 0.6662  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 1.0078  decode.d5.loss_dice: 0.6605  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.9820  decode.d6.loss_dice: 0.6366  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.9809  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 1.0038  decode.d8.loss_dice: 0.6536\n",
      "07/02 17:08:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2550/32000]  base_lr: 5.8001e-06 lr: 5.8001e-07  eta: 1:17:13  time: 0.1572  data_time: 0.0090  memory: 5153  grad_norm: 171.7646  loss: 13.7864  decode.loss_cls: 0.0038  decode.loss_mask: 0.7499  decode.loss_dice: 0.5505  decode.d0.loss_cls: 0.2396  decode.d0.loss_mask: 0.9609  decode.d0.loss_dice: 0.6569  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.7759  decode.d1.loss_dice: 0.5774  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.7811  decode.d2.loss_dice: 0.5628  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.7677  decode.d3.loss_dice: 0.5591  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.7706  decode.d4.loss_dice: 0.5537  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.7614  decode.d5.loss_dice: 0.5674  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.7459  decode.d6.loss_dice: 0.5495  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.7498  decode.d7.loss_dice: 0.5587  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 0.5450\n",
      "07/02 17:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2600/32000]  base_lr: 5.7912e-06 lr: 5.7912e-07  eta: 1:17:04  time: 0.1545  data_time: 0.0077  memory: 5154  grad_norm: 287.7231  loss: 17.2228  decode.loss_cls: 0.0061  decode.loss_mask: 0.9936  decode.loss_dice: 0.6067  decode.d0.loss_cls: 0.2795  decode.d0.loss_mask: 1.2218  decode.d0.loss_dice: 0.7637  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 1.0492  decode.d1.loss_dice: 0.6832  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 1.0431  decode.d2.loss_dice: 0.6497  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 1.0221  decode.d3.loss_dice: 0.6267  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 1.0322  decode.d4.loss_dice: 0.6364  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.9945  decode.d5.loss_dice: 0.6239  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 1.0093  decode.d6.loss_dice: 0.6300  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 1.0006  decode.d7.loss_dice: 0.6299  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 1.0085  decode.d8.loss_dice: 0.6057\n",
      "07/02 17:08:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2650/32000]  base_lr: 5.7824e-06 lr: 5.7824e-07  eta: 1:16:57  time: 0.1562  data_time: 0.0084  memory: 5154  grad_norm: 248.7448  loss: 14.3645  decode.loss_cls: 0.0028  decode.loss_mask: 0.8158  decode.loss_dice: 0.5171  decode.d0.loss_cls: 0.2277  decode.d0.loss_mask: 1.0505  decode.d0.loss_dice: 0.6338  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.9170  decode.d1.loss_dice: 0.5182  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.8760  decode.d2.loss_dice: 0.5478  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.8304  decode.d3.loss_dice: 0.5504  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.8559  decode.d4.loss_dice: 0.5155  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.8458  decode.d5.loss_dice: 0.5425  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.8282  decode.d6.loss_dice: 0.5648  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.8210  decode.d7.loss_dice: 0.5344  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.8009  decode.d8.loss_dice: 0.5154\n",
      "07/02 17:08:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2700/32000]  base_lr: 5.7735e-06 lr: 5.7735e-07  eta: 1:16:49  time: 0.1583  data_time: 0.0085  memory: 5153  grad_norm: 271.2139  loss: 17.3983  decode.loss_cls: 0.1492  decode.loss_mask: 1.0010  decode.loss_dice: 0.5941  decode.d0.loss_cls: 0.3339  decode.d0.loss_mask: 1.2092  decode.d0.loss_dice: 0.7460  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 1.0225  decode.d1.loss_dice: 0.6079  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.9851  decode.d2.loss_dice: 0.6053  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.9574  decode.d3.loss_dice: 0.5932  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.9983  decode.d4.loss_dice: 0.6143  decode.d5.loss_cls: 0.1609  decode.d5.loss_mask: 0.9763  decode.d5.loss_dice: 0.5965  decode.d6.loss_cls: 0.1428  decode.d6.loss_mask: 0.9345  decode.d6.loss_dice: 0.5940  decode.d7.loss_cls: 0.1486  decode.d7.loss_mask: 0.9710  decode.d7.loss_dice: 0.6028  decode.d8.loss_cls: 0.1470  decode.d8.loss_mask: 0.9763  decode.d8.loss_dice: 0.6138\n",
      "07/02 17:08:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2750/32000]  base_lr: 5.7646e-06 lr: 5.7646e-07  eta: 1:16:41  time: 0.1558  data_time: 0.0080  memory: 5153  grad_norm: 241.9711  loss: 12.5251  decode.loss_cls: 0.0240  decode.loss_mask: 0.6874  decode.loss_dice: 0.4399  decode.d0.loss_cls: 0.2588  decode.d0.loss_mask: 0.9424  decode.d0.loss_dice: 0.5724  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.7520  decode.d1.loss_dice: 0.4926  decode.d2.loss_cls: 0.0741  decode.d2.loss_mask: 0.7271  decode.d2.loss_dice: 0.4659  decode.d3.loss_cls: 0.1066  decode.d3.loss_mask: 0.6782  decode.d3.loss_dice: 0.4465  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 0.4333  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.6973  decode.d5.loss_dice: 0.4438  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.6902  decode.d6.loss_dice: 0.4504  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.6856  decode.d7.loss_dice: 0.4452  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.6999  decode.d8.loss_dice: 0.4526\n",
      "07/02 17:08:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2800/32000]  base_lr: 5.7557e-06 lr: 5.7557e-07  eta: 1:16:32  time: 0.1544  data_time: 0.0076  memory: 5153  grad_norm: 296.5439  loss: 16.6989  decode.loss_cls: 0.0056  decode.loss_mask: 0.9636  decode.loss_dice: 0.5821  decode.d0.loss_cls: 0.2161  decode.d0.loss_mask: 1.2063  decode.d0.loss_dice: 0.7357  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.9864  decode.d1.loss_dice: 0.6458  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.9888  decode.d2.loss_dice: 0.6255  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.9717  decode.d3.loss_dice: 0.6183  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.9694  decode.d4.loss_dice: 0.6087  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 1.0008  decode.d5.loss_dice: 0.6113  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 1.0046  decode.d6.loss_dice: 0.6260  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 1.0287  decode.d7.loss_dice: 0.6197  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 1.0123  decode.d8.loss_dice: 0.6131\n",
      "07/02 17:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2850/32000]  base_lr: 5.7469e-06 lr: 5.7469e-07  eta: 1:16:23  time: 0.1540  data_time: 0.0085  memory: 5153  grad_norm: 276.4253  loss: 16.7409  decode.loss_cls: 0.0130  decode.loss_mask: 0.9175  decode.loss_dice: 0.5760  decode.d0.loss_cls: 0.2574  decode.d0.loss_mask: 1.2971  decode.d0.loss_dice: 0.8243  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.9701  decode.d1.loss_dice: 0.6337  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 1.0183  decode.d2.loss_dice: 0.6527  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.9775  decode.d3.loss_dice: 0.6093  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.9949  decode.d4.loss_dice: 0.6397  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.9904  decode.d5.loss_dice: 0.6119  decode.d6.loss_cls: 0.0209  decode.d6.loss_mask: 0.9599  decode.d6.loss_dice: 0.5884  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.9499  decode.d7.loss_dice: 0.6054  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.9470  decode.d8.loss_dice: 0.5905\n",
      "07/02 17:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2900/32000]  base_lr: 5.7380e-06 lr: 5.7380e-07  eta: 1:16:16  time: 0.1560  data_time: 0.0101  memory: 5153  grad_norm: 245.3439  loss: 14.6395  decode.loss_cls: 0.0021  decode.loss_mask: 0.8420  decode.loss_dice: 0.5494  decode.d0.loss_cls: 0.2720  decode.d0.loss_mask: 0.9958  decode.d0.loss_dice: 0.6547  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.8645  decode.d1.loss_dice: 0.5957  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.8509  decode.d2.loss_dice: 0.5597  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.8416  decode.d3.loss_dice: 0.5323  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.8529  decode.d4.loss_dice: 0.5389  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.8482  decode.d5.loss_dice: 0.5314  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.8526  decode.d6.loss_dice: 0.5440  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.8618  decode.d7.loss_dice: 0.5474  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.8588  decode.d8.loss_dice: 0.5575\n",
      "07/02 17:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2950/32000]  base_lr: 5.7291e-06 lr: 5.7291e-07  eta: 1:16:08  time: 0.1577  data_time: 0.0104  memory: 5153  grad_norm: 304.4096  loss: 18.4098  decode.loss_cls: 0.0114  decode.loss_mask: 1.0348  decode.loss_dice: 0.6747  decode.d0.loss_cls: 0.2859  decode.d0.loss_mask: 1.3030  decode.d0.loss_dice: 0.8374  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 1.1359  decode.d1.loss_dice: 0.7431  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 1.1313  decode.d2.loss_dice: 0.6895  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 1.1134  decode.d3.loss_dice: 0.6863  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 1.0091  decode.d4.loss_dice: 0.6687  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 1.0560  decode.d5.loss_dice: 0.6905  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 1.0498  decode.d6.loss_dice: 0.6691  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 1.0420  decode.d7.loss_dice: 0.6935  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 1.0548  decode.d8.loss_dice: 0.7023\n",
      "07/02 17:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3000/32000]  base_lr: 5.7203e-06 lr: 5.7203e-07  eta: 1:15:59  time: 0.1574  data_time: 0.0094  memory: 5153  grad_norm: 221.9303  loss: 13.2996  decode.loss_cls: 0.0024  decode.loss_mask: 0.7418  decode.loss_dice: 0.4872  decode.d0.loss_cls: 0.2484  decode.d0.loss_mask: 1.0285  decode.d0.loss_dice: 0.6401  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.8036  decode.d1.loss_dice: 0.5112  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.8244  decode.d2.loss_dice: 0.5094  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.7928  decode.d3.loss_dice: 0.4892  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.7730  decode.d4.loss_dice: 0.4735  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.7766  decode.d5.loss_dice: 0.4736  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.7834  decode.d6.loss_dice: 0.4589  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.7570  decode.d7.loss_dice: 0.4566  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 0.4684\n",
      "07/02 17:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0211  data_time: 0.0020  memory: 2165  \n",
      "07/02 17:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0287  data_time: 0.0062  memory: 1073  \n",
      "07/02 17:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background |  87.7 | 95.03 |\n",
      "|   lesion   | 64.73 | 74.52 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 89.9700  mIoU: 76.2200  mAcc: 84.7800  data_time: 0.0113  time: 0.0364\n",
      "07/02 17:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3050/32000]  base_lr: 5.7114e-06 lr: 5.7114e-07  eta: 1:15:51  time: 0.1552  data_time: 0.0084  memory: 5154  grad_norm: 342.9487  loss: 15.6927  decode.loss_cls: 0.0099  decode.loss_mask: 0.9457  decode.loss_dice: 0.6024  decode.d0.loss_cls: 0.2150  decode.d0.loss_mask: 1.0832  decode.d0.loss_dice: 0.7433  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.8632  decode.d1.loss_dice: 0.5953  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 0.5966  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.9126  decode.d3.loss_dice: 0.6149  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.8942  decode.d4.loss_dice: 0.6013  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.9150  decode.d5.loss_dice: 0.6040  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.9236  decode.d6.loss_dice: 0.6018  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.9055  decode.d7.loss_dice: 0.5858  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.9164  decode.d8.loss_dice: 0.5918\n",
      "07/02 17:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3100/32000]  base_lr: 5.7025e-06 lr: 5.7025e-07  eta: 1:15:43  time: 0.1577  data_time: 0.0097  memory: 5153  grad_norm: 204.5003  loss: 14.1011  decode.loss_cls: 0.0049  decode.loss_mask: 0.8061  decode.loss_dice: 0.4971  decode.d0.loss_cls: 0.2157  decode.d0.loss_mask: 1.0604  decode.d0.loss_dice: 0.6699  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.8594  decode.d1.loss_dice: 0.5411  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.8528  decode.d2.loss_dice: 0.5387  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.8294  decode.d3.loss_dice: 0.5293  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.8336  decode.d4.loss_dice: 0.5063  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.8438  decode.d5.loss_dice: 0.5249  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.8142  decode.d6.loss_dice: 0.4929  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.8172  decode.d7.loss_dice: 0.4911  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.8077  decode.d8.loss_dice: 0.4985\n",
      "07/02 17:09:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3150/32000]  base_lr: 5.6936e-06 lr: 5.6936e-07  eta: 1:15:35  time: 0.1549  data_time: 0.0082  memory: 5154  grad_norm: 240.2903  loss: 14.8907  decode.loss_cls: 0.0034  decode.loss_mask: 0.8521  decode.loss_dice: 0.5366  decode.d0.loss_cls: 0.2644  decode.d0.loss_mask: 1.1286  decode.d0.loss_dice: 0.6819  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.9361  decode.d1.loss_dice: 0.5674  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.9403  decode.d2.loss_dice: 0.5427  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.9160  decode.d3.loss_dice: 0.5361  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.8787  decode.d4.loss_dice: 0.5486  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.8687  decode.d5.loss_dice: 0.5233  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.8498  decode.d6.loss_dice: 0.5046  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.8575  decode.d7.loss_dice: 0.5147  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.8499  decode.d8.loss_dice: 0.5213\n",
      "07/02 17:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3200/32000]  base_lr: 5.6847e-06 lr: 5.6847e-07  eta: 1:15:27  time: 0.1555  data_time: 0.0096  memory: 5153  grad_norm: 348.8338  loss: 18.7020  decode.loss_cls: 0.0548  decode.loss_mask: 1.0878  decode.loss_dice: 0.6926  decode.d0.loss_cls: 0.2119  decode.d0.loss_mask: 1.2832  decode.d0.loss_dice: 0.8291  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 1.1188  decode.d1.loss_dice: 0.7283  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 1.0948  decode.d2.loss_dice: 0.7066  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 1.1128  decode.d3.loss_dice: 0.7021  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 1.1162  decode.d4.loss_dice: 0.6893  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 1.0642  decode.d5.loss_dice: 0.6862  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 1.0557  decode.d6.loss_dice: 0.6835  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 1.0586  decode.d7.loss_dice: 0.6815  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 1.0555  decode.d8.loss_dice: 0.6832\n",
      "07/02 17:10:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3250/32000]  base_lr: 5.6759e-06 lr: 5.6759e-07  eta: 1:15:18  time: 0.1563  data_time: 0.0102  memory: 5153  grad_norm: 248.2303  loss: 14.3291  decode.loss_cls: 0.0033  decode.loss_mask: 0.7922  decode.loss_dice: 0.4838  decode.d0.loss_cls: 0.1783  decode.d0.loss_mask: 1.1826  decode.d0.loss_dice: 0.6898  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.8546  decode.d1.loss_dice: 0.5311  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.8758  decode.d2.loss_dice: 0.5250  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.8425  decode.d3.loss_dice: 0.5303  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.8564  decode.d4.loss_dice: 0.5387  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.8439  decode.d5.loss_dice: 0.5389  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.8611  decode.d6.loss_dice: 0.5059  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.8343  decode.d7.loss_dice: 0.5037  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8150  decode.d8.loss_dice: 0.5034\n",
      "07/02 17:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3300/32000]  base_lr: 5.6670e-06 lr: 5.6670e-07  eta: 1:15:10  time: 0.1565  data_time: 0.0090  memory: 5154  grad_norm: 163.2974  loss: 12.1010  decode.loss_cls: 0.0016  decode.loss_mask: 0.6768  decode.loss_dice: 0.4402  decode.d0.loss_cls: 0.1578  decode.d0.loss_mask: 0.9562  decode.d0.loss_dice: 0.6059  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 0.5081  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.7275  decode.d2.loss_dice: 0.4534  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.7064  decode.d3.loss_dice: 0.4412  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.6873  decode.d4.loss_dice: 0.4477  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.6854  decode.d5.loss_dice: 0.4502  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.6922  decode.d6.loss_dice: 0.4305  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.6954  decode.d7.loss_dice: 0.4303  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.6873  decode.d8.loss_dice: 0.4317\n",
      "07/02 17:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3350/32000]  base_lr: 5.6581e-06 lr: 5.6581e-07  eta: 1:15:02  time: 0.1567  data_time: 0.0092  memory: 5152  grad_norm: 219.9622  loss: 12.9053  decode.loss_cls: 0.0017  decode.loss_mask: 0.7263  decode.loss_dice: 0.4509  decode.d0.loss_cls: 0.2000  decode.d0.loss_mask: 1.0178  decode.d0.loss_dice: 0.6391  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.7495  decode.d1.loss_dice: 0.5023  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 0.4626  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.7541  decode.d3.loss_dice: 0.4999  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.7872  decode.d4.loss_dice: 0.5049  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.7623  decode.d5.loss_dice: 0.4843  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.7200  decode.d6.loss_dice: 0.4515  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.7334  decode.d7.loss_dice: 0.4563  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.7300  decode.d8.loss_dice: 0.4632\n",
      "07/02 17:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3400/32000]  base_lr: 5.6492e-06 lr: 5.6492e-07  eta: 1:14:54  time: 0.1574  data_time: 0.0092  memory: 5153  grad_norm: 190.7995  loss: 13.6549  decode.loss_cls: 0.0009  decode.loss_mask: 0.7913  decode.loss_dice: 0.4739  decode.d0.loss_cls: 0.1943  decode.d0.loss_mask: 0.9933  decode.d0.loss_dice: 0.6023  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.8379  decode.d1.loss_dice: 0.5171  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.8818  decode.d2.loss_dice: 0.5054  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.8653  decode.d3.loss_dice: 0.4739  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.8161  decode.d4.loss_dice: 0.4876  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.8366  decode.d5.loss_dice: 0.4928  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.8047  decode.d6.loss_dice: 0.4668  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.8110  decode.d7.loss_dice: 0.4779  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.8063  decode.d8.loss_dice: 0.4788\n",
      "07/02 17:10:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3450/32000]  base_lr: 5.6403e-06 lr: 5.6403e-07  eta: 1:14:47  time: 0.1574  data_time: 0.0096  memory: 5153  grad_norm: 150.3820  loss: 11.5582  decode.loss_cls: 0.0014  decode.loss_mask: 0.6591  decode.loss_dice: 0.4169  decode.d0.loss_cls: 0.1708  decode.d0.loss_mask: 0.9480  decode.d0.loss_dice: 0.5758  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.6719  decode.d1.loss_dice: 0.4574  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.6357  decode.d2.loss_dice: 0.4219  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.6572  decode.d3.loss_dice: 0.4279  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.6442  decode.d4.loss_dice: 0.4230  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.6692  decode.d5.loss_dice: 0.4401  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.6646  decode.d6.loss_dice: 0.4289  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.6436  decode.d7.loss_dice: 0.4260  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.6577  decode.d8.loss_dice: 0.4209\n",
      "07/02 17:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3500/32000]  base_lr: 5.6314e-06 lr: 5.6314e-07  eta: 1:14:39  time: 0.1569  data_time: 0.0092  memory: 5153  grad_norm: 259.8346  loss: 20.3455  decode.loss_cls: 0.3234  decode.loss_mask: 1.0396  decode.loss_dice: 0.6635  decode.d0.loss_cls: 0.2781  decode.d0.loss_mask: 1.2376  decode.d0.loss_dice: 0.8725  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 1.0865  decode.d1.loss_dice: 0.7390  decode.d2.loss_cls: 0.2410  decode.d2.loss_mask: 1.0969  decode.d2.loss_dice: 0.7604  decode.d3.loss_cls: 0.2168  decode.d3.loss_mask: 1.0951  decode.d3.loss_dice: 0.7436  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 1.0817  decode.d4.loss_dice: 0.7111  decode.d5.loss_cls: 0.2300  decode.d5.loss_mask: 1.0405  decode.d5.loss_dice: 0.6866  decode.d6.loss_cls: 0.1657  decode.d6.loss_mask: 1.0420  decode.d6.loss_dice: 0.6722  decode.d7.loss_cls: 0.2026  decode.d7.loss_mask: 1.0270  decode.d7.loss_dice: 0.6787  decode.d8.loss_cls: 0.3214  decode.d8.loss_mask: 1.0521  decode.d8.loss_dice: 0.6775\n",
      "07/02 17:10:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3550/32000]  base_lr: 5.6225e-06 lr: 5.6225e-07  eta: 1:14:31  time: 0.1565  data_time: 0.0088  memory: 5153  grad_norm: 206.4757  loss: 13.6357  decode.loss_cls: 0.0039  decode.loss_mask: 0.7588  decode.loss_dice: 0.5151  decode.d0.loss_cls: 0.1884  decode.d0.loss_mask: 0.9627  decode.d0.loss_dice: 0.6452  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.7797  decode.d1.loss_dice: 0.5474  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 0.5485  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.7549  decode.d3.loss_dice: 0.5307  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.7518  decode.d4.loss_dice: 0.5434  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 0.5423  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.7656  decode.d6.loss_dice: 0.5277  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.8055  decode.d7.loss_dice: 0.5299  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.7597  decode.d8.loss_dice: 0.5369\n",
      "07/02 17:11:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3600/32000]  base_lr: 5.6136e-06 lr: 5.6136e-07  eta: 1:14:24  time: 0.1573  data_time: 0.0091  memory: 5153  grad_norm: 194.9578  loss: 12.8242  decode.loss_cls: 0.0010  decode.loss_mask: 0.7342  decode.loss_dice: 0.4616  decode.d0.loss_cls: 0.1766  decode.d0.loss_mask: 0.9541  decode.d0.loss_dice: 0.6190  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.7657  decode.d1.loss_dice: 0.4807  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.7968  decode.d2.loss_dice: 0.4855  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.7376  decode.d3.loss_dice: 0.4711  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.7452  decode.d4.loss_dice: 0.4908  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.7661  decode.d5.loss_dice: 0.4690  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.7528  decode.d6.loss_dice: 0.4709  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7470  decode.d7.loss_dice: 0.4540  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7522  decode.d8.loss_dice: 0.4669\n",
      "07/02 17:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3650/32000]  base_lr: 5.6047e-06 lr: 5.6047e-07  eta: 1:14:16  time: 0.1579  data_time: 0.0098  memory: 5153  grad_norm: 299.7987  loss: 15.5274  decode.loss_cls: 0.0123  decode.loss_mask: 0.8567  decode.loss_dice: 0.5719  decode.d0.loss_cls: 0.1801  decode.d0.loss_mask: 1.1655  decode.d0.loss_dice: 0.7551  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.9548  decode.d1.loss_dice: 0.6464  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.8840  decode.d2.loss_dice: 0.6043  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.8404  decode.d3.loss_dice: 0.5577  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.8967  decode.d4.loss_dice: 0.6021  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.8982  decode.d5.loss_dice: 0.6121  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.8690  decode.d6.loss_dice: 0.5843  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.8697  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.8596  decode.d8.loss_dice: 0.5786\n",
      "07/02 17:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3700/32000]  base_lr: 5.5958e-06 lr: 5.5958e-07  eta: 1:14:08  time: 0.1575  data_time: 0.0095  memory: 5154  grad_norm: 173.3205  loss: 12.3474  decode.loss_cls: 0.0043  decode.loss_mask: 0.7376  decode.loss_dice: 0.4408  decode.d0.loss_cls: 0.1751  decode.d0.loss_mask: 0.9559  decode.d0.loss_dice: 0.5338  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.7204  decode.d1.loss_dice: 0.4363  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.7466  decode.d2.loss_dice: 0.4356  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.7372  decode.d3.loss_dice: 0.4482  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.7571  decode.d4.loss_dice: 0.4519  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.7293  decode.d5.loss_dice: 0.4467  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.7415  decode.d6.loss_dice: 0.4336  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.7415  decode.d7.loss_dice: 0.4327  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.7453  decode.d8.loss_dice: 0.4364\n",
      "07/02 17:11:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3750/32000]  base_lr: 5.5869e-06 lr: 5.5869e-07  eta: 1:14:01  time: 0.1578  data_time: 0.0093  memory: 5153  grad_norm: 188.3972  loss: 12.5432  decode.loss_cls: 0.0060  decode.loss_mask: 0.6742  decode.loss_dice: 0.4730  decode.d0.loss_cls: 0.2251  decode.d0.loss_mask: 0.8989  decode.d0.loss_dice: 0.6041  decode.d1.loss_cls: 0.0334  decode.d1.loss_mask: 0.7902  decode.d1.loss_dice: 0.5385  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.7172  decode.d2.loss_dice: 0.4998  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.7236  decode.d3.loss_dice: 0.4890  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.7051  decode.d4.loss_dice: 0.4810  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.7082  decode.d5.loss_dice: 0.4921  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.6788  decode.d6.loss_dice: 0.4783  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.6824  decode.d7.loss_dice: 0.4779  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.6697  decode.d8.loss_dice: 0.4587\n",
      "07/02 17:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3800/32000]  base_lr: 5.5780e-06 lr: 5.5780e-07  eta: 1:13:53  time: 0.1574  data_time: 0.0091  memory: 5154  grad_norm: 197.4922  loss: 12.7342  decode.loss_cls: 0.0009  decode.loss_mask: 0.7564  decode.loss_dice: 0.4277  decode.d0.loss_cls: 0.1142  decode.d0.loss_mask: 0.9687  decode.d0.loss_dice: 0.5743  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.7907  decode.d1.loss_dice: 0.4862  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.7555  decode.d2.loss_dice: 0.4557  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.7857  decode.d3.loss_dice: 0.4578  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.8209  decode.d4.loss_dice: 0.4648  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.8117  decode.d5.loss_dice: 0.4765  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.7360  decode.d6.loss_dice: 0.4287  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.7621  decode.d7.loss_dice: 0.4338  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7605  decode.d8.loss_dice: 0.4379\n",
      "07/02 17:11:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3850/32000]  base_lr: 5.5691e-06 lr: 5.5691e-07  eta: 1:13:46  time: 0.1620  data_time: 0.0098  memory: 5154  grad_norm: 213.3205  loss: 13.6257  decode.loss_cls: 0.0013  decode.loss_mask: 0.7631  decode.loss_dice: 0.4873  decode.d0.loss_cls: 0.2139  decode.d0.loss_mask: 1.0922  decode.d0.loss_dice: 0.6528  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.8353  decode.d1.loss_dice: 0.5681  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.8329  decode.d2.loss_dice: 0.5532  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.8068  decode.d3.loss_dice: 0.5004  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.7987  decode.d4.loss_dice: 0.5061  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.7675  decode.d5.loss_dice: 0.4842  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7571  decode.d6.loss_dice: 0.4956  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7607  decode.d7.loss_dice: 0.4822  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7572  decode.d8.loss_dice: 0.4784\n",
      "07/02 17:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3900/32000]  base_lr: 5.5602e-06 lr: 5.5602e-07  eta: 1:13:39  time: 0.1588  data_time: 0.0094  memory: 5153  grad_norm: 179.3962  loss: 10.5656  decode.loss_cls: 0.0018  decode.loss_mask: 0.5938  decode.loss_dice: 0.3773  decode.d0.loss_cls: 0.1455  decode.d0.loss_mask: 0.8467  decode.d0.loss_dice: 0.5592  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5957  decode.d1.loss_dice: 0.3903  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.6058  decode.d2.loss_dice: 0.4040  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.5670  decode.d3.loss_dice: 0.3931  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.6042  decode.d4.loss_dice: 0.4188  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.6185  decode.d5.loss_dice: 0.4261  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.6021  decode.d6.loss_dice: 0.4191  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.5992  decode.d7.loss_dice: 0.4092  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.5742  decode.d8.loss_dice: 0.3893\n",
      "07/02 17:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3950/32000]  base_lr: 5.5513e-06 lr: 5.5513e-07  eta: 1:13:31  time: 0.1553  data_time: 0.0085  memory: 5153  grad_norm: 238.6220  loss: 14.7053  decode.loss_cls: 0.0024  decode.loss_mask: 0.8590  decode.loss_dice: 0.5284  decode.d0.loss_cls: 0.1481  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.6697  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.9174  decode.d1.loss_dice: 0.5606  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.8423  decode.d2.loss_dice: 0.5551  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.9015  decode.d3.loss_dice: 0.5637  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.8729  decode.d4.loss_dice: 0.5727  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.8886  decode.d5.loss_dice: 0.5553  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.8362  decode.d6.loss_dice: 0.5440  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.8551  decode.d7.loss_dice: 0.5514  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.8759  decode.d8.loss_dice: 0.5600\n",
      "07/02 17:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4000/32000]  base_lr: 5.5424e-06 lr: 5.5424e-07  eta: 1:13:23  time: 0.1560  data_time: 0.0087  memory: 5154  grad_norm: 321.7927  loss: 17.6977  decode.loss_cls: 0.0042  decode.loss_mask: 0.9871  decode.loss_dice: 0.6924  decode.d0.loss_cls: 0.2031  decode.d0.loss_mask: 1.2472  decode.d0.loss_dice: 0.8144  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 1.0034  decode.d1.loss_dice: 0.6866  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 1.0453  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.9992  decode.d3.loss_dice: 0.6827  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 1.0557  decode.d4.loss_dice: 0.7066  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.9883  decode.d5.loss_dice: 0.6932  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 1.0090  decode.d6.loss_dice: 0.7070  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.9952  decode.d7.loss_dice: 0.7070  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.9740  decode.d8.loss_dice: 0.6797\n",
      "07/02 17:12:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0213  data_time: 0.0021  memory: 2161  \n",
      "07/02 17:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0291  data_time: 0.0063  memory: 1077  \n",
      "07/02 17:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 87.07 | 92.86 |\n",
      "|   lesion   | 65.51 | 79.76 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 89.6200  mIoU: 76.2900  mAcc: 86.3100  data_time: 0.0114  time: 0.0366\n",
      "07/02 17:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4050/32000]  base_lr: 5.5335e-06 lr: 5.5335e-07  eta: 1:13:15  time: 0.1548  data_time: 0.0082  memory: 5153  grad_norm: 202.7717  loss: 12.2738  decode.loss_cls: 0.0013  decode.loss_mask: 0.7169  decode.loss_dice: 0.4763  decode.d0.loss_cls: 0.1351  decode.d0.loss_mask: 0.9271  decode.d0.loss_dice: 0.6076  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.4936  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.6985  decode.d2.loss_dice: 0.4718  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.6946  decode.d3.loss_dice: 0.4616  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.6918  decode.d4.loss_dice: 0.4626  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.6769  decode.d5.loss_dice: 0.4583  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7159  decode.d6.loss_dice: 0.4770  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.7241  decode.d7.loss_dice: 0.4664  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7073  decode.d8.loss_dice: 0.4621\n",
      "07/02 17:12:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4100/32000]  base_lr: 5.5246e-06 lr: 5.5246e-07  eta: 1:13:07  time: 0.1576  data_time: 0.0093  memory: 5153  grad_norm: 186.9503  loss: 11.6716  decode.loss_cls: 0.0014  decode.loss_mask: 0.7023  decode.loss_dice: 0.4381  decode.d0.loss_cls: 0.1439  decode.d0.loss_mask: 0.8623  decode.d0.loss_dice: 0.5811  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.6954  decode.d1.loss_dice: 0.4543  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.7396  decode.d2.loss_dice: 0.4288  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.6817  decode.d3.loss_dice: 0.4067  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.6780  decode.d4.loss_dice: 0.4129  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.6807  decode.d5.loss_dice: 0.4193  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.6823  decode.d6.loss_dice: 0.4097  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.6978  decode.d7.loss_dice: 0.4162  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6863  decode.d8.loss_dice: 0.4224\n",
      "07/02 17:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4150/32000]  base_lr: 5.5157e-06 lr: 5.5157e-07  eta: 1:12:59  time: 0.1581  data_time: 0.0101  memory: 5153  grad_norm: 266.0441  loss: 16.3665  decode.loss_cls: 0.0055  decode.loss_mask: 0.9038  decode.loss_dice: 0.5808  decode.d0.loss_cls: 0.1910  decode.d0.loss_mask: 1.1837  decode.d0.loss_dice: 0.8305  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.9967  decode.d1.loss_dice: 0.7202  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.9746  decode.d2.loss_dice: 0.6480  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.9236  decode.d3.loss_dice: 0.6334  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.9477  decode.d4.loss_dice: 0.6380  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.9345  decode.d5.loss_dice: 0.6355  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.9102  decode.d6.loss_dice: 0.5881  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.9149  decode.d7.loss_dice: 0.5891  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.8995  decode.d8.loss_dice: 0.5950\n",
      "07/02 17:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4200/32000]  base_lr: 5.5068e-06 lr: 5.5068e-07  eta: 1:12:52  time: 0.1578  data_time: 0.0097  memory: 5153  grad_norm: 211.7362  loss: 16.0130  decode.loss_cls: 0.0016  decode.loss_mask: 0.9057  decode.loss_dice: 0.6000  decode.d0.loss_cls: 0.1479  decode.d0.loss_mask: 1.2211  decode.d0.loss_dice: 0.7737  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.9572  decode.d1.loss_dice: 0.6463  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.9529  decode.d2.loss_dice: 0.6257  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 0.6008  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.8989  decode.d4.loss_dice: 0.6143  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.9015  decode.d5.loss_dice: 0.6282  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.9284  decode.d6.loss_dice: 0.6093  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.9345  decode.d7.loss_dice: 0.6168  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.9092  decode.d8.loss_dice: 0.5989\n",
      "07/02 17:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4250/32000]  base_lr: 5.4979e-06 lr: 5.4979e-07  eta: 1:12:44  time: 0.1577  data_time: 0.0094  memory: 5154  grad_norm: 266.5696  loss: 16.8469  decode.loss_cls: 0.0175  decode.loss_mask: 1.0465  decode.loss_dice: 0.5640  decode.d0.loss_cls: 0.2596  decode.d0.loss_mask: 1.0987  decode.d0.loss_dice: 0.6688  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.9747  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.9911  decode.d2.loss_dice: 0.5590  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.9855  decode.d3.loss_dice: 0.6139  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 1.0222  decode.d4.loss_dice: 0.5928  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 1.0416  decode.d5.loss_dice: 0.5875  decode.d6.loss_cls: 0.1288  decode.d6.loss_mask: 0.9821  decode.d6.loss_dice: 0.6082  decode.d7.loss_cls: 0.1239  decode.d7.loss_mask: 0.9916  decode.d7.loss_dice: 0.5855  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 1.0130  decode.d8.loss_dice: 0.5821\n",
      "07/02 17:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4300/32000]  base_lr: 5.4889e-06 lr: 5.4889e-07  eta: 1:12:36  time: 0.1579  data_time: 0.0098  memory: 5153  grad_norm: 319.1175  loss: 17.4985  decode.loss_cls: 0.0027  decode.loss_mask: 0.9995  decode.loss_dice: 0.6244  decode.d0.loss_cls: 0.2501  decode.d0.loss_mask: 1.2767  decode.d0.loss_dice: 0.7789  decode.d1.loss_cls: 0.1366  decode.d1.loss_mask: 1.0373  decode.d1.loss_dice: 0.6860  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 1.0591  decode.d2.loss_dice: 0.6460  decode.d3.loss_cls: 0.1330  decode.d3.loss_mask: 1.0423  decode.d3.loss_dice: 0.6359  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.9862  decode.d4.loss_dice: 0.6423  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.9697  decode.d5.loss_dice: 0.6250  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.9542  decode.d6.loss_dice: 0.6228  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.9841  decode.d7.loss_dice: 0.6257  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.9844  decode.d8.loss_dice: 0.6501\n",
      "07/02 17:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4350/32000]  base_lr: 5.4800e-06 lr: 5.4800e-07  eta: 1:12:28  time: 0.1544  data_time: 0.0077  memory: 5153  grad_norm: 243.5048  loss: 15.8500  decode.loss_cls: 0.0025  decode.loss_mask: 0.8830  decode.loss_dice: 0.6063  decode.d0.loss_cls: 0.1482  decode.d0.loss_mask: 1.1138  decode.d0.loss_dice: 0.7436  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.9213  decode.d1.loss_dice: 0.6720  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.8983  decode.d2.loss_dice: 0.6171  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.8604  decode.d3.loss_dice: 0.6139  decode.d4.loss_cls: 0.1019  decode.d4.loss_mask: 0.8356  decode.d4.loss_dice: 0.5955  decode.d5.loss_cls: 0.1302  decode.d5.loss_mask: 0.8233  decode.d5.loss_dice: 0.6061  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 0.5957  decode.d7.loss_cls: 0.1094  decode.d7.loss_mask: 0.8347  decode.d7.loss_dice: 0.6132  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.8532  decode.d8.loss_dice: 0.6089\n",
      "07/02 17:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4400/32000]  base_lr: 5.4711e-06 lr: 5.4711e-07  eta: 1:12:20  time: 0.1554  data_time: 0.0087  memory: 5153  grad_norm: 175.1482  loss: 13.9188  decode.loss_cls: 0.0015  decode.loss_mask: 0.8270  decode.loss_dice: 0.5121  decode.d0.loss_cls: 0.1919  decode.d0.loss_mask: 1.0170  decode.d0.loss_dice: 0.6248  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.8923  decode.d1.loss_dice: 0.5842  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.8088  decode.d2.loss_dice: 0.4984  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.8228  decode.d3.loss_dice: 0.4995  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.8168  decode.d4.loss_dice: 0.5160  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.8132  decode.d5.loss_dice: 0.5068  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.8070  decode.d6.loss_dice: 0.4959  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.8068  decode.d7.loss_dice: 0.5098  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.8156  decode.d8.loss_dice: 0.5084\n",
      "07/02 17:13:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4450/32000]  base_lr: 5.4622e-06 lr: 5.4622e-07  eta: 1:12:12  time: 0.1587  data_time: 0.0096  memory: 5154  grad_norm: 276.1103  loss: 15.8113  decode.loss_cls: 0.0079  decode.loss_mask: 0.8876  decode.loss_dice: 0.5986  decode.d0.loss_cls: 0.3494  decode.d0.loss_mask: 1.1073  decode.d0.loss_dice: 0.7358  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.9567  decode.d1.loss_dice: 0.6319  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.9049  decode.d2.loss_dice: 0.6320  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.8952  decode.d3.loss_dice: 0.5835  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.9285  decode.d4.loss_dice: 0.6181  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.9005  decode.d5.loss_dice: 0.6096  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.8673  decode.d6.loss_dice: 0.5797  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.8762  decode.d7.loss_dice: 0.5900  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.8672  decode.d8.loss_dice: 0.5957\n",
      "07/02 17:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4500/32000]  base_lr: 5.4533e-06 lr: 5.4533e-07  eta: 1:12:04  time: 0.1579  data_time: 0.0097  memory: 5152  grad_norm: 291.1947  loss: 15.9795  decode.loss_cls: 0.0087  decode.loss_mask: 0.9052  decode.loss_dice: 0.6120  decode.d0.loss_cls: 0.1414  decode.d0.loss_mask: 1.1177  decode.d0.loss_dice: 0.7513  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.9584  decode.d1.loss_dice: 0.6129  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.9413  decode.d2.loss_dice: 0.6353  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.9028  decode.d3.loss_dice: 0.6295  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.8926  decode.d4.loss_dice: 0.6185  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.9067  decode.d5.loss_dice: 0.6471  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.8845  decode.d6.loss_dice: 0.6093  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.9055  decode.d7.loss_dice: 0.6062  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.8806  decode.d8.loss_dice: 0.6019\n",
      "07/02 17:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4550/32000]  base_lr: 5.4443e-06 lr: 5.4443e-07  eta: 1:11:57  time: 0.1585  data_time: 0.0098  memory: 5153  grad_norm: 280.3093  loss: 14.7882  decode.loss_cls: 0.0024  decode.loss_mask: 0.8187  decode.loss_dice: 0.5556  decode.d0.loss_cls: 0.2580  decode.d0.loss_mask: 1.0586  decode.d0.loss_dice: 0.7360  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.8697  decode.d1.loss_dice: 0.6132  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.8621  decode.d2.loss_dice: 0.5829  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.8647  decode.d3.loss_dice: 0.5768  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 0.5798  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.8755  decode.d5.loss_dice: 0.5909  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.8032  decode.d6.loss_dice: 0.5326  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.8156  decode.d7.loss_dice: 0.5426  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.8150  decode.d8.loss_dice: 0.5521\n",
      "07/02 17:13:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4600/32000]  base_lr: 5.4354e-06 lr: 5.4354e-07  eta: 1:11:49  time: 0.1581  data_time: 0.0095  memory: 5153  grad_norm: 200.0444  loss: 13.1992  decode.loss_cls: 0.0036  decode.loss_mask: 0.7026  decode.loss_dice: 0.4991  decode.d0.loss_cls: 0.2062  decode.d0.loss_mask: 0.9183  decode.d0.loss_dice: 0.6497  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.7802  decode.d1.loss_dice: 0.5434  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.7590  decode.d2.loss_dice: 0.5347  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.7114  decode.d3.loss_dice: 0.5219  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.7089  decode.d4.loss_dice: 0.5084  decode.d5.loss_cls: 0.0316  decode.d5.loss_mask: 0.7029  decode.d5.loss_dice: 0.5285  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.7126  decode.d6.loss_dice: 0.5217  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.7096  decode.d7.loss_dice: 0.5022  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.7047  decode.d8.loss_dice: 0.5025\n",
      "07/02 17:13:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4650/32000]  base_lr: 5.4265e-06 lr: 5.4265e-07  eta: 1:11:41  time: 0.1579  data_time: 0.0098  memory: 5153  grad_norm: 291.2020  loss: 17.1314  decode.loss_cls: 0.0038  decode.loss_mask: 0.9599  decode.loss_dice: 0.6267  decode.d0.loss_cls: 0.3088  decode.d0.loss_mask: 1.2298  decode.d0.loss_dice: 0.8395  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 1.0064  decode.d1.loss_dice: 0.6909  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.9790  decode.d2.loss_dice: 0.6870  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.9858  decode.d3.loss_dice: 0.6616  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.9722  decode.d4.loss_dice: 0.6652  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.9601  decode.d5.loss_dice: 0.6722  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.9708  decode.d6.loss_dice: 0.6399  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.9497  decode.d7.loss_dice: 0.6375  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.9391  decode.d8.loss_dice: 0.6309\n",
      "07/02 17:14:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4700/32000]  base_lr: 5.4176e-06 lr: 5.4176e-07  eta: 1:11:33  time: 0.1585  data_time: 0.0096  memory: 5153  grad_norm: 229.4227  loss: 15.1942  decode.loss_cls: 0.0015  decode.loss_mask: 0.8938  decode.loss_dice: 0.5425  decode.d0.loss_cls: 0.1127  decode.d0.loss_mask: 1.1499  decode.d0.loss_dice: 0.6934  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.9531  decode.d1.loss_dice: 0.5882  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.9277  decode.d2.loss_dice: 0.5855  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.9034  decode.d3.loss_dice: 0.5516  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.8981  decode.d4.loss_dice: 0.5690  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.9043  decode.d5.loss_dice: 0.5769  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.9080  decode.d6.loss_dice: 0.5417  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.8938  decode.d7.loss_dice: 0.5377  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.8861  decode.d8.loss_dice: 0.5460\n",
      "07/02 17:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4750/32000]  base_lr: 5.4086e-06 lr: 5.4086e-07  eta: 1:11:26  time: 0.1610  data_time: 0.0097  memory: 5154  grad_norm: 233.6323  loss: 14.7785  decode.loss_cls: 0.0015  decode.loss_mask: 0.8649  decode.loss_dice: 0.5610  decode.d0.loss_cls: 0.1466  decode.d0.loss_mask: 1.0838  decode.d0.loss_dice: 0.6637  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.9366  decode.d1.loss_dice: 0.5800  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.8753  decode.d2.loss_dice: 0.5611  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.8692  decode.d3.loss_dice: 0.5534  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.8732  decode.d4.loss_dice: 0.5402  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.8324  decode.d5.loss_dice: 0.5441  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.8525  decode.d6.loss_dice: 0.5433  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.8690  decode.d7.loss_dice: 0.5624  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.8649  decode.d8.loss_dice: 0.5633\n",
      "07/02 17:14:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4800/32000]  base_lr: 5.3997e-06 lr: 5.3997e-07  eta: 1:11:18  time: 0.1537  data_time: 0.0088  memory: 5153  grad_norm: 222.2277  loss: 12.6716  decode.loss_cls: 0.0009  decode.loss_mask: 0.7355  decode.loss_dice: 0.4451  decode.d0.loss_cls: 0.1681  decode.d0.loss_mask: 0.9128  decode.d0.loss_dice: 0.6163  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.7654  decode.d1.loss_dice: 0.5082  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.7599  decode.d2.loss_dice: 0.4723  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.7681  decode.d3.loss_dice: 0.4547  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7693  decode.d4.loss_dice: 0.4739  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.7599  decode.d5.loss_dice: 0.4821  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.7322  decode.d6.loss_dice: 0.4549  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7371  decode.d7.loss_dice: 0.4518  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7329  decode.d8.loss_dice: 0.4448\n",
      "07/02 17:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4850/32000]  base_lr: 5.3908e-06 lr: 5.3908e-07  eta: 1:11:10  time: 0.1575  data_time: 0.0098  memory: 5154  grad_norm: 160.3609  loss: 11.9850  decode.loss_cls: 0.0004  decode.loss_mask: 0.7423  decode.loss_dice: 0.4000  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.9644  decode.d0.loss_dice: 0.5481  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.7174  decode.d1.loss_dice: 0.4369  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7694  decode.d2.loss_dice: 0.4559  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.7419  decode.d3.loss_dice: 0.4086  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 0.4029  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7511  decode.d5.loss_dice: 0.3963  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.7299  decode.d6.loss_dice: 0.4012  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7322  decode.d7.loss_dice: 0.3927  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7391  decode.d8.loss_dice: 0.3872\n",
      "07/02 17:14:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4900/32000]  base_lr: 5.3818e-06 lr: 5.3818e-07  eta: 1:11:02  time: 0.1588  data_time: 0.0103  memory: 5153  grad_norm: 188.9500  loss: 12.7605  decode.loss_cls: 0.0028  decode.loss_mask: 0.7614  decode.loss_dice: 0.4544  decode.d0.loss_cls: 0.1657  decode.d0.loss_mask: 0.9855  decode.d0.loss_dice: 0.5849  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.7701  decode.d1.loss_dice: 0.4728  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.7771  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.7642  decode.d3.loss_dice: 0.4700  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.7658  decode.d4.loss_dice: 0.4727  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.7529  decode.d5.loss_dice: 0.4811  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.7307  decode.d6.loss_dice: 0.4514  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.7339  decode.d7.loss_dice: 0.4473  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.7435  decode.d8.loss_dice: 0.4519\n",
      "07/02 17:14:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4950/32000]  base_lr: 5.3729e-06 lr: 5.3729e-07  eta: 1:10:54  time: 0.1576  data_time: 0.0098  memory: 5154  grad_norm: 169.9182  loss: 12.5331  decode.loss_cls: 0.0025  decode.loss_mask: 0.7052  decode.loss_dice: 0.5039  decode.d0.loss_cls: 0.1147  decode.d0.loss_mask: 0.9102  decode.d0.loss_dice: 0.6081  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.7257  decode.d1.loss_dice: 0.5319  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.6992  decode.d2.loss_dice: 0.4991  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.7211  decode.d3.loss_dice: 0.4836  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.7286  decode.d4.loss_dice: 0.4843  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.7154  decode.d5.loss_dice: 0.4937  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.7160  decode.d6.loss_dice: 0.4900  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.6893  decode.d7.loss_dice: 0.4954  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.7090  decode.d8.loss_dice: 0.4829\n",
      "07/02 17:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5000/32000]  base_lr: 5.3639e-06 lr: 5.3639e-07  eta: 1:10:46  time: 0.1573  data_time: 0.0094  memory: 5153  grad_norm: 266.6310  loss: 17.6163  decode.loss_cls: 0.0138  decode.loss_mask: 1.0589  decode.loss_dice: 0.5849  decode.d0.loss_cls: 0.1244  decode.d0.loss_mask: 1.3255  decode.d0.loss_dice: 0.7610  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 1.1097  decode.d1.loss_dice: 0.6211  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 1.1491  decode.d2.loss_dice: 0.6126  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 1.1230  decode.d3.loss_dice: 0.5962  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 1.1112  decode.d4.loss_dice: 0.6068  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 1.1139  decode.d5.loss_dice: 0.5922  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 1.0887  decode.d6.loss_dice: 0.5998  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 1.0474  decode.d7.loss_dice: 0.5810  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 1.0886  decode.d8.loss_dice: 0.5962\n",
      "07/02 17:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5000 iterations\n",
      "07/02 17:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0216  data_time: 0.0023  memory: 2168  \n",
      "07/02 17:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0289  data_time: 0.0062  memory: 1073  \n",
      "07/02 17:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 89.25 | 96.31 |\n",
      "|   lesion   | 68.21 | 75.88 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 91.2600  mIoU: 78.7300  mAcc: 86.0900  data_time: 0.0113  time: 0.0367\n",
      "07/02 17:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_2000.pth is removed\n",
      "07/02 17:14:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 78.7300 mIoU at 5000 iter is saved to best_mIoU_iter_5000.pth.\n",
      "07/02 17:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5050/32000]  base_lr: 5.3550e-06 lr: 5.3550e-07  eta: 1:10:48  time: 0.1574  data_time: 0.0089  memory: 5154  grad_norm: 190.8363  loss: 14.2940  decode.loss_cls: 0.0017  decode.loss_mask: 0.8252  decode.loss_dice: 0.4870  decode.d0.loss_cls: 0.1116  decode.d0.loss_mask: 1.0951  decode.d0.loss_dice: 0.6582  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.8794  decode.d1.loss_dice: 0.5498  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.8463  decode.d2.loss_dice: 0.5529  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.8916  decode.d3.loss_dice: 0.5267  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.8889  decode.d4.loss_dice: 0.5390  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.8715  decode.d5.loss_dice: 0.5190  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.8485  decode.d6.loss_dice: 0.4784  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.8592  decode.d7.loss_dice: 0.4918  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8604  decode.d8.loss_dice: 0.4824\n",
      "07/02 17:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5100/32000]  base_lr: 5.3461e-06 lr: 5.3461e-07  eta: 1:10:40  time: 0.1557  data_time: 0.0075  memory: 5154  grad_norm: 193.9751  loss: 13.6406  decode.loss_cls: 0.0007  decode.loss_mask: 0.7919  decode.loss_dice: 0.5223  decode.d0.loss_cls: 0.1022  decode.d0.loss_mask: 1.0198  decode.d0.loss_dice: 0.6554  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.8387  decode.d1.loss_dice: 0.5924  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.7979  decode.d2.loss_dice: 0.5488  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.7686  decode.d3.loss_dice: 0.5365  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.7780  decode.d4.loss_dice: 0.5100  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.7561  decode.d5.loss_dice: 0.5219  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.7613  decode.d6.loss_dice: 0.5000  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.7732  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 0.5176\n",
      "07/02 17:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5150/32000]  base_lr: 5.3371e-06 lr: 5.3371e-07  eta: 1:10:32  time: 0.1608  data_time: 0.0093  memory: 5153  grad_norm: 181.4228  loss: 13.0055  decode.loss_cls: 0.0045  decode.loss_mask: 0.7797  decode.loss_dice: 0.4490  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.9812  decode.d0.loss_dice: 0.6313  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.8181  decode.d1.loss_dice: 0.5052  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.7652  decode.d2.loss_dice: 0.4614  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.7652  decode.d3.loss_dice: 0.4764  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.7803  decode.d4.loss_dice: 0.4645  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.7999  decode.d5.loss_dice: 0.4767  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.7822  decode.d6.loss_dice: 0.4410  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.7683  decode.d7.loss_dice: 0.4283  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.7795  decode.d8.loss_dice: 0.4497\n",
      "07/02 17:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5200/32000]  base_lr: 5.3282e-06 lr: 5.3282e-07  eta: 1:10:25  time: 0.1562  data_time: 0.0078  memory: 5153  grad_norm: 204.2557  loss: 15.3635  decode.loss_cls: 0.0016  decode.loss_mask: 0.8989  decode.loss_dice: 0.5353  decode.d0.loss_cls: 0.1485  decode.d0.loss_mask: 1.1644  decode.d0.loss_dice: 0.6294  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.9552  decode.d1.loss_dice: 0.5859  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.9569  decode.d2.loss_dice: 0.5709  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.9437  decode.d3.loss_dice: 0.5551  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.9511  decode.d4.loss_dice: 0.5453  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.9358  decode.d5.loss_dice: 0.5397  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.9184  decode.d6.loss_dice: 0.5266  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.9006  decode.d7.loss_dice: 0.5384  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.8925  decode.d8.loss_dice: 0.5315\n",
      "07/02 17:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5250/32000]  base_lr: 5.3192e-06 lr: 5.3192e-07  eta: 1:10:18  time: 0.1634  data_time: 0.0091  memory: 5154  grad_norm: 225.4384  loss: 15.2195  decode.loss_cls: 0.0016  decode.loss_mask: 0.8169  decode.loss_dice: 0.5783  decode.d0.loss_cls: 0.1487  decode.d0.loss_mask: 1.1157  decode.d0.loss_dice: 0.7586  decode.d1.loss_cls: 0.0301  decode.d1.loss_mask: 0.9206  decode.d1.loss_dice: 0.6751  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.8642  decode.d2.loss_dice: 0.6496  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.8655  decode.d3.loss_dice: 0.6113  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.8318  decode.d4.loss_dice: 0.6066  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.8541  decode.d5.loss_dice: 0.5885  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.8513  decode.d6.loss_dice: 0.5879  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.8253  decode.d7.loss_dice: 0.5820  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.8254  decode.d8.loss_dice: 0.6034\n",
      "07/02 17:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5300/32000]  base_lr: 5.3103e-06 lr: 5.3103e-07  eta: 1:10:10  time: 0.1570  data_time: 0.0085  memory: 5155  grad_norm: 200.3556  loss: 14.1754  decode.loss_cls: 0.0018  decode.loss_mask: 0.8199  decode.loss_dice: 0.4962  decode.d0.loss_cls: 0.1081  decode.d0.loss_mask: 1.0269  decode.d0.loss_dice: 0.6864  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.8714  decode.d1.loss_dice: 0.5783  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.8368  decode.d2.loss_dice: 0.5332  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.8388  decode.d3.loss_dice: 0.5140  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.8481  decode.d4.loss_dice: 0.5361  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.8179  decode.d5.loss_dice: 0.5358  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.8592  decode.d6.loss_dice: 0.5421  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.8604  decode.d7.loss_dice: 0.5276  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.8163  decode.d8.loss_dice: 0.5001\n",
      "07/02 17:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5350/32000]  base_lr: 5.3013e-06 lr: 5.3013e-07  eta: 1:10:03  time: 0.1600  data_time: 0.0080  memory: 5153  grad_norm: 236.9823  loss: 15.7559  decode.loss_cls: 0.0023  decode.loss_mask: 0.9260  decode.loss_dice: 0.5912  decode.d0.loss_cls: 0.1930  decode.d0.loss_mask: 1.0940  decode.d0.loss_dice: 0.7303  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.9591  decode.d1.loss_dice: 0.6379  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.9355  decode.d2.loss_dice: 0.5963  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.9396  decode.d3.loss_dice: 0.5842  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.9632  decode.d4.loss_dice: 0.5840  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.8730  decode.d5.loss_dice: 0.5562  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.9257  decode.d6.loss_dice: 0.5748  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.9299  decode.d7.loss_dice: 0.5814  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.9415  decode.d8.loss_dice: 0.5936\n",
      "07/02 17:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5400/32000]  base_lr: 5.2924e-06 lr: 5.2924e-07  eta: 1:09:56  time: 0.1591  data_time: 0.0090  memory: 5153  grad_norm: 157.5504  loss: 11.9487  decode.loss_cls: 0.0015  decode.loss_mask: 0.7197  decode.loss_dice: 0.4206  decode.d0.loss_cls: 0.0981  decode.d0.loss_mask: 0.9579  decode.d0.loss_dice: 0.5397  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.7556  decode.d1.loss_dice: 0.4424  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.7187  decode.d2.loss_dice: 0.4441  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.6986  decode.d3.loss_dice: 0.4090  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.7140  decode.d4.loss_dice: 0.4180  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7195  decode.d5.loss_dice: 0.4321  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7177  decode.d6.loss_dice: 0.4247  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7191  decode.d7.loss_dice: 0.4316  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.7303  decode.d8.loss_dice: 0.4192\n",
      "07/02 17:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5450/32000]  base_lr: 5.2834e-06 lr: 5.2834e-07  eta: 1:09:48  time: 0.1594  data_time: 0.0091  memory: 5153  grad_norm: 167.6032  loss: 12.1529  decode.loss_cls: 0.0036  decode.loss_mask: 0.7012  decode.loss_dice: 0.4364  decode.d0.loss_cls: 0.1294  decode.d0.loss_mask: 0.9352  decode.d0.loss_dice: 0.6016  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.7534  decode.d1.loss_dice: 0.4844  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.7560  decode.d2.loss_dice: 0.4702  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.7413  decode.d3.loss_dice: 0.4456  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.7067  decode.d4.loss_dice: 0.4477  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.6910  decode.d5.loss_dice: 0.4212  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.6903  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.7007  decode.d7.loss_dice: 0.4380  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.6876  decode.d8.loss_dice: 0.4353\n",
      "07/02 17:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5500/32000]  base_lr: 5.2745e-06 lr: 5.2745e-07  eta: 1:09:41  time: 0.1613  data_time: 0.0088  memory: 5153  grad_norm: 200.4004  loss: 13.4454  decode.loss_cls: 0.0029  decode.loss_mask: 0.7372  decode.loss_dice: 0.5251  decode.d0.loss_cls: 0.1092  decode.d0.loss_mask: 0.9510  decode.d0.loss_dice: 0.7128  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.8003  decode.d1.loss_dice: 0.6268  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.7748  decode.d2.loss_dice: 0.5645  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 0.7601  decode.d3.loss_dice: 0.5502  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 0.5244  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.7230  decode.d5.loss_dice: 0.5039  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.7174  decode.d6.loss_dice: 0.5123  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 0.5093  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.7277  decode.d8.loss_dice: 0.5393\n",
      "07/02 17:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5550/32000]  base_lr: 5.2655e-06 lr: 5.2655e-07  eta: 1:09:34  time: 0.1613  data_time: 0.0087  memory: 5153  grad_norm: 150.0406  loss: 12.0358  decode.loss_cls: 0.0005  decode.loss_mask: 0.6985  decode.loss_dice: 0.4050  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 1.0477  decode.d0.loss_dice: 0.5853  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.7680  decode.d1.loss_dice: 0.4302  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.8011  decode.d2.loss_dice: 0.4472  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.7509  decode.d3.loss_dice: 0.4162  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.7510  decode.d4.loss_dice: 0.4101  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7353  decode.d5.loss_dice: 0.3971  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7133  decode.d6.loss_dice: 0.4007  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.6972  decode.d7.loss_dice: 0.4029  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6903  decode.d8.loss_dice: 0.3907\n",
      "07/02 17:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5600/32000]  base_lr: 5.2565e-06 lr: 5.2565e-07  eta: 1:09:27  time: 0.1622  data_time: 0.0087  memory: 5153  grad_norm: 144.0318  loss: 11.1009  decode.loss_cls: 0.0007  decode.loss_mask: 0.6427  decode.loss_dice: 0.4259  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.8354  decode.d0.loss_dice: 0.5638  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.6594  decode.d1.loss_dice: 0.4556  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.6271  decode.d2.loss_dice: 0.4531  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.6291  decode.d3.loss_dice: 0.4339  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.6382  decode.d4.loss_dice: 0.4306  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.6301  decode.d5.loss_dice: 0.4244  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6466  decode.d6.loss_dice: 0.4240  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6215  decode.d7.loss_dice: 0.4158  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6468  decode.d8.loss_dice: 0.4177\n",
      "07/02 17:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5650/32000]  base_lr: 5.2476e-06 lr: 5.2476e-07  eta: 1:09:20  time: 0.1586  data_time: 0.0090  memory: 5153  grad_norm: 212.5928  loss: 13.1075  decode.loss_cls: 0.0014  decode.loss_mask: 0.7748  decode.loss_dice: 0.4538  decode.d0.loss_cls: 0.1256  decode.d0.loss_mask: 0.9830  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.8308  decode.d1.loss_dice: 0.5301  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.7987  decode.d2.loss_dice: 0.4768  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.7741  decode.d3.loss_dice: 0.4713  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.7723  decode.d4.loss_dice: 0.4827  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 0.4759  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.7865  decode.d6.loss_dice: 0.4645  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.7905  decode.d7.loss_dice: 0.4642  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.7820  decode.d8.loss_dice: 0.4541\n",
      "07/02 17:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5700/32000]  base_lr: 5.2386e-06 lr: 5.2386e-07  eta: 1:09:13  time: 0.1574  data_time: 0.0092  memory: 5154  grad_norm: 190.5826  loss: 11.9148  decode.loss_cls: 0.0011  decode.loss_mask: 0.6898  decode.loss_dice: 0.4087  decode.d0.loss_cls: 0.1414  decode.d0.loss_mask: 0.9500  decode.d0.loss_dice: 0.5781  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.7444  decode.d1.loss_dice: 0.4794  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.7267  decode.d2.loss_dice: 0.4597  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.6907  decode.d3.loss_dice: 0.4451  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.6560  decode.d4.loss_dice: 0.4366  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.7052  decode.d5.loss_dice: 0.4336  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.6942  decode.d6.loss_dice: 0.4178  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.6956  decode.d7.loss_dice: 0.4185  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.6982  decode.d8.loss_dice: 0.4100\n",
      "07/02 17:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5750/32000]  base_lr: 5.2297e-06 lr: 5.2297e-07  eta: 1:09:05  time: 0.1543  data_time: 0.0081  memory: 5153  grad_norm: 134.5943  loss: 10.5437  decode.loss_cls: 0.0005  decode.loss_mask: 0.5904  decode.loss_dice: 0.3917  decode.d0.loss_cls: 0.1116  decode.d0.loss_mask: 0.8147  decode.d0.loss_dice: 0.5463  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.6226  decode.d1.loss_dice: 0.4176  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.6134  decode.d2.loss_dice: 0.4030  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.6333  decode.d3.loss_dice: 0.3918  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.6241  decode.d4.loss_dice: 0.3897  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6146  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6165  decode.d6.loss_dice: 0.3802  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6048  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 0.3869\n",
      "07/02 17:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5800/32000]  base_lr: 5.2207e-06 lr: 5.2207e-07  eta: 1:08:57  time: 0.1714  data_time: 0.0097  memory: 5153  grad_norm: 221.4456  loss: 14.2918  decode.loss_cls: 0.0013  decode.loss_mask: 0.7812  decode.loss_dice: 0.5373  decode.d0.loss_cls: 0.1233  decode.d0.loss_mask: 1.0069  decode.d0.loss_dice: 0.6916  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.8897  decode.d1.loss_dice: 0.5910  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.8391  decode.d2.loss_dice: 0.5896  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.8071  decode.d3.loss_dice: 0.5410  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.8266  decode.d4.loss_dice: 0.5485  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 0.5567  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.7948  decode.d6.loss_dice: 0.5648  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 0.5332  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7924  decode.d8.loss_dice: 0.5525\n",
      "07/02 17:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5850/32000]  base_lr: 5.2117e-06 lr: 5.2117e-07  eta: 1:08:49  time: 0.1574  data_time: 0.0096  memory: 5153  grad_norm: 154.1869  loss: 10.6296  decode.loss_cls: 0.0008  decode.loss_mask: 0.6096  decode.loss_dice: 0.3739  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 0.8709  decode.d0.loss_dice: 0.5265  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.6958  decode.d1.loss_dice: 0.4224  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.6333  decode.d2.loss_dice: 0.3923  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.6374  decode.d3.loss_dice: 0.3798  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.6311  decode.d4.loss_dice: 0.3523  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6541  decode.d5.loss_dice: 0.3823  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.6288  decode.d6.loss_dice: 0.3772  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6099  decode.d7.loss_dice: 0.3709  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6033  decode.d8.loss_dice: 0.3590\n",
      "07/02 17:17:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5900/32000]  base_lr: 5.2028e-06 lr: 5.2028e-07  eta: 1:08:41  time: 0.1580  data_time: 0.0097  memory: 5153  grad_norm: 237.8765  loss: 14.5812  decode.loss_cls: 0.0004  decode.loss_mask: 0.8781  decode.loss_dice: 0.5259  decode.d0.loss_cls: 0.1414  decode.d0.loss_mask: 1.0814  decode.d0.loss_dice: 0.6498  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.8616  decode.d1.loss_dice: 0.5537  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.8640  decode.d2.loss_dice: 0.5541  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.8971  decode.d3.loss_dice: 0.5350  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.8899  decode.d4.loss_dice: 0.5367  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.8792  decode.d5.loss_dice: 0.5283  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.8616  decode.d6.loss_dice: 0.5283  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.8689  decode.d7.loss_dice: 0.5261  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.8707  decode.d8.loss_dice: 0.5269\n",
      "07/02 17:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5950/32000]  base_lr: 5.1938e-06 lr: 5.1938e-07  eta: 1:08:33  time: 0.1576  data_time: 0.0098  memory: 5153  grad_norm: 190.1499  loss: 12.1325  decode.loss_cls: 0.0012  decode.loss_mask: 0.7176  decode.loss_dice: 0.4403  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.9407  decode.d0.loss_dice: 0.5753  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.7250  decode.d1.loss_dice: 0.4582  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.7384  decode.d2.loss_dice: 0.4831  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.7011  decode.d3.loss_dice: 0.4480  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7100  decode.d4.loss_dice: 0.4525  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7163  decode.d5.loss_dice: 0.4416  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.7133  decode.d6.loss_dice: 0.4355  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7080  decode.d7.loss_dice: 0.4421  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7030  decode.d8.loss_dice: 0.4650\n",
      "07/02 17:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6000/32000]  base_lr: 5.1848e-06 lr: 5.1848e-07  eta: 1:08:25  time: 0.1582  data_time: 0.0098  memory: 5153  grad_norm: 161.9875  loss: 12.0762  decode.loss_cls: 0.0005  decode.loss_mask: 0.7246  decode.loss_dice: 0.4213  decode.d0.loss_cls: 0.1307  decode.d0.loss_mask: 0.8767  decode.d0.loss_dice: 0.5515  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.7597  decode.d1.loss_dice: 0.4792  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.7201  decode.d2.loss_dice: 0.4268  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.7146  decode.d3.loss_dice: 0.4267  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7214  decode.d4.loss_dice: 0.4552  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 0.4383  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7386  decode.d6.loss_dice: 0.4499  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7337  decode.d7.loss_dice: 0.4385  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7235  decode.d8.loss_dice: 0.4296\n",
      "07/02 17:17:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0215  data_time: 0.0023  memory: 2165  \n",
      "07/02 17:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0292  data_time: 0.0063  memory: 1078  \n",
      "07/02 17:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 88.95 | 94.25 |\n",
      "|   lesion   | 69.64 | 81.85 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 91.1900  mIoU: 79.3000  mAcc: 88.0500  data_time: 0.0117  time: 0.0369\n",
      "07/02 17:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_5000.pth is removed\n",
      "07/02 17:17:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 79.3000 mIoU at 6000 iter is saved to best_mIoU_iter_6000.pth.\n",
      "07/02 17:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6050/32000]  base_lr: 5.1758e-06 lr: 5.1758e-07  eta: 1:08:23  time: 0.1531  data_time: 0.0080  memory: 5154  grad_norm: 286.4480  loss: 16.6229  decode.loss_cls: 0.0158  decode.loss_mask: 0.9899  decode.loss_dice: 0.6258  decode.d0.loss_cls: 0.1431  decode.d0.loss_mask: 1.2010  decode.d0.loss_dice: 0.7286  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 1.0149  decode.d1.loss_dice: 0.6126  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 1.0112  decode.d2.loss_dice: 0.5944  decode.d3.loss_cls: 0.0217  decode.d3.loss_mask: 0.9814  decode.d3.loss_dice: 0.5697  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 1.0050  decode.d4.loss_dice: 0.6116  decode.d5.loss_cls: 0.0124  decode.d5.loss_mask: 1.0123  decode.d5.loss_dice: 0.6071  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.9678  decode.d6.loss_dice: 0.6146  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.9607  decode.d7.loss_dice: 0.6135  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.9866  decode.d8.loss_dice: 0.6140\n",
      "07/02 17:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6100/32000]  base_lr: 5.1669e-06 lr: 5.1669e-07  eta: 1:08:14  time: 0.1541  data_time: 0.0079  memory: 5154  grad_norm: 215.3759  loss: 14.9559  decode.loss_cls: 0.0012  decode.loss_mask: 0.8955  decode.loss_dice: 0.5540  decode.d0.loss_cls: 0.1382  decode.d0.loss_mask: 1.0001  decode.d0.loss_dice: 0.7022  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.8924  decode.d1.loss_dice: 0.5942  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.8201  decode.d2.loss_dice: 0.5792  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.8024  decode.d3.loss_dice: 0.5528  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.8248  decode.d4.loss_dice: 0.5683  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.8929  decode.d5.loss_dice: 0.5684  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.9062  decode.d6.loss_dice: 0.5772  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.9186  decode.d7.loss_dice: 0.5711  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.9153  decode.d8.loss_dice: 0.5653\n",
      "07/02 17:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6150/32000]  base_lr: 5.1579e-06 lr: 5.1579e-07  eta: 1:08:06  time: 0.1571  data_time: 0.0090  memory: 5152  grad_norm: 266.1649  loss: 14.2846  decode.loss_cls: 0.0015  decode.loss_mask: 0.8895  decode.loss_dice: 0.5229  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 1.1143  decode.d0.loss_dice: 0.7116  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.8606  decode.d1.loss_dice: 0.5524  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.8782  decode.d2.loss_dice: 0.5556  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.8518  decode.d3.loss_dice: 0.5380  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.8150  decode.d4.loss_dice: 0.5073  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.8210  decode.d5.loss_dice: 0.5136  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.8240  decode.d6.loss_dice: 0.5040  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.8331  decode.d7.loss_dice: 0.5112  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.8678  decode.d8.loss_dice: 0.5096\n",
      "07/02 17:18:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6200/32000]  base_lr: 5.1489e-06 lr: 5.1489e-07  eta: 1:07:58  time: 0.1574  data_time: 0.0090  memory: 5153  grad_norm: 207.6262  loss: 14.2176  decode.loss_cls: 0.0060  decode.loss_mask: 0.6926  decode.loss_dice: 0.6631  decode.d0.loss_cls: 0.1105  decode.d0.loss_mask: 0.8845  decode.d0.loss_dice: 0.8479  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.7363  decode.d1.loss_dice: 0.6937  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.7175  decode.d2.loss_dice: 0.6853  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.7164  decode.d3.loss_dice: 0.6721  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.7214  decode.d4.loss_dice: 0.6632  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.6832  decode.d5.loss_dice: 0.6571  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.6836  decode.d6.loss_dice: 0.6396  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.6658  decode.d7.loss_dice: 0.6506  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.6904  decode.d8.loss_dice: 0.6523\n",
      "07/02 17:18:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6250/32000]  base_lr: 5.1399e-06 lr: 5.1399e-07  eta: 1:07:50  time: 0.1577  data_time: 0.0088  memory: 5154  grad_norm: 262.6395  loss: 15.3786  decode.loss_cls: 0.0009  decode.loss_mask: 0.8908  decode.loss_dice: 0.5795  decode.d0.loss_cls: 0.1045  decode.d0.loss_mask: 1.0908  decode.d0.loss_dice: 0.7011  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.8996  decode.d1.loss_dice: 0.6406  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.9837  decode.d2.loss_dice: 0.6133  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.8649  decode.d3.loss_dice: 0.5851  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.8868  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.8997  decode.d5.loss_dice: 0.6100  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.8942  decode.d6.loss_dice: 0.5894  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.8800  decode.d7.loss_dice: 0.5922  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.8887  decode.d8.loss_dice: 0.5823\n",
      "07/02 17:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6300/32000]  base_lr: 5.1309e-06 lr: 5.1309e-07  eta: 1:07:42  time: 0.1571  data_time: 0.0089  memory: 5154  grad_norm: 207.4736  loss: 14.7640  decode.loss_cls: 0.0031  decode.loss_mask: 0.8620  decode.loss_dice: 0.5195  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 1.1797  decode.d0.loss_dice: 0.7038  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.9567  decode.d1.loss_dice: 0.5787  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.8953  decode.d2.loss_dice: 0.5506  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.8714  decode.d3.loss_dice: 0.5268  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.8647  decode.d4.loss_dice: 0.5293  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8614  decode.d5.loss_dice: 0.5296  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.8759  decode.d6.loss_dice: 0.5241  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.8813  decode.d7.loss_dice: 0.5234  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.8697  decode.d8.loss_dice: 0.5199\n",
      "07/02 17:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6350/32000]  base_lr: 5.1220e-06 lr: 5.1220e-07  eta: 1:07:33  time: 0.1572  data_time: 0.0090  memory: 5153  grad_norm: 345.4890  loss: 16.5239  decode.loss_cls: 0.1285  decode.loss_mask: 0.9272  decode.loss_dice: 0.5552  decode.d0.loss_cls: 0.2730  decode.d0.loss_mask: 1.2273  decode.d0.loss_dice: 0.7007  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 1.0017  decode.d1.loss_dice: 0.6126  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 0.9831  decode.d2.loss_dice: 0.5796  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.8903  decode.d3.loss_dice: 0.5446  decode.d4.loss_cls: 0.0234  decode.d4.loss_mask: 0.9345  decode.d4.loss_dice: 0.5694  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.9352  decode.d5.loss_dice: 0.5618  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.9391  decode.d6.loss_dice: 0.5622  decode.d7.loss_cls: 0.1136  decode.d7.loss_mask: 0.9342  decode.d7.loss_dice: 0.5655  decode.d8.loss_cls: 0.1324  decode.d8.loss_mask: 0.9258  decode.d8.loss_dice: 0.5492\n",
      "07/02 17:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6400/32000]  base_lr: 5.1130e-06 lr: 5.1130e-07  eta: 1:07:25  time: 0.1565  data_time: 0.0086  memory: 5152  grad_norm: 195.1100  loss: 14.6536  decode.loss_cls: 0.0009  decode.loss_mask: 0.8866  decode.loss_dice: 0.5529  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 1.0634  decode.d0.loss_dice: 0.6684  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.8929  decode.d1.loss_dice: 0.5881  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.8448  decode.d2.loss_dice: 0.5428  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.8687  decode.d3.loss_dice: 0.5313  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.8686  decode.d4.loss_dice: 0.5306  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.8923  decode.d5.loss_dice: 0.5535  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.8789  decode.d6.loss_dice: 0.5367  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.8746  decode.d7.loss_dice: 0.5478  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.8719  decode.d8.loss_dice: 0.5471\n",
      "07/02 17:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6450/32000]  base_lr: 5.1040e-06 lr: 5.1040e-07  eta: 1:07:17  time: 0.1569  data_time: 0.0090  memory: 5153  grad_norm: 178.7955  loss: 12.9088  decode.loss_cls: 0.0008  decode.loss_mask: 0.7497  decode.loss_dice: 0.4948  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.9130  decode.d0.loss_dice: 0.6288  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.7546  decode.d1.loss_dice: 0.5169  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.7728  decode.d2.loss_dice: 0.5045  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.7862  decode.d3.loss_dice: 0.4984  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.7585  decode.d4.loss_dice: 0.4884  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.7450  decode.d5.loss_dice: 0.4888  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.7463  decode.d6.loss_dice: 0.4844  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7564  decode.d7.loss_dice: 0.4937  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7494  decode.d8.loss_dice: 0.4811\n",
      "07/02 17:18:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6500/32000]  base_lr: 5.0950e-06 lr: 5.0950e-07  eta: 1:07:09  time: 0.1572  data_time: 0.0092  memory: 5153  grad_norm: 237.6441  loss: 13.9229  decode.loss_cls: 0.0024  decode.loss_mask: 0.7776  decode.loss_dice: 0.5325  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 1.0348  decode.d0.loss_dice: 0.7396  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.8416  decode.d1.loss_dice: 0.5676  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.8408  decode.d2.loss_dice: 0.5608  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.7951  decode.d3.loss_dice: 0.5440  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.7562  decode.d4.loss_dice: 0.5392  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.7627  decode.d5.loss_dice: 0.5382  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.7885  decode.d6.loss_dice: 0.5563  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.7741  decode.d7.loss_dice: 0.5401  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.7895  decode.d8.loss_dice: 0.5293\n",
      "07/02 17:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6550/32000]  base_lr: 5.0860e-06 lr: 5.0860e-07  eta: 1:07:01  time: 0.1549  data_time: 0.0089  memory: 5154  grad_norm: 157.2773  loss: 11.6202  decode.loss_cls: 0.0004  decode.loss_mask: 0.6902  decode.loss_dice: 0.4046  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 0.5703  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.6989  decode.d1.loss_dice: 0.4237  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.7061  decode.d2.loss_dice: 0.4125  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.6905  decode.d3.loss_dice: 0.3999  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6991  decode.d4.loss_dice: 0.3991  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7261  decode.d5.loss_dice: 0.4247  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7100  decode.d6.loss_dice: 0.4228  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7086  decode.d7.loss_dice: 0.4099  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7093  decode.d8.loss_dice: 0.4063\n",
      "07/02 17:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6600/32000]  base_lr: 5.0770e-06 lr: 5.0770e-07  eta: 1:06:52  time: 0.1547  data_time: 0.0080  memory: 5154  grad_norm: 225.0204  loss: 14.5706  decode.loss_cls: 0.0015  decode.loss_mask: 0.9085  decode.loss_dice: 0.4950  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 1.0580  decode.d0.loss_dice: 0.6752  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.8914  decode.d1.loss_dice: 0.5524  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.8561  decode.d2.loss_dice: 0.5194  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.9084  decode.d3.loss_dice: 0.5090  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.9183  decode.d4.loss_dice: 0.5098  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.8867  decode.d5.loss_dice: 0.5221  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.9205  decode.d6.loss_dice: 0.5111  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.9092  decode.d7.loss_dice: 0.5163  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.8919  decode.d8.loss_dice: 0.5184\n",
      "07/02 17:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6650/32000]  base_lr: 5.0680e-06 lr: 5.0680e-07  eta: 1:06:44  time: 0.1543  data_time: 0.0081  memory: 5154  grad_norm: 178.7681  loss: 13.5573  decode.loss_cls: 0.0007  decode.loss_mask: 0.7836  decode.loss_dice: 0.5076  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 1.0663  decode.d0.loss_dice: 0.6848  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.8156  decode.d1.loss_dice: 0.5454  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.7940  decode.d2.loss_dice: 0.5507  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.7616  decode.d3.loss_dice: 0.5054  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.7611  decode.d4.loss_dice: 0.5174  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7735  decode.d5.loss_dice: 0.5094  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7965  decode.d6.loss_dice: 0.4974  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7853  decode.d7.loss_dice: 0.5028  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7906  decode.d8.loss_dice: 0.5106\n",
      "07/02 17:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6700/32000]  base_lr: 5.0590e-06 lr: 5.0590e-07  eta: 1:06:36  time: 0.1576  data_time: 0.0086  memory: 5153  grad_norm: 135.1022  loss: 9.0714  decode.loss_cls: 0.0004  decode.loss_mask: 0.5309  decode.loss_dice: 0.3329  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.6964  decode.d0.loss_dice: 0.4495  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.5616  decode.d1.loss_dice: 0.3468  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.5250  decode.d2.loss_dice: 0.3384  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.5273  decode.d3.loss_dice: 0.3203  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.5326  decode.d4.loss_dice: 0.3245  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.5343  decode.d5.loss_dice: 0.3325  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.5435  decode.d6.loss_dice: 0.3382  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.5458  decode.d7.loss_dice: 0.3462  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.5259  decode.d8.loss_dice: 0.3325\n",
      "07/02 17:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6750/32000]  base_lr: 5.0500e-06 lr: 5.0500e-07  eta: 1:06:28  time: 0.1572  data_time: 0.0091  memory: 5153  grad_norm: 217.2830  loss: 13.5817  decode.loss_cls: 0.0017  decode.loss_mask: 0.8054  decode.loss_dice: 0.5001  decode.d0.loss_cls: 0.0848  decode.d0.loss_mask: 0.9820  decode.d0.loss_dice: 0.6378  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.8204  decode.d1.loss_dice: 0.5398  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.7941  decode.d2.loss_dice: 0.5171  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.7952  decode.d3.loss_dice: 0.5130  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.8055  decode.d4.loss_dice: 0.5218  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.7739  decode.d5.loss_dice: 0.5216  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.8101  decode.d6.loss_dice: 0.5191  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.7956  decode.d7.loss_dice: 0.5160  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 0.5029\n",
      "07/02 17:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6800/32000]  base_lr: 5.0410e-06 lr: 5.0410e-07  eta: 1:06:19  time: 0.1571  data_time: 0.0086  memory: 5152  grad_norm: 207.0837  loss: 12.9172  decode.loss_cls: 0.0030  decode.loss_mask: 0.7590  decode.loss_dice: 0.4410  decode.d0.loss_cls: 0.1434  decode.d0.loss_mask: 1.0084  decode.d0.loss_dice: 0.5647  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 0.4935  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 0.4974  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.8095  decode.d3.loss_dice: 0.4779  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.7646  decode.d4.loss_dice: 0.4599  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.7718  decode.d5.loss_dice: 0.4509  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.7513  decode.d6.loss_dice: 0.4374  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.7542  decode.d7.loss_dice: 0.4400  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.7540  decode.d8.loss_dice: 0.4381\n",
      "07/02 17:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6850/32000]  base_lr: 5.0320e-06 lr: 5.0320e-07  eta: 1:06:11  time: 0.1566  data_time: 0.0087  memory: 5153  grad_norm: 171.8868  loss: 11.9579  decode.loss_cls: 0.0017  decode.loss_mask: 0.7071  decode.loss_dice: 0.4246  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.8536  decode.d0.loss_dice: 0.5704  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.6839  decode.d1.loss_dice: 0.4490  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.7201  decode.d2.loss_dice: 0.4269  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.7252  decode.d3.loss_dice: 0.4503  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.4576  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.7321  decode.d5.loss_dice: 0.4778  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.7327  decode.d6.loss_dice: 0.4460  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.7249  decode.d7.loss_dice: 0.4288  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.6942  decode.d8.loss_dice: 0.4183\n",
      "07/02 17:19:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6900/32000]  base_lr: 5.0230e-06 lr: 5.0230e-07  eta: 1:06:03  time: 0.1553  data_time: 0.0091  memory: 5153  grad_norm: 126.7972  loss: 11.8042  decode.loss_cls: 0.0043  decode.loss_mask: 0.7139  decode.loss_dice: 0.4231  decode.d0.loss_cls: 0.0584  decode.d0.loss_mask: 0.9086  decode.d0.loss_dice: 0.5246  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.7735  decode.d1.loss_dice: 0.4377  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.7124  decode.d2.loss_dice: 0.4200  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.7128  decode.d3.loss_dice: 0.4220  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.7364  decode.d4.loss_dice: 0.4193  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.7142  decode.d5.loss_dice: 0.4169  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7313  decode.d6.loss_dice: 0.4027  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.7202  decode.d7.loss_dice: 0.4132  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.7047  decode.d8.loss_dice: 0.4150\n",
      "07/02 17:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6950/32000]  base_lr: 5.0140e-06 lr: 5.0140e-07  eta: 1:05:55  time: 0.1571  data_time: 0.0084  memory: 5153  grad_norm: 172.8101  loss: 14.9184  decode.loss_cls: 0.1288  decode.loss_mask: 0.8252  decode.loss_dice: 0.5074  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 1.0068  decode.d0.loss_dice: 0.6753  decode.d1.loss_cls: 0.2553  decode.d1.loss_mask: 0.8590  decode.d1.loss_dice: 0.5308  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 0.5404  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.8111  decode.d3.loss_dice: 0.5338  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.8077  decode.d4.loss_dice: 0.5213  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 0.8326  decode.d5.loss_dice: 0.5226  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.8159  decode.d6.loss_dice: 0.5164  decode.d7.loss_cls: 0.1780  decode.d7.loss_mask: 0.8322  decode.d7.loss_dice: 0.5082  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.8253  decode.d8.loss_dice: 0.5042\n",
      "07/02 17:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7000/32000]  base_lr: 5.0050e-06 lr: 5.0050e-07  eta: 1:05:47  time: 0.1574  data_time: 0.0089  memory: 5154  grad_norm: 158.2140  loss: 11.6047  decode.loss_cls: 0.0019  decode.loss_mask: 0.6981  decode.loss_dice: 0.4212  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 0.8219  decode.d0.loss_dice: 0.5507  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.6689  decode.d1.loss_dice: 0.4549  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.6877  decode.d2.loss_dice: 0.4435  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.6756  decode.d3.loss_dice: 0.4194  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.6904  decode.d4.loss_dice: 0.4288  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.6773  decode.d5.loss_dice: 0.4292  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.6916  decode.d6.loss_dice: 0.4296  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.7271  decode.d7.loss_dice: 0.4328  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 0.4291\n",
      "07/02 17:20:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0214  data_time: 0.0022  memory: 2168  \n",
      "07/02 17:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0290  data_time: 0.0063  memory: 1078  \n",
      "07/02 17:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 89.18 | 95.68 |\n",
      "|   lesion   | 68.72 | 77.76 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 91.2600  mIoU: 78.9500  mAcc: 86.7200  data_time: 0.0115  time: 0.0370\n",
      "07/02 17:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7050/32000]  base_lr: 4.9960e-06 lr: 4.9960e-07  eta: 1:05:39  time: 0.1565  data_time: 0.0099  memory: 5153  grad_norm: 233.2910  loss: 14.7712  decode.loss_cls: 0.0006  decode.loss_mask: 0.9235  decode.loss_dice: 0.5073  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 1.0889  decode.d0.loss_dice: 0.6090  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.9169  decode.d1.loss_dice: 0.5453  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.9583  decode.d2.loss_dice: 0.5209  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.9501  decode.d3.loss_dice: 0.5385  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.9554  decode.d4.loss_dice: 0.5372  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.8639  decode.d5.loss_dice: 0.5057  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.8916  decode.d6.loss_dice: 0.5157  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.9029  decode.d7.loss_dice: 0.5107  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 0.5178\n",
      "07/02 17:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7100/32000]  base_lr: 4.9870e-06 lr: 4.9870e-07  eta: 1:05:31  time: 0.1549  data_time: 0.0085  memory: 5153  grad_norm: 129.5603  loss: 9.5375  decode.loss_cls: 0.0014  decode.loss_mask: 0.5586  decode.loss_dice: 0.3582  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.7371  decode.d0.loss_dice: 0.4874  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.5844  decode.d1.loss_dice: 0.3753  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.5770  decode.d2.loss_dice: 0.3647  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.5496  decode.d3.loss_dice: 0.3476  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.5591  decode.d4.loss_dice: 0.3474  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.5520  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.5554  decode.d6.loss_dice: 0.3446  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.5449  decode.d7.loss_dice: 0.3384  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.5441  decode.d8.loss_dice: 0.3497\n",
      "07/02 17:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7150/32000]  base_lr: 4.9780e-06 lr: 4.9780e-07  eta: 1:05:22  time: 0.1553  data_time: 0.0089  memory: 5154  grad_norm: 163.5748  loss: 11.4645  decode.loss_cls: 0.0006  decode.loss_mask: 0.6968  decode.loss_dice: 0.4213  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 0.8860  decode.d0.loss_dice: 0.5215  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.7043  decode.d1.loss_dice: 0.4350  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.6828  decode.d2.loss_dice: 0.4013  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 0.4046  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.6937  decode.d4.loss_dice: 0.4146  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.6741  decode.d5.loss_dice: 0.3989  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.6806  decode.d6.loss_dice: 0.3952  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.6827  decode.d7.loss_dice: 0.4159  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6980  decode.d8.loss_dice: 0.4316\n",
      "07/02 17:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7200/32000]  base_lr: 4.9689e-06 lr: 4.9689e-07  eta: 1:05:14  time: 0.1578  data_time: 0.0096  memory: 5153  grad_norm: 194.6348  loss: 15.3079  decode.loss_cls: 0.0006  decode.loss_mask: 0.9768  decode.loss_dice: 0.5509  decode.d0.loss_cls: 0.1460  decode.d0.loss_mask: 1.0444  decode.d0.loss_dice: 0.6356  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.9831  decode.d1.loss_dice: 0.5627  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.9305  decode.d2.loss_dice: 0.5387  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.9283  decode.d3.loss_dice: 0.5057  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.9444  decode.d4.loss_dice: 0.5225  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.9352  decode.d5.loss_dice: 0.5041  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.9654  decode.d6.loss_dice: 0.5283  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.9664  decode.d7.loss_dice: 0.5470  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 1.0026  decode.d8.loss_dice: 0.5600\n",
      "07/02 17:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7250/32000]  base_lr: 4.9599e-06 lr: 4.9599e-07  eta: 1:05:06  time: 0.1587  data_time: 0.0098  memory: 5153  grad_norm: 234.3784  loss: 16.6127  decode.loss_cls: 0.0015  decode.loss_mask: 1.0137  decode.loss_dice: 0.6023  decode.d0.loss_cls: 0.0961  decode.d0.loss_mask: 1.2228  decode.d0.loss_dice: 0.7123  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.9893  decode.d1.loss_dice: 0.6581  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.9647  decode.d2.loss_dice: 0.6297  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.9769  decode.d3.loss_dice: 0.6161  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.9823  decode.d4.loss_dice: 0.6373  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.9860  decode.d5.loss_dice: 0.6281  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.9720  decode.d6.loss_dice: 0.6237  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.9761  decode.d7.loss_dice: 0.6270  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 1.0321  decode.d8.loss_dice: 0.6013\n",
      "07/02 17:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7300/32000]  base_lr: 4.9509e-06 lr: 4.9509e-07  eta: 1:04:59  time: 0.1569  data_time: 0.0094  memory: 5153  grad_norm: 230.3602  loss: 15.9316  decode.loss_cls: 0.0022  decode.loss_mask: 1.0112  decode.loss_dice: 0.5795  decode.d0.loss_cls: 0.1271  decode.d0.loss_mask: 1.1661  decode.d0.loss_dice: 0.6783  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 1.0132  decode.d1.loss_dice: 0.5673  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.9782  decode.d2.loss_dice: 0.5601  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.9704  decode.d3.loss_dice: 0.5312  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.9437  decode.d4.loss_dice: 0.5442  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.9798  decode.d5.loss_dice: 0.5772  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.9722  decode.d6.loss_dice: 0.5594  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.9914  decode.d7.loss_dice: 0.5590  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 1.0116  decode.d8.loss_dice: 0.5819\n",
      "07/02 17:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7350/32000]  base_lr: 4.9419e-06 lr: 4.9419e-07  eta: 1:04:50  time: 0.1562  data_time: 0.0091  memory: 5153  grad_norm: 174.3094  loss: 12.0543  decode.loss_cls: 0.0007  decode.loss_mask: 0.6815  decode.loss_dice: 0.4727  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.8345  decode.d0.loss_dice: 0.5792  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.7214  decode.d1.loss_dice: 0.4884  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7269  decode.d2.loss_dice: 0.5004  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.7130  decode.d3.loss_dice: 0.4637  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.6924  decode.d4.loss_dice: 0.4490  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7056  decode.d5.loss_dice: 0.4677  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6920  decode.d6.loss_dice: 0.4625  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6901  decode.d7.loss_dice: 0.4656  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.6842  decode.d8.loss_dice: 0.4531\n",
      "07/02 17:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7400/32000]  base_lr: 4.9329e-06 lr: 4.9329e-07  eta: 1:04:42  time: 0.1550  data_time: 0.0084  memory: 5153  grad_norm: 216.4204  loss: 14.9848  decode.loss_cls: 0.1702  decode.loss_mask: 0.8774  decode.loss_dice: 0.4669  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 1.0164  decode.d0.loss_dice: 0.5404  decode.d1.loss_cls: 0.1055  decode.d1.loss_mask: 0.8949  decode.d1.loss_dice: 0.5207  decode.d2.loss_cls: 0.2077  decode.d2.loss_mask: 0.9015  decode.d2.loss_dice: 0.4803  decode.d3.loss_cls: 0.1390  decode.d3.loss_mask: 0.8837  decode.d3.loss_dice: 0.4770  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.8172  decode.d4.loss_dice: 0.4483  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.8574  decode.d5.loss_dice: 0.4674  decode.d6.loss_cls: 0.1473  decode.d6.loss_mask: 0.8515  decode.d6.loss_dice: 0.4657  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.8477  decode.d7.loss_dice: 0.4675  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 0.8660  decode.d8.loss_dice: 0.4691\n",
      "07/02 17:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7450/32000]  base_lr: 4.9238e-06 lr: 4.9238e-07  eta: 1:04:34  time: 0.1592  data_time: 0.0104  memory: 5153  grad_norm: 241.2084  loss: 15.6930  decode.loss_cls: 0.0133  decode.loss_mask: 0.9479  decode.loss_dice: 0.5733  decode.d0.loss_cls: 0.1337  decode.d0.loss_mask: 1.0774  decode.d0.loss_dice: 0.6812  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.9379  decode.d1.loss_dice: 0.5907  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 1.0175  decode.d2.loss_dice: 0.5862  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.9280  decode.d3.loss_dice: 0.5695  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.9383  decode.d4.loss_dice: 0.5599  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.9304  decode.d5.loss_dice: 0.5809  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.9251  decode.d6.loss_dice: 0.5666  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.9481  decode.d7.loss_dice: 0.5779  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.9502  decode.d8.loss_dice: 0.5587\n",
      "07/02 17:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7500/32000]  base_lr: 4.9148e-06 lr: 4.9148e-07  eta: 1:04:26  time: 0.1588  data_time: 0.0100  memory: 5153  grad_norm: 202.9164  loss: 13.6112  decode.loss_cls: 0.0005  decode.loss_mask: 0.8167  decode.loss_dice: 0.5151  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 1.0361  decode.d0.loss_dice: 0.6597  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.8157  decode.d1.loss_dice: 0.4975  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.8162  decode.d2.loss_dice: 0.5073  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.8058  decode.d3.loss_dice: 0.4965  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7905  decode.d4.loss_dice: 0.4901  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7992  decode.d5.loss_dice: 0.5054  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8219  decode.d6.loss_dice: 0.5038  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.8290  decode.d7.loss_dice: 0.5204  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.8198  decode.d8.loss_dice: 0.5058\n",
      "07/02 17:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7550/32000]  base_lr: 4.9058e-06 lr: 4.9058e-07  eta: 1:04:19  time: 0.1663  data_time: 0.0202  memory: 5153  grad_norm: 198.7822  loss: 12.4427  decode.loss_cls: 0.0006  decode.loss_mask: 0.7861  decode.loss_dice: 0.4417  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.9378  decode.d0.loss_dice: 0.5644  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.7444  decode.d1.loss_dice: 0.4369  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.7720  decode.d2.loss_dice: 0.4636  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.7627  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.7644  decode.d4.loss_dice: 0.4307  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.7509  decode.d5.loss_dice: 0.4290  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7497  decode.d6.loss_dice: 0.4240  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.7853  decode.d7.loss_dice: 0.4291  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7896  decode.d8.loss_dice: 0.4416\n",
      "07/02 17:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7600/32000]  base_lr: 4.8968e-06 lr: 4.8968e-07  eta: 1:04:10  time: 0.1554  data_time: 0.0086  memory: 5155  grad_norm: 137.1568  loss: 12.6130  decode.loss_cls: 0.0013  decode.loss_mask: 0.7337  decode.loss_dice: 0.4534  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.9682  decode.d0.loss_dice: 0.6071  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.8044  decode.d1.loss_dice: 0.5035  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7632  decode.d2.loss_dice: 0.4626  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7684  decode.d3.loss_dice: 0.4665  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7599  decode.d4.loss_dice: 0.4578  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7533  decode.d5.loss_dice: 0.4409  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7618  decode.d6.loss_dice: 0.4547  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7463  decode.d7.loss_dice: 0.4472  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7448  decode.d8.loss_dice: 0.4408\n",
      "07/02 17:22:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7650/32000]  base_lr: 4.8877e-06 lr: 4.8877e-07  eta: 1:04:02  time: 0.1573  data_time: 0.0095  memory: 5154  grad_norm: 259.5052  loss: 14.9890  decode.loss_cls: 0.0005  decode.loss_mask: 0.8729  decode.loss_dice: 0.5533  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 0.7022  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.9254  decode.d1.loss_dice: 0.5965  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.8919  decode.d2.loss_dice: 0.5627  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.9305  decode.d3.loss_dice: 0.5728  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.9049  decode.d4.loss_dice: 0.5625  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.8821  decode.d5.loss_dice: 0.5587  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.8821  decode.d6.loss_dice: 0.5609  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.8592  decode.d7.loss_dice: 0.5594  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8761  decode.d8.loss_dice: 0.5641\n",
      "07/02 17:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7700/32000]  base_lr: 4.8787e-06 lr: 4.8787e-07  eta: 1:03:55  time: 0.1583  data_time: 0.0095  memory: 5153  grad_norm: 254.5885  loss: 15.2675  decode.loss_cls: 0.3918  decode.loss_mask: 0.8062  decode.loss_dice: 0.4905  decode.d0.loss_cls: 0.1369  decode.d0.loss_mask: 1.0468  decode.d0.loss_dice: 0.6592  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.8384  decode.d1.loss_dice: 0.5095  decode.d2.loss_cls: 0.2470  decode.d2.loss_mask: 0.8339  decode.d2.loss_dice: 0.5211  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.8084  decode.d3.loss_dice: 0.4843  decode.d4.loss_cls: 0.0275  decode.d4.loss_mask: 0.7834  decode.d4.loss_dice: 0.4940  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 0.4774  decode.d6.loss_cls: 0.1704  decode.d6.loss_mask: 0.8085  decode.d6.loss_dice: 0.4720  decode.d7.loss_cls: 0.1754  decode.d7.loss_mask: 0.7906  decode.d7.loss_dice: 0.4811  decode.d8.loss_cls: 0.3679  decode.d8.loss_mask: 0.7916  decode.d8.loss_dice: 0.5043\n",
      "07/02 17:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7750/32000]  base_lr: 4.8697e-06 lr: 4.8697e-07  eta: 1:03:47  time: 0.1587  data_time: 0.0099  memory: 5154  grad_norm: 288.4627  loss: 15.4315  decode.loss_cls: 0.0006  decode.loss_mask: 0.9205  decode.loss_dice: 0.5485  decode.d0.loss_cls: 0.1086  decode.d0.loss_mask: 1.1912  decode.d0.loss_dice: 0.6740  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 1.0073  decode.d1.loss_dice: 0.5905  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 0.5813  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 1.0005  decode.d3.loss_dice: 0.5580  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 0.5341  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.9046  decode.d5.loss_dice: 0.5331  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.8876  decode.d6.loss_dice: 0.5296  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.9303  decode.d7.loss_dice: 0.5364  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.9295  decode.d8.loss_dice: 0.5441\n",
      "07/02 17:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7800/32000]  base_lr: 4.8606e-06 lr: 4.8606e-07  eta: 1:03:39  time: 0.1587  data_time: 0.0101  memory: 5154  grad_norm: 234.6705  loss: 16.3809  decode.loss_cls: 0.0006  decode.loss_mask: 0.9947  decode.loss_dice: 0.5886  decode.d0.loss_cls: 0.0922  decode.d0.loss_mask: 1.2335  decode.d0.loss_dice: 0.7834  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 1.0339  decode.d1.loss_dice: 0.6203  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 1.0020  decode.d2.loss_dice: 0.5840  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.9675  decode.d3.loss_dice: 0.5970  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.9755  decode.d4.loss_dice: 0.6005  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 1.0095  decode.d5.loss_dice: 0.5940  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.9683  decode.d6.loss_dice: 0.5636  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.9922  decode.d7.loss_dice: 0.5885  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.9866  decode.d8.loss_dice: 0.5878\n",
      "07/02 17:22:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7850/32000]  base_lr: 4.8516e-06 lr: 4.8516e-07  eta: 1:03:31  time: 0.1595  data_time: 0.0101  memory: 5153  grad_norm: 114.7609  loss: 9.5044  decode.loss_cls: 0.0004  decode.loss_mask: 0.5483  decode.loss_dice: 0.3701  decode.d0.loss_cls: 0.0585  decode.d0.loss_mask: 0.7104  decode.d0.loss_dice: 0.4914  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.5750  decode.d1.loss_dice: 0.3959  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.5374  decode.d2.loss_dice: 0.3733  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.5409  decode.d3.loss_dice: 0.3526  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.5325  decode.d4.loss_dice: 0.3557  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.5244  decode.d5.loss_dice: 0.3777  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.5370  decode.d6.loss_dice: 0.3705  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.5394  decode.d7.loss_dice: 0.3792  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5412  decode.d8.loss_dice: 0.3851\n",
      "07/02 17:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7900/32000]  base_lr: 4.8425e-06 lr: 4.8425e-07  eta: 1:03:24  time: 0.1579  data_time: 0.0097  memory: 5153  grad_norm: 208.5984  loss: 13.8282  decode.loss_cls: 0.0006  decode.loss_mask: 0.8209  decode.loss_dice: 0.5055  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 1.0349  decode.d0.loss_dice: 0.6359  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 0.5107  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.8398  decode.d2.loss_dice: 0.5046  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.8563  decode.d3.loss_dice: 0.5123  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.8480  decode.d4.loss_dice: 0.5088  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.7725  decode.d5.loss_dice: 0.5051  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.8276  decode.d6.loss_dice: 0.5128  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 0.5084  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.8122  decode.d8.loss_dice: 0.5169\n",
      "07/02 17:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7950/32000]  base_lr: 4.8335e-06 lr: 4.8335e-07  eta: 1:03:16  time: 0.1581  data_time: 0.0096  memory: 5153  grad_norm: 166.2120  loss: 11.5944  decode.loss_cls: 0.0023  decode.loss_mask: 0.6424  decode.loss_dice: 0.4766  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 0.6049  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.6643  decode.d1.loss_dice: 0.4818  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.6342  decode.d2.loss_dice: 0.4732  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.6330  decode.d3.loss_dice: 0.4687  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.6375  decode.d4.loss_dice: 0.4781  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6297  decode.d5.loss_dice: 0.4810  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.6425  decode.d6.loss_dice: 0.4864  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.6605  decode.d7.loss_dice: 0.4834  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.6383  decode.d8.loss_dice: 0.4716\n",
      "07/02 17:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8000/32000]  base_lr: 4.8244e-06 lr: 4.8244e-07  eta: 1:03:08  time: 0.1580  data_time: 0.0097  memory: 5153  grad_norm: 194.4826  loss: 16.7089  decode.loss_cls: 0.3776  decode.loss_mask: 0.8324  decode.loss_dice: 0.4824  decode.d0.loss_cls: 0.1518  decode.d0.loss_mask: 1.0320  decode.d0.loss_dice: 0.5645  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 0.8630  decode.d1.loss_dice: 0.5246  decode.d2.loss_cls: 0.2853  decode.d2.loss_mask: 0.8158  decode.d2.loss_dice: 0.4866  decode.d3.loss_cls: 0.3607  decode.d3.loss_mask: 0.8543  decode.d3.loss_dice: 0.5201  decode.d4.loss_cls: 0.1825  decode.d4.loss_mask: 0.8476  decode.d4.loss_dice: 0.5404  decode.d5.loss_cls: 0.2485  decode.d5.loss_mask: 0.8605  decode.d5.loss_dice: 0.5147  decode.d6.loss_cls: 0.3737  decode.d6.loss_mask: 0.8452  decode.d6.loss_dice: 0.5014  decode.d7.loss_cls: 0.3602  decode.d7.loss_mask: 0.8390  decode.d7.loss_dice: 0.4979  decode.d8.loss_cls: 0.3730  decode.d8.loss_mask: 0.8442  decode.d8.loss_dice: 0.4998\n",
      "07/02 17:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0214  data_time: 0.0023  memory: 2169  \n",
      "07/02 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0288  data_time: 0.0063  memory: 1074  \n",
      "07/02 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background |  90.4 | 95.48 |\n",
      "|   lesion   | 72.86 | 82.89 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 92.3700  mIoU: 81.6300  mAcc: 89.1800  data_time: 0.0115  time: 0.0367\n",
      "07/02 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_6000.pth is removed\n",
      "07/02 17:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 81.6300 mIoU at 8000 iter is saved to best_mIoU_iter_8000.pth.\n",
      "07/02 17:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8050/32000]  base_lr: 4.8154e-06 lr: 4.8154e-07  eta: 1:03:05  time: 0.1569  data_time: 0.0088  memory: 5153  grad_norm: 149.8049  loss: 10.4420  decode.loss_cls: 0.0004  decode.loss_mask: 0.5922  decode.loss_dice: 0.3976  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.8307  decode.d0.loss_dice: 0.5241  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.6247  decode.d1.loss_dice: 0.4031  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.6322  decode.d2.loss_dice: 0.4070  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.6090  decode.d3.loss_dice: 0.3979  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.6143  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6047  decode.d5.loss_dice: 0.3896  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6015  decode.d6.loss_dice: 0.3900  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.5989  decode.d7.loss_dice: 0.3918  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5812  decode.d8.loss_dice: 0.3999\n",
      "07/02 17:23:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8100/32000]  base_lr: 4.8063e-06 lr: 4.8063e-07  eta: 1:02:57  time: 0.1558  data_time: 0.0083  memory: 5154  grad_norm: 165.5556  loss: 10.4905  decode.loss_cls: 0.0006  decode.loss_mask: 0.6148  decode.loss_dice: 0.3725  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.7219  decode.d0.loss_dice: 0.4739  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.6542  decode.d1.loss_dice: 0.4123  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.6646  decode.d2.loss_dice: 0.4064  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.6387  decode.d3.loss_dice: 0.4129  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.6123  decode.d4.loss_dice: 0.4067  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.6337  decode.d5.loss_dice: 0.4071  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6005  decode.d6.loss_dice: 0.3856  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6040  decode.d7.loss_dice: 0.3763  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6200  decode.d8.loss_dice: 0.3772\n",
      "07/02 17:23:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8150/32000]  base_lr: 4.7973e-06 lr: 4.7973e-07  eta: 1:02:49  time: 0.1568  data_time: 0.0085  memory: 5155  grad_norm: 172.3888  loss: 11.4631  decode.loss_cls: 0.0004  decode.loss_mask: 0.6631  decode.loss_dice: 0.4360  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.8116  decode.d0.loss_dice: 0.5474  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.6798  decode.d1.loss_dice: 0.4605  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.6847  decode.d2.loss_dice: 0.4591  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 0.4511  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.6798  decode.d4.loss_dice: 0.4372  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.6597  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 0.4552  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.6559  decode.d7.loss_dice: 0.4392  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.6508  decode.d8.loss_dice: 0.4251\n",
      "07/02 17:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8200/32000]  base_lr: 4.7882e-06 lr: 4.7882e-07  eta: 1:02:41  time: 0.1569  data_time: 0.0087  memory: 5154  grad_norm: 168.8812  loss: 12.5798  decode.loss_cls: 0.0050  decode.loss_mask: 0.6473  decode.loss_dice: 0.4964  decode.d0.loss_cls: 0.1575  decode.d0.loss_mask: 0.8204  decode.d0.loss_dice: 0.6338  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.6313  decode.d1.loss_dice: 0.5095  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.6271  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.6542  decode.d3.loss_dice: 0.4933  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.6381  decode.d4.loss_dice: 0.4800  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 0.6217  decode.d5.loss_dice: 0.5041  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 0.6359  decode.d6.loss_dice: 0.5003  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.6480  decode.d7.loss_dice: 0.5064  decode.d8.loss_cls: 0.1784  decode.d8.loss_mask: 0.6529  decode.d8.loss_dice: 0.4894\n",
      "07/02 17:23:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8250/32000]  base_lr: 4.7792e-06 lr: 4.7792e-07  eta: 1:02:33  time: 0.1580  data_time: 0.0091  memory: 5153  grad_norm: 264.6783  loss: 15.2962  decode.loss_cls: 0.0028  decode.loss_mask: 0.9196  decode.loss_dice: 0.5321  decode.d0.loss_cls: 0.1093  decode.d0.loss_mask: 1.1425  decode.d0.loss_dice: 0.6578  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.9895  decode.d1.loss_dice: 0.5572  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.9066  decode.d2.loss_dice: 0.5225  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.9699  decode.d3.loss_dice: 0.5370  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.9536  decode.d4.loss_dice: 0.5342  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.9420  decode.d5.loss_dice: 0.5533  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.9173  decode.d6.loss_dice: 0.5465  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.9363  decode.d7.loss_dice: 0.5436  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.9317  decode.d8.loss_dice: 0.5300\n",
      "07/02 17:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8300/32000]  base_lr: 4.7701e-06 lr: 4.7701e-07  eta: 1:02:25  time: 0.1591  data_time: 0.0099  memory: 5153  grad_norm: 165.9991  loss: 12.0538  decode.loss_cls: 0.0010  decode.loss_mask: 0.6957  decode.loss_dice: 0.4572  decode.d0.loss_cls: 0.0692  decode.d0.loss_mask: 0.9571  decode.d0.loss_dice: 0.5845  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.7363  decode.d1.loss_dice: 0.4684  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.7197  decode.d2.loss_dice: 0.4542  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.7221  decode.d3.loss_dice: 0.4457  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 0.4430  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.7015  decode.d5.loss_dice: 0.4500  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7115  decode.d6.loss_dice: 0.4414  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6889  decode.d7.loss_dice: 0.4349  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.6972  decode.d8.loss_dice: 0.4551\n",
      "07/02 17:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8350/32000]  base_lr: 4.7611e-06 lr: 4.7611e-07  eta: 1:02:18  time: 0.1582  data_time: 0.0099  memory: 5153  grad_norm: 245.8418  loss: 13.8400  decode.loss_cls: 0.0026  decode.loss_mask: 0.7411  decode.loss_dice: 0.5191  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.9543  decode.d0.loss_dice: 0.6626  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.8106  decode.d1.loss_dice: 0.5578  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 0.5571  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.8016  decode.d3.loss_dice: 0.5423  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.8028  decode.d4.loss_dice: 0.5405  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.8535  decode.d5.loss_dice: 0.5467  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.8327  decode.d6.loss_dice: 0.5525  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.7990  decode.d7.loss_dice: 0.5316  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.7530  decode.d8.loss_dice: 0.5237\n",
      "07/02 17:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8400/32000]  base_lr: 4.7520e-06 lr: 4.7520e-07  eta: 1:02:10  time: 0.1583  data_time: 0.0099  memory: 5153  grad_norm: 150.6983  loss: 12.7069  decode.loss_cls: 0.0010  decode.loss_mask: 0.7737  decode.loss_dice: 0.4120  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.9770  decode.d0.loss_dice: 0.5313  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.8275  decode.d1.loss_dice: 0.4518  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.8162  decode.d2.loss_dice: 0.4542  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.7993  decode.d3.loss_dice: 0.4230  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.8086  decode.d4.loss_dice: 0.4346  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.8102  decode.d5.loss_dice: 0.4381  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.8011  decode.d6.loss_dice: 0.4305  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.8127  decode.d7.loss_dice: 0.4357  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7747  decode.d8.loss_dice: 0.4186\n",
      "07/02 17:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8450/32000]  base_lr: 4.7430e-06 lr: 4.7430e-07  eta: 1:02:02  time: 0.1584  data_time: 0.0097  memory: 5153  grad_norm: 247.8242  loss: 14.6957  decode.loss_cls: 0.0061  decode.loss_mask: 0.7931  decode.loss_dice: 0.5845  decode.d0.loss_cls: 0.1289  decode.d0.loss_mask: 0.9299  decode.d0.loss_dice: 0.7408  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.8828  decode.d1.loss_dice: 0.6375  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 0.8204  decode.d2.loss_dice: 0.5966  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.8204  decode.d3.loss_dice: 0.5769  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.8214  decode.d4.loss_dice: 0.6223  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.8011  decode.d5.loss_dice: 0.6290  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.8167  decode.d6.loss_dice: 0.6218  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.7914  decode.d7.loss_dice: 0.6098  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.7817  decode.d8.loss_dice: 0.5922\n",
      "07/02 17:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8500/32000]  base_lr: 4.7339e-06 lr: 4.7339e-07  eta: 1:01:54  time: 0.1590  data_time: 0.0101  memory: 5154  grad_norm: 216.1138  loss: 16.9724  decode.loss_cls: 0.0004  decode.loss_mask: 1.0221  decode.loss_dice: 0.5951  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 1.2536  decode.d0.loss_dice: 0.7379  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 1.0638  decode.d1.loss_dice: 0.6280  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 1.0308  decode.d2.loss_dice: 0.6207  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 1.0347  decode.d3.loss_dice: 0.5931  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 1.0687  decode.d4.loss_dice: 0.6136  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 1.0738  decode.d5.loss_dice: 0.6054  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 1.0355  decode.d6.loss_dice: 0.6041  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 1.0422  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 1.0413  decode.d8.loss_dice: 0.6032\n",
      "07/02 17:24:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8550/32000]  base_lr: 4.7248e-06 lr: 4.7248e-07  eta: 1:01:46  time: 0.1525  data_time: 0.0080  memory: 5154  grad_norm: 208.4138  loss: 12.1474  decode.loss_cls: 0.0019  decode.loss_mask: 0.6718  decode.loss_dice: 0.4875  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.8691  decode.d0.loss_dice: 0.6472  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.7401  decode.d1.loss_dice: 0.5334  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.6899  decode.d2.loss_dice: 0.5027  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.6595  decode.d3.loss_dice: 0.4684  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.6633  decode.d4.loss_dice: 0.4869  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.6702  decode.d5.loss_dice: 0.5012  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.6712  decode.d6.loss_dice: 0.4898  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.6685  decode.d7.loss_dice: 0.4794  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.6617  decode.d8.loss_dice: 0.4695\n",
      "07/02 17:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8600/32000]  base_lr: 4.7158e-06 lr: 4.7158e-07  eta: 1:01:38  time: 0.1580  data_time: 0.0098  memory: 5153  grad_norm: 193.3774  loss: 13.8352  decode.loss_cls: 0.0004  decode.loss_mask: 0.7926  decode.loss_dice: 0.4948  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 1.0320  decode.d0.loss_dice: 0.6644  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.8844  decode.d1.loss_dice: 0.5426  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.8365  decode.d2.loss_dice: 0.5209  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.8658  decode.d3.loss_dice: 0.5219  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.8496  decode.d4.loss_dice: 0.5229  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.8271  decode.d5.loss_dice: 0.5024  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7944  decode.d6.loss_dice: 0.5023  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8018  decode.d7.loss_dice: 0.5009  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7996  decode.d8.loss_dice: 0.5120\n",
      "07/02 17:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8650/32000]  base_lr: 4.7067e-06 lr: 4.7067e-07  eta: 1:01:30  time: 0.1580  data_time: 0.0097  memory: 5153  grad_norm: 218.1235  loss: 13.5181  decode.loss_cls: 0.0040  decode.loss_mask: 0.7704  decode.loss_dice: 0.4721  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 1.0367  decode.d0.loss_dice: 0.6509  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.9166  decode.d1.loss_dice: 0.5345  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.8682  decode.d2.loss_dice: 0.4924  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.8593  decode.d3.loss_dice: 0.4728  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.8144  decode.d4.loss_dice: 0.4571  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.8022  decode.d5.loss_dice: 0.4603  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.8042  decode.d6.loss_dice: 0.4756  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.7799  decode.d7.loss_dice: 0.4691  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.7838  decode.d8.loss_dice: 0.4641\n",
      "07/02 17:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8700/32000]  base_lr: 4.6976e-06 lr: 4.6976e-07  eta: 1:01:22  time: 0.1595  data_time: 0.0106  memory: 5153  grad_norm: 168.9952  loss: 13.3850  decode.loss_cls: 0.0008  decode.loss_mask: 0.8254  decode.loss_dice: 0.4816  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 1.0411  decode.d0.loss_dice: 0.6112  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.8373  decode.d1.loss_dice: 0.4796  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.8049  decode.d2.loss_dice: 0.4608  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.8204  decode.d3.loss_dice: 0.5001  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.8257  decode.d4.loss_dice: 0.4677  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8322  decode.d5.loss_dice: 0.4729  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.8033  decode.d6.loss_dice: 0.4635  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.8120  decode.d7.loss_dice: 0.4728  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.8217  decode.d8.loss_dice: 0.4813\n",
      "07/02 17:25:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8750/32000]  base_lr: 4.6885e-06 lr: 4.6885e-07  eta: 1:01:15  time: 0.1600  data_time: 0.0104  memory: 5153  grad_norm: 247.2367  loss: 14.1089  decode.loss_cls: 0.0014  decode.loss_mask: 0.8512  decode.loss_dice: 0.4874  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 1.0945  decode.d0.loss_dice: 0.6783  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.8775  decode.d1.loss_dice: 0.5558  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.8577  decode.d2.loss_dice: 0.5496  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.8465  decode.d3.loss_dice: 0.5118  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.8457  decode.d4.loss_dice: 0.5218  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 0.5317  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.8208  decode.d6.loss_dice: 0.4926  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.8363  decode.d7.loss_dice: 0.4987  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.8305  decode.d8.loss_dice: 0.4947\n",
      "07/02 17:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8800/32000]  base_lr: 4.6795e-06 lr: 4.6795e-07  eta: 1:01:07  time: 0.1585  data_time: 0.0097  memory: 5153  grad_norm: 162.7500  loss: 12.7612  decode.loss_cls: 0.0005  decode.loss_mask: 0.7564  decode.loss_dice: 0.4331  decode.d0.loss_cls: 0.0481  decode.d0.loss_mask: 1.0122  decode.d0.loss_dice: 0.5836  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.8051  decode.d1.loss_dice: 0.4724  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7982  decode.d2.loss_dice: 0.4727  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7924  decode.d3.loss_dice: 0.4468  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7798  decode.d4.loss_dice: 0.4440  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7881  decode.d5.loss_dice: 0.4448  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7868  decode.d6.loss_dice: 0.4486  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7888  decode.d7.loss_dice: 0.4520  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7647  decode.d8.loss_dice: 0.4355\n",
      "07/02 17:25:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8850/32000]  base_lr: 4.6704e-06 lr: 4.6704e-07  eta: 1:00:58  time: 0.1579  data_time: 0.0095  memory: 5152  grad_norm: 147.7697  loss: 10.9258  decode.loss_cls: 0.0045  decode.loss_mask: 0.6630  decode.loss_dice: 0.3657  decode.d0.loss_cls: 0.0516  decode.d0.loss_mask: 0.9017  decode.d0.loss_dice: 0.5347  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.6911  decode.d1.loss_dice: 0.4085  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.6823  decode.d2.loss_dice: 0.3946  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.6620  decode.d3.loss_dice: 0.3758  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.6617  decode.d4.loss_dice: 0.3684  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.6539  decode.d5.loss_dice: 0.3887  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.6498  decode.d6.loss_dice: 0.3708  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.6532  decode.d7.loss_dice: 0.3718  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.6448  decode.d8.loss_dice: 0.3669\n",
      "07/02 17:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8900/32000]  base_lr: 4.6613e-06 lr: 4.6613e-07  eta: 1:00:51  time: 0.1583  data_time: 0.0093  memory: 5155  grad_norm: 231.8844  loss: 15.3017  decode.loss_cls: 0.0013  decode.loss_mask: 0.9045  decode.loss_dice: 0.5371  decode.d0.loss_cls: 0.1055  decode.d0.loss_mask: 1.0940  decode.d0.loss_dice: 0.6592  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 1.0093  decode.d1.loss_dice: 0.5960  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.9408  decode.d2.loss_dice: 0.5941  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.9573  decode.d3.loss_dice: 0.5557  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.9143  decode.d4.loss_dice: 0.5457  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.9187  decode.d5.loss_dice: 0.5620  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.9079  decode.d6.loss_dice: 0.5548  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.8871  decode.d7.loss_dice: 0.5405  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8945  decode.d8.loss_dice: 0.5499\n",
      "07/02 17:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8950/32000]  base_lr: 4.6522e-06 lr: 4.6522e-07  eta: 1:00:43  time: 0.1592  data_time: 0.0101  memory: 5153  grad_norm: 216.3575  loss: 12.4557  decode.loss_cls: 0.0125  decode.loss_mask: 0.7064  decode.loss_dice: 0.4444  decode.d0.loss_cls: 0.0741  decode.d0.loss_mask: 0.9548  decode.d0.loss_dice: 0.5924  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.7477  decode.d1.loss_dice: 0.4806  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.7401  decode.d2.loss_dice: 0.4707  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.7322  decode.d3.loss_dice: 0.4937  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7242  decode.d4.loss_dice: 0.4737  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7367  decode.d5.loss_dice: 0.4723  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.7340  decode.d6.loss_dice: 0.4582  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.7172  decode.d7.loss_dice: 0.4656  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.7078  decode.d8.loss_dice: 0.4331\n",
      "07/02 17:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9000/32000]  base_lr: 4.6431e-06 lr: 4.6431e-07  eta: 1:00:35  time: 0.1590  data_time: 0.0103  memory: 5153  grad_norm: 199.7703  loss: 13.1954  decode.loss_cls: 0.0043  decode.loss_mask: 0.7080  decode.loss_dice: 0.4907  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.9677  decode.d0.loss_dice: 0.6818  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.7497  decode.d1.loss_dice: 0.5285  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.7789  decode.d2.loss_dice: 0.5441  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.7764  decode.d3.loss_dice: 0.5213  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.7466  decode.d4.loss_dice: 0.5028  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.7797  decode.d5.loss_dice: 0.5293  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.7622  decode.d6.loss_dice: 0.5258  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.7313  decode.d7.loss_dice: 0.4938  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.7345  decode.d8.loss_dice: 0.5041\n",
      "07/02 17:25:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0212  data_time: 0.0021  memory: 2164  \n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0287  data_time: 0.0062  memory: 1077  \n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 89.99 | 91.77 |\n",
      "|   lesion   | 75.15 |  94.0 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 92.3200  mIoU: 82.5700  mAcc: 92.8800  data_time: 0.0114  time: 0.0366\n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_8000.pth is removed\n",
      "07/02 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 82.5700 mIoU at 9000 iter is saved to best_mIoU_iter_9000.pth.\n",
      "07/02 17:25:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9050/32000]  base_lr: 4.6341e-06 lr: 4.6341e-07  eta: 1:00:31  time: 0.1577  data_time: 0.0088  memory: 5154  grad_norm: 331.3891  loss: 16.9084  decode.loss_cls: 0.0017  decode.loss_mask: 0.9991  decode.loss_dice: 0.6611  decode.d0.loss_cls: 0.1411  decode.d0.loss_mask: 1.1341  decode.d0.loss_dice: 0.7810  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 1.0208  decode.d1.loss_dice: 0.6653  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.9873  decode.d2.loss_dice: 0.6692  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.9641  decode.d3.loss_dice: 0.6709  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 1.0075  decode.d4.loss_dice: 0.6788  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.9810  decode.d5.loss_dice: 0.6582  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.9648  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.9680  decode.d7.loss_dice: 0.6247  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.9954  decode.d8.loss_dice: 0.6336\n",
      "07/02 17:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9100/32000]  base_lr: 4.6250e-06 lr: 4.6250e-07  eta: 1:00:23  time: 0.1569  data_time: 0.0086  memory: 5153  grad_norm: 179.9346  loss: 12.5522  decode.loss_cls: 0.0022  decode.loss_mask: 0.7441  decode.loss_dice: 0.4452  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.9138  decode.d0.loss_dice: 0.6068  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.7715  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.7730  decode.d2.loss_dice: 0.4752  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.7657  decode.d3.loss_dice: 0.4372  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.7719  decode.d4.loss_dice: 0.4508  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.7610  decode.d5.loss_dice: 0.4400  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.7680  decode.d6.loss_dice: 0.4439  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.7586  decode.d7.loss_dice: 0.4323  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.7469  decode.d8.loss_dice: 0.4600\n",
      "07/02 17:26:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9150/32000]  base_lr: 4.6159e-06 lr: 4.6159e-07  eta: 1:00:15  time: 0.1571  data_time: 0.0085  memory: 5153  grad_norm: 210.4909  loss: 11.5216  decode.loss_cls: 0.0009  decode.loss_mask: 0.6918  decode.loss_dice: 0.4265  decode.d0.loss_cls: 0.0974  decode.d0.loss_mask: 0.8405  decode.d0.loss_dice: 0.5388  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.7190  decode.d1.loss_dice: 0.4446  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.6843  decode.d2.loss_dice: 0.4565  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.6469  decode.d3.loss_dice: 0.4096  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6588  decode.d4.loss_dice: 0.4087  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.6773  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.7015  decode.d6.loss_dice: 0.4541  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.6781  decode.d7.loss_dice: 0.4304  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6847  decode.d8.loss_dice: 0.4274\n",
      "07/02 17:26:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9200/32000]  base_lr: 4.6068e-06 lr: 4.6068e-07  eta: 1:00:07  time: 0.1578  data_time: 0.0093  memory: 5153  grad_norm: 179.4676  loss: 14.0976  decode.loss_cls: 0.0005  decode.loss_mask: 0.8762  decode.loss_dice: 0.4772  decode.d0.loss_cls: 0.0438  decode.d0.loss_mask: 1.1600  decode.d0.loss_dice: 0.6311  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.8905  decode.d1.loss_dice: 0.5015  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.9073  decode.d2.loss_dice: 0.4974  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.9020  decode.d3.loss_dice: 0.4926  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.8734  decode.d4.loss_dice: 0.4771  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8764  decode.d5.loss_dice: 0.4784  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8732  decode.d6.loss_dice: 0.4563  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.8524  decode.d7.loss_dice: 0.4531  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.8899  decode.d8.loss_dice: 0.4777\n",
      "07/02 17:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9250/32000]  base_lr: 4.5977e-06 lr: 4.5977e-07  eta: 0:59:59  time: 0.1572  data_time: 0.0086  memory: 5153  grad_norm: 273.6824  loss: 15.2556  decode.loss_cls: 0.0025  decode.loss_mask: 0.8639  decode.loss_dice: 0.5878  decode.d0.loss_cls: 0.1071  decode.d0.loss_mask: 1.0562  decode.d0.loss_dice: 0.7190  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.9408  decode.d1.loss_dice: 0.6076  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.9062  decode.d2.loss_dice: 0.6120  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.8807  decode.d3.loss_dice: 0.6019  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.8548  decode.d4.loss_dice: 0.5761  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.9138  decode.d5.loss_dice: 0.5911  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.8915  decode.d6.loss_dice: 0.5885  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.8807  decode.d7.loss_dice: 0.5867  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.8601  decode.d8.loss_dice: 0.5899\n",
      "07/02 17:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9300/32000]  base_lr: 4.5886e-06 lr: 4.5886e-07  eta: 0:59:51  time: 0.1581  data_time: 0.0090  memory: 5153  grad_norm: 210.8841  loss: 13.3412  decode.loss_cls: 0.0025  decode.loss_mask: 0.7490  decode.loss_dice: 0.4601  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.9585  decode.d0.loss_dice: 0.6446  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.8359  decode.d1.loss_dice: 0.5461  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 0.5075  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.8055  decode.d3.loss_dice: 0.5328  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.7799  decode.d4.loss_dice: 0.5103  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.7650  decode.d5.loss_dice: 0.4906  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.7670  decode.d6.loss_dice: 0.4872  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.7891  decode.d7.loss_dice: 0.4925  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.7692  decode.d8.loss_dice: 0.5006\n",
      "07/02 17:26:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9350/32000]  base_lr: 4.5795e-06 lr: 4.5795e-07  eta: 0:59:43  time: 0.1568  data_time: 0.0086  memory: 5153  grad_norm: 240.8030  loss: 14.7083  decode.loss_cls: 0.0041  decode.loss_mask: 0.8684  decode.loss_dice: 0.5277  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 1.0368  decode.d0.loss_dice: 0.6775  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.9236  decode.d1.loss_dice: 0.5553  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.9188  decode.d2.loss_dice: 0.5492  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.8866  decode.d3.loss_dice: 0.5453  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.8886  decode.d4.loss_dice: 0.5357  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.8724  decode.d5.loss_dice: 0.5132  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.8717  decode.d6.loss_dice: 0.5390  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.8951  decode.d7.loss_dice: 0.5536  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.8602  decode.d8.loss_dice: 0.5192\n",
      "07/02 17:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9400/32000]  base_lr: 4.5704e-06 lr: 4.5704e-07  eta: 0:59:35  time: 0.1587  data_time: 0.0101  memory: 5154  grad_norm: 121.2949  loss: 9.7613  decode.loss_cls: 0.0002  decode.loss_mask: 0.5597  decode.loss_dice: 0.3576  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.7277  decode.d0.loss_dice: 0.4708  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.6006  decode.d1.loss_dice: 0.3754  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.6116  decode.d2.loss_dice: 0.3745  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5856  decode.d3.loss_dice: 0.3588  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.5993  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.5824  decode.d5.loss_dice: 0.3592  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5782  decode.d6.loss_dice: 0.3583  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.5602  decode.d7.loss_dice: 0.3580  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5571  decode.d8.loss_dice: 0.3496\n",
      "07/02 17:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9450/32000]  base_lr: 4.5613e-06 lr: 4.5613e-07  eta: 0:59:28  time: 0.1585  data_time: 0.0098  memory: 5154  grad_norm: 157.4074  loss: 10.8040  decode.loss_cls: 0.0006  decode.loss_mask: 0.6053  decode.loss_dice: 0.4270  decode.d0.loss_cls: 0.0451  decode.d0.loss_mask: 0.7845  decode.d0.loss_dice: 0.5339  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.6205  decode.d1.loss_dice: 0.4414  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.6226  decode.d2.loss_dice: 0.4407  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.6143  decode.d3.loss_dice: 0.4224  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6271  decode.d4.loss_dice: 0.4242  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6173  decode.d5.loss_dice: 0.4187  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.6137  decode.d6.loss_dice: 0.4419  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.6140  decode.d7.loss_dice: 0.4299  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.6070  decode.d8.loss_dice: 0.4379\n",
      "07/02 17:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9500/32000]  base_lr: 4.5522e-06 lr: 4.5522e-07  eta: 0:59:20  time: 0.1585  data_time: 0.0097  memory: 5153  grad_norm: 182.9085  loss: 13.1273  decode.loss_cls: 0.0020  decode.loss_mask: 0.7760  decode.loss_dice: 0.4414  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.9740  decode.d0.loss_dice: 0.5730  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.8313  decode.d1.loss_dice: 0.4950  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.8067  decode.d2.loss_dice: 0.4610  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.8271  decode.d3.loss_dice: 0.4578  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.8349  decode.d4.loss_dice: 0.4622  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.8169  decode.d5.loss_dice: 0.4607  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 0.4618  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.8308  decode.d7.loss_dice: 0.4515  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.7793  decode.d8.loss_dice: 0.4521\n",
      "07/02 17:27:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9550/32000]  base_lr: 4.5431e-06 lr: 4.5431e-07  eta: 0:59:12  time: 0.1587  data_time: 0.0097  memory: 5153  grad_norm: 155.7059  loss: 10.8439  decode.loss_cls: 0.0008  decode.loss_mask: 0.6341  decode.loss_dice: 0.3953  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 0.5203  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.6578  decode.d1.loss_dice: 0.4170  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.6766  decode.d2.loss_dice: 0.4307  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.6201  decode.d3.loss_dice: 0.3814  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.6493  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6534  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.6408  decode.d6.loss_dice: 0.3937  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.6323  decode.d7.loss_dice: 0.4047  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6357  decode.d8.loss_dice: 0.3902\n",
      "07/02 17:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9600/32000]  base_lr: 4.5340e-06 lr: 4.5340e-07  eta: 0:59:04  time: 0.1598  data_time: 0.0102  memory: 5153  grad_norm: 231.9950  loss: 15.0305  decode.loss_cls: 0.0028  decode.loss_mask: 0.8437  decode.loss_dice: 0.6015  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.9947  decode.d0.loss_dice: 0.7587  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.8797  decode.d1.loss_dice: 0.6431  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.8087  decode.d2.loss_dice: 0.6171  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.8144  decode.d3.loss_dice: 0.6293  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.8186  decode.d4.loss_dice: 0.6149  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.8517  decode.d5.loss_dice: 0.6307  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.8509  decode.d6.loss_dice: 0.6209  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.8463  decode.d7.loss_dice: 0.6378  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.8325  decode.d8.loss_dice: 0.6057\n",
      "07/02 17:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9650/32000]  base_lr: 4.5249e-06 lr: 4.5249e-07  eta: 0:58:56  time: 0.1573  data_time: 0.0089  memory: 5153  grad_norm: 228.8862  loss: 14.8039  decode.loss_cls: 0.0006  decode.loss_mask: 0.8763  decode.loss_dice: 0.5830  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 1.0927  decode.d0.loss_dice: 0.7337  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.8940  decode.d1.loss_dice: 0.6101  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.8435  decode.d2.loss_dice: 0.5620  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.8277  decode.d3.loss_dice: 0.5622  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.8610  decode.d4.loss_dice: 0.5648  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.8534  decode.d5.loss_dice: 0.5572  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.8483  decode.d6.loss_dice: 0.5870  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8397  decode.d7.loss_dice: 0.5709  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.5688\n",
      "07/02 17:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9700/32000]  base_lr: 4.5158e-06 lr: 4.5158e-07  eta: 0:58:48  time: 0.1543  data_time: 0.0090  memory: 5153  grad_norm: 320.7580  loss: 15.8365  decode.loss_cls: 0.0018  decode.loss_mask: 0.9299  decode.loss_dice: 0.6121  decode.d0.loss_cls: 0.2553  decode.d0.loss_mask: 1.0391  decode.d0.loss_dice: 0.7398  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.8585  decode.d1.loss_dice: 0.6095  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 0.6167  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.8939  decode.d3.loss_dice: 0.6081  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.9133  decode.d4.loss_dice: 0.5983  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.9530  decode.d5.loss_dice: 0.6229  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.8929  decode.d6.loss_dice: 0.6398  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.9205  decode.d7.loss_dice: 0.6359  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.9110  decode.d8.loss_dice: 0.6217\n",
      "07/02 17:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9750/32000]  base_lr: 4.5067e-06 lr: 4.5067e-07  eta: 0:58:39  time: 0.1532  data_time: 0.0085  memory: 5154  grad_norm: 228.3974  loss: 15.6525  decode.loss_cls: 0.0037  decode.loss_mask: 0.9537  decode.loss_dice: 0.5421  decode.d0.loss_cls: 0.1577  decode.d0.loss_mask: 1.1326  decode.d0.loss_dice: 0.6884  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.9931  decode.d1.loss_dice: 0.5715  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.9849  decode.d2.loss_dice: 0.5674  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.9493  decode.d3.loss_dice: 0.5607  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.9565  decode.d4.loss_dice: 0.5400  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.9542  decode.d5.loss_dice: 0.5502  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.9655  decode.d6.loss_dice: 0.5384  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.9579  decode.d7.loss_dice: 0.5412  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.9541  decode.d8.loss_dice: 0.5372\n",
      "07/02 17:27:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9800/32000]  base_lr: 4.4975e-06 lr: 4.4975e-07  eta: 0:58:31  time: 0.1576  data_time: 0.0092  memory: 5153  grad_norm: 228.6344  loss: 12.0424  decode.loss_cls: 0.0044  decode.loss_mask: 0.7025  decode.loss_dice: 0.4735  decode.d0.loss_cls: 0.0962  decode.d0.loss_mask: 0.8579  decode.d0.loss_dice: 0.6073  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.7290  decode.d1.loss_dice: 0.4686  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.7114  decode.d2.loss_dice: 0.4771  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.6542  decode.d3.loss_dice: 0.4455  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.6498  decode.d4.loss_dice: 0.4344  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.6829  decode.d5.loss_dice: 0.4635  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.7467  decode.d6.loss_dice: 0.4609  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.7167  decode.d7.loss_dice: 0.4566  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.7130  decode.d8.loss_dice: 0.4592\n",
      "07/02 17:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9850/32000]  base_lr: 4.4884e-06 lr: 4.4884e-07  eta: 0:58:23  time: 0.1590  data_time: 0.0099  memory: 5155  grad_norm: 224.1594  loss: 13.9392  decode.loss_cls: 0.0063  decode.loss_mask: 0.7825  decode.loss_dice: 0.5023  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 1.0704  decode.d0.loss_dice: 0.6563  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.8802  decode.d1.loss_dice: 0.5482  decode.d2.loss_cls: 0.0312  decode.d2.loss_mask: 0.8814  decode.d2.loss_dice: 0.5256  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.8341  decode.d3.loss_dice: 0.5194  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.8323  decode.d4.loss_dice: 0.5160  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.8079  decode.d5.loss_dice: 0.5205  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.7902  decode.d6.loss_dice: 0.5091  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.7842  decode.d7.loss_dice: 0.5020  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.7791  decode.d8.loss_dice: 0.4972\n",
      "07/02 17:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9900/32000]  base_lr: 4.4793e-06 lr: 4.4793e-07  eta: 0:58:16  time: 0.1582  data_time: 0.0093  memory: 5153  grad_norm: 223.2598  loss: 13.1666  decode.loss_cls: 0.0010  decode.loss_mask: 0.7411  decode.loss_dice: 0.4884  decode.d0.loss_cls: 0.1357  decode.d0.loss_mask: 0.9061  decode.d0.loss_dice: 0.6528  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.7889  decode.d1.loss_dice: 0.5381  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.8001  decode.d2.loss_dice: 0.5242  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.8243  decode.d3.loss_dice: 0.4973  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.7808  decode.d4.loss_dice: 0.5279  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7505  decode.d5.loss_dice: 0.5003  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7490  decode.d6.loss_dice: 0.5014  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7420  decode.d7.loss_dice: 0.4865  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7310  decode.d8.loss_dice: 0.4850\n",
      "07/02 17:28:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9950/32000]  base_lr: 4.4702e-06 lr: 4.4702e-07  eta: 0:58:08  time: 0.1590  data_time: 0.0098  memory: 5154  grad_norm: 161.1987  loss: 12.5125  decode.loss_cls: 0.0005  decode.loss_mask: 0.7757  decode.loss_dice: 0.4822  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.8994  decode.d0.loss_dice: 0.5853  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.7391  decode.d1.loss_dice: 0.4593  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7422  decode.d2.loss_dice: 0.4588  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7447  decode.d3.loss_dice: 0.4479  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 0.4591  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7466  decode.d5.loss_dice: 0.4693  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7446  decode.d6.loss_dice: 0.4687  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7416  decode.d7.loss_dice: 0.4570  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7851  decode.d8.loss_dice: 0.4738\n",
      "07/02 17:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10000/32000]  base_lr: 4.4611e-06 lr: 4.4611e-07  eta: 0:58:00  time: 0.1576  data_time: 0.0091  memory: 5154  grad_norm: 162.2432  loss: 11.3887  decode.loss_cls: 0.0004  decode.loss_mask: 0.6707  decode.loss_dice: 0.4516  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 0.5692  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.6487  decode.d1.loss_dice: 0.4929  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.6658  decode.d2.loss_dice: 0.4598  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.6480  decode.d3.loss_dice: 0.4494  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.6505  decode.d4.loss_dice: 0.4475  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.6387  decode.d5.loss_dice: 0.4573  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.6492  decode.d6.loss_dice: 0.4559  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.6376  decode.d7.loss_dice: 0.4386  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 0.4415\n",
      "07/02 17:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10000 iterations\n",
      "07/02 17:28:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0212  data_time: 0.0022  memory: 2167  \n",
      "07/02 17:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0291  data_time: 0.0062  memory: 1078  \n",
      "07/02 17:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 89.25 | 95.22 |\n",
      "|   lesion   |  69.5 | 79.62 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 91.3700  mIoU: 79.3700  mAcc: 87.4200  data_time: 0.0111  time: 0.0364\n",
      "07/02 17:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10050/32000]  base_lr: 4.4519e-06 lr: 4.4519e-07  eta: 0:57:52  time: 0.1658  data_time: 0.0091  memory: 5153  grad_norm: 239.6379  loss: 14.7501  decode.loss_cls: 0.0004  decode.loss_mask: 0.8940  decode.loss_dice: 0.5186  decode.d0.loss_cls: 0.0591  decode.d0.loss_mask: 1.0531  decode.d0.loss_dice: 0.6596  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.9360  decode.d1.loss_dice: 0.5444  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.9109  decode.d2.loss_dice: 0.5450  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.9086  decode.d3.loss_dice: 0.5418  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.9352  decode.d4.loss_dice: 0.5297  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.9094  decode.d5.loss_dice: 0.5274  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8957  decode.d6.loss_dice: 0.5183  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.9275  decode.d7.loss_dice: 0.5178  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.8880  decode.d8.loss_dice: 0.5213\n",
      "07/02 17:28:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10100/32000]  base_lr: 4.4428e-06 lr: 4.4428e-07  eta: 0:57:44  time: 0.1578  data_time: 0.0091  memory: 5154  grad_norm: 296.9302  loss: 16.2310  decode.loss_cls: 0.0802  decode.loss_mask: 0.9329  decode.loss_dice: 0.5608  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 1.1638  decode.d0.loss_dice: 0.7663  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.9255  decode.d1.loss_dice: 0.5831  decode.d2.loss_cls: 0.1599  decode.d2.loss_mask: 0.8837  decode.d2.loss_dice: 0.5535  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.9229  decode.d3.loss_dice: 0.5713  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.9051  decode.d4.loss_dice: 0.5770  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.9531  decode.d5.loss_dice: 0.6028  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.9227  decode.d6.loss_dice: 0.5536  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.9200  decode.d7.loss_dice: 0.5595  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.9302  decode.d8.loss_dice: 0.5628\n",
      "07/02 17:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10150/32000]  base_lr: 4.4337e-06 lr: 4.4337e-07  eta: 0:57:37  time: 0.1624  data_time: 0.0089  memory: 5153  grad_norm: 145.4393  loss: 9.6685  decode.loss_cls: 0.0007  decode.loss_mask: 0.5187  decode.loss_dice: 0.3765  decode.d0.loss_cls: 0.0571  decode.d0.loss_mask: 0.7518  decode.d0.loss_dice: 0.5585  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.5710  decode.d1.loss_dice: 0.4328  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.5238  decode.d2.loss_dice: 0.4124  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.5280  decode.d3.loss_dice: 0.4031  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.5105  decode.d4.loss_dice: 0.3968  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.5154  decode.d5.loss_dice: 0.3893  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.5150  decode.d6.loss_dice: 0.3708  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.5342  decode.d7.loss_dice: 0.3820  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.5249  decode.d8.loss_dice: 0.3732\n",
      "07/02 17:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10200/32000]  base_lr: 4.4245e-06 lr: 4.4245e-07  eta: 0:57:29  time: 0.1582  data_time: 0.0087  memory: 5153  grad_norm: 164.8540  loss: 13.1777  decode.loss_cls: 0.0011  decode.loss_mask: 0.7755  decode.loss_dice: 0.5139  decode.d0.loss_cls: 0.0437  decode.d0.loss_mask: 0.9676  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.8252  decode.d1.loss_dice: 0.4991  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.7505  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7944  decode.d3.loss_dice: 0.5021  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7804  decode.d4.loss_dice: 0.4937  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7663  decode.d5.loss_dice: 0.4768  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7795  decode.d6.loss_dice: 0.5036  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7766  decode.d7.loss_dice: 0.5013  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7599  decode.d8.loss_dice: 0.5016\n",
      "07/02 17:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10250/32000]  base_lr: 4.4154e-06 lr: 4.4154e-07  eta: 0:57:21  time: 0.1550  data_time: 0.0075  memory: 5153  grad_norm: 167.4693  loss: 12.2575  decode.loss_cls: 0.0019  decode.loss_mask: 0.7277  decode.loss_dice: 0.4450  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.8768  decode.d0.loss_dice: 0.5715  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.7635  decode.d1.loss_dice: 0.4979  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.7285  decode.d2.loss_dice: 0.4547  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.7427  decode.d3.loss_dice: 0.4710  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.7029  decode.d4.loss_dice: 0.4649  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.6989  decode.d5.loss_dice: 0.4298  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 0.4383  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.7355  decode.d7.loss_dice: 0.4453  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.7305  decode.d8.loss_dice: 0.4428\n",
      "07/02 17:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10300/32000]  base_lr: 4.4063e-06 lr: 4.4063e-07  eta: 0:57:13  time: 0.1607  data_time: 0.0091  memory: 5153  grad_norm: 193.5137  loss: 11.9230  decode.loss_cls: 0.0005  decode.loss_mask: 0.7197  decode.loss_dice: 0.4367  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.8829  decode.d0.loss_dice: 0.5947  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.7425  decode.d1.loss_dice: 0.4854  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.7186  decode.d2.loss_dice: 0.4452  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.7128  decode.d3.loss_dice: 0.4607  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7027  decode.d4.loss_dice: 0.4321  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6978  decode.d5.loss_dice: 0.4365  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6991  decode.d6.loss_dice: 0.4213  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6991  decode.d7.loss_dice: 0.4369  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7005  decode.d8.loss_dice: 0.4214\n",
      "07/02 17:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10350/32000]  base_lr: 4.3971e-06 lr: 4.3971e-07  eta: 0:57:05  time: 0.1596  data_time: 0.0089  memory: 5153  grad_norm: 206.3179  loss: 12.9242  decode.loss_cls: 0.0030  decode.loss_mask: 0.7919  decode.loss_dice: 0.4393  decode.d0.loss_cls: 0.0877  decode.d0.loss_mask: 0.9858  decode.d0.loss_dice: 0.5833  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.8112  decode.d1.loss_dice: 0.4890  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.8123  decode.d2.loss_dice: 0.4675  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.8033  decode.d3.loss_dice: 0.4813  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7815  decode.d4.loss_dice: 0.4368  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.7861  decode.d5.loss_dice: 0.4496  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.7918  decode.d6.loss_dice: 0.4542  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.7767  decode.d7.loss_dice: 0.4346  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.7864  decode.d8.loss_dice: 0.4330\n",
      "07/02 17:29:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10400/32000]  base_lr: 4.3880e-06 lr: 4.3880e-07  eta: 0:56:58  time: 0.1595  data_time: 0.0094  memory: 5153  grad_norm: 243.5521  loss: 13.9170  decode.loss_cls: 0.0139  decode.loss_mask: 0.8115  decode.loss_dice: 0.4639  decode.d0.loss_cls: 0.1504  decode.d0.loss_mask: 0.9803  decode.d0.loss_dice: 0.5906  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.8331  decode.d1.loss_dice: 0.4931  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.8720  decode.d2.loss_dice: 0.4951  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.8749  decode.d3.loss_dice: 0.4806  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.8731  decode.d4.loss_dice: 0.4772  decode.d5.loss_cls: 0.0361  decode.d5.loss_mask: 0.8651  decode.d5.loss_dice: 0.4982  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.8366  decode.d6.loss_dice: 0.4781  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.8188  decode.d7.loss_dice: 0.4664  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.8058  decode.d8.loss_dice: 0.4571\n",
      "07/02 17:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10450/32000]  base_lr: 4.3788e-06 lr: 4.3788e-07  eta: 0:56:50  time: 0.1580  data_time: 0.0084  memory: 5154  grad_norm: 183.2857  loss: 12.0668  decode.loss_cls: 0.0003  decode.loss_mask: 0.7112  decode.loss_dice: 0.4443  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.8818  decode.d0.loss_dice: 0.5405  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.7507  decode.d1.loss_dice: 0.4581  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.7335  decode.d2.loss_dice: 0.4696  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.7129  decode.d3.loss_dice: 0.4561  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.7430  decode.d4.loss_dice: 0.4527  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.7507  decode.d5.loss_dice: 0.4264  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7326  decode.d6.loss_dice: 0.4330  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7144  decode.d7.loss_dice: 0.4244  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 0.4249\n",
      "07/02 17:29:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10500/32000]  base_lr: 4.3697e-06 lr: 4.3697e-07  eta: 0:56:42  time: 0.1640  data_time: 0.0092  memory: 5153  grad_norm: 179.0470  loss: 13.4331  decode.loss_cls: 0.0004  decode.loss_mask: 0.8071  decode.loss_dice: 0.4971  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.9731  decode.d0.loss_dice: 0.6211  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.8105  decode.d1.loss_dice: 0.5241  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7790  decode.d2.loss_dice: 0.5152  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.7823  decode.d3.loss_dice: 0.5149  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.7843  decode.d4.loss_dice: 0.4951  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.8313  decode.d5.loss_dice: 0.5068  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.8139  decode.d6.loss_dice: 0.4906  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 0.5063  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7903  decode.d8.loss_dice: 0.5016\n",
      "07/02 17:29:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10550/32000]  base_lr: 4.3606e-06 lr: 4.3606e-07  eta: 0:56:34  time: 0.1576  data_time: 0.0088  memory: 5154  grad_norm: 201.1752  loss: 12.6003  decode.loss_cls: 0.0123  decode.loss_mask: 0.6875  decode.loss_dice: 0.4207  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.8995  decode.d0.loss_dice: 0.5999  decode.d1.loss_cls: 0.3068  decode.d1.loss_mask: 0.7116  decode.d1.loss_dice: 0.4451  decode.d2.loss_cls: 0.3290  decode.d2.loss_mask: 0.6946  decode.d2.loss_dice: 0.4292  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.6769  decode.d3.loss_dice: 0.4241  decode.d4.loss_cls: 0.1478  decode.d4.loss_mask: 0.6894  decode.d4.loss_dice: 0.4173  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.7003  decode.d5.loss_dice: 0.4338  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.6925  decode.d6.loss_dice: 0.4086  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.7003  decode.d7.loss_dice: 0.4104  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.6942  decode.d8.loss_dice: 0.4166\n",
      "07/02 17:30:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10600/32000]  base_lr: 4.3514e-06 lr: 4.3514e-07  eta: 0:56:26  time: 0.1598  data_time: 0.0093  memory: 5153  grad_norm: 159.9001  loss: 12.7969  decode.loss_cls: 0.0014  decode.loss_mask: 0.7345  decode.loss_dice: 0.5067  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.9011  decode.d0.loss_dice: 0.6201  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.7507  decode.d1.loss_dice: 0.5238  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.7405  decode.d2.loss_dice: 0.5356  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.7417  decode.d3.loss_dice: 0.5116  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7226  decode.d4.loss_dice: 0.4987  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7375  decode.d5.loss_dice: 0.5074  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7216  decode.d6.loss_dice: 0.4966  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7229  decode.d7.loss_dice: 0.5013  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.7258  decode.d8.loss_dice: 0.5137\n",
      "07/02 17:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10650/32000]  base_lr: 4.3423e-06 lr: 4.3423e-07  eta: 0:56:18  time: 0.1601  data_time: 0.0091  memory: 5152  grad_norm: 226.4966  loss: 15.2224  decode.loss_cls: 0.2724  decode.loss_mask: 0.7773  decode.loss_dice: 0.4548  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 1.0175  decode.d0.loss_dice: 0.6205  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.9208  decode.d1.loss_dice: 0.5363  decode.d2.loss_cls: 0.2451  decode.d2.loss_mask: 0.8182  decode.d2.loss_dice: 0.4849  decode.d3.loss_cls: 0.2180  decode.d3.loss_mask: 0.8268  decode.d3.loss_dice: 0.4756  decode.d4.loss_cls: 0.1782  decode.d4.loss_mask: 0.8099  decode.d4.loss_dice: 0.4567  decode.d5.loss_cls: 0.1608  decode.d5.loss_mask: 0.8058  decode.d5.loss_dice: 0.4703  decode.d6.loss_cls: 0.1943  decode.d6.loss_mask: 0.8237  decode.d6.loss_dice: 0.4552  decode.d7.loss_cls: 0.2968  decode.d7.loss_mask: 0.7871  decode.d7.loss_dice: 0.4384  decode.d8.loss_cls: 0.2753  decode.d8.loss_mask: 0.7777  decode.d8.loss_dice: 0.4449\n",
      "07/02 17:30:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10700/32000]  base_lr: 4.3331e-06 lr: 4.3331e-07  eta: 0:56:11  time: 0.1601  data_time: 0.0088  memory: 5153  grad_norm: 182.4062  loss: 12.7044  decode.loss_cls: 0.0006  decode.loss_mask: 0.7603  decode.loss_dice: 0.4672  decode.d0.loss_cls: 0.1097  decode.d0.loss_mask: 0.9090  decode.d0.loss_dice: 0.5835  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.8105  decode.d1.loss_dice: 0.5322  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.7753  decode.d2.loss_dice: 0.4727  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 0.4754  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.7513  decode.d4.loss_dice: 0.4606  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.7464  decode.d5.loss_dice: 0.4478  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.7383  decode.d6.loss_dice: 0.4620  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7518  decode.d7.loss_dice: 0.4580  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7493  decode.d8.loss_dice: 0.4586\n",
      "07/02 17:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10750/32000]  base_lr: 4.3239e-06 lr: 4.3239e-07  eta: 0:56:03  time: 0.1576  data_time: 0.0087  memory: 5153  grad_norm: 176.4700  loss: 11.8700  decode.loss_cls: 0.0002  decode.loss_mask: 0.7341  decode.loss_dice: 0.4171  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.9527  decode.d0.loss_dice: 0.5444  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.7397  decode.d1.loss_dice: 0.4425  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.7638  decode.d2.loss_dice: 0.4408  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.7363  decode.d3.loss_dice: 0.4305  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.7118  decode.d4.loss_dice: 0.4001  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.7015  decode.d5.loss_dice: 0.4113  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.7075  decode.d6.loss_dice: 0.4175  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.6961  decode.d7.loss_dice: 0.4126  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.7088  decode.d8.loss_dice: 0.4298\n",
      "07/02 17:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10800/32000]  base_lr: 4.3148e-06 lr: 4.3148e-07  eta: 0:55:55  time: 0.1558  data_time: 0.0084  memory: 5152  grad_norm: 198.3423  loss: 12.6223  decode.loss_cls: 0.0050  decode.loss_mask: 0.7127  decode.loss_dice: 0.4556  decode.d0.loss_cls: 0.0718  decode.d0.loss_mask: 0.9979  decode.d0.loss_dice: 0.6635  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.7803  decode.d1.loss_dice: 0.5179  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.7582  decode.d2.loss_dice: 0.5012  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.7559  decode.d3.loss_dice: 0.4837  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7413  decode.d4.loss_dice: 0.4531  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.7256  decode.d5.loss_dice: 0.4558  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7161  decode.d6.loss_dice: 0.4535  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 0.4735  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.7017  decode.d8.loss_dice: 0.4632\n",
      "07/02 17:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10850/32000]  base_lr: 4.3056e-06 lr: 4.3056e-07  eta: 0:55:47  time: 0.1583  data_time: 0.0088  memory: 5153  grad_norm: 143.5967  loss: 10.1065  decode.loss_cls: 0.0007  decode.loss_mask: 0.6100  decode.loss_dice: 0.3603  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.7173  decode.d0.loss_dice: 0.4658  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.6374  decode.d1.loss_dice: 0.3962  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.6114  decode.d2.loss_dice: 0.3825  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.6281  decode.d3.loss_dice: 0.3599  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.6281  decode.d4.loss_dice: 0.3519  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6282  decode.d5.loss_dice: 0.3534  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.5980  decode.d6.loss_dice: 0.3530  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6359  decode.d7.loss_dice: 0.3569  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.6164  decode.d8.loss_dice: 0.3709\n",
      "07/02 17:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10900/32000]  base_lr: 4.2965e-06 lr: 4.2965e-07  eta: 0:55:39  time: 0.1586  data_time: 0.0091  memory: 5153  grad_norm: 245.6314  loss: 15.2256  decode.loss_cls: 0.1318  decode.loss_mask: 0.8363  decode.loss_dice: 0.5409  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 1.1156  decode.d0.loss_dice: 0.7004  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.8735  decode.d1.loss_dice: 0.5961  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.8803  decode.d2.loss_dice: 0.5967  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.8747  decode.d3.loss_dice: 0.5720  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.8645  decode.d4.loss_dice: 0.5563  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.8867  decode.d5.loss_dice: 0.5513  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.9209  decode.d6.loss_dice: 0.5418  decode.d7.loss_cls: 0.1281  decode.d7.loss_mask: 0.8304  decode.d7.loss_dice: 0.5500  decode.d8.loss_cls: 0.1338  decode.d8.loss_mask: 0.8493  decode.d8.loss_dice: 0.5604\n",
      "07/02 17:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10950/32000]  base_lr: 4.2873e-06 lr: 4.2873e-07  eta: 0:55:31  time: 0.1594  data_time: 0.0093  memory: 5153  grad_norm: 197.0913  loss: 12.9299  decode.loss_cls: 0.0006  decode.loss_mask: 0.7893  decode.loss_dice: 0.4316  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.9424  decode.d0.loss_dice: 0.5550  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.8026  decode.d1.loss_dice: 0.4707  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.8353  decode.d2.loss_dice: 0.4675  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.8345  decode.d3.loss_dice: 0.4478  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 0.4588  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.8092  decode.d5.loss_dice: 0.4484  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8288  decode.d6.loss_dice: 0.4514  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7888  decode.d7.loss_dice: 0.4425  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7757  decode.d8.loss_dice: 0.4338\n",
      "07/02 17:31:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:31:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11000/32000]  base_lr: 4.2781e-06 lr: 4.2781e-07  eta: 0:55:23  time: 0.1581  data_time: 0.0090  memory: 5153  grad_norm: 159.1192  loss: 13.2869  decode.loss_cls: 0.0004  decode.loss_mask: 0.8084  decode.loss_dice: 0.4926  decode.d0.loss_cls: 0.0539  decode.d0.loss_mask: 1.0520  decode.d0.loss_dice: 0.6219  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.8078  decode.d1.loss_dice: 0.4658  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.8009  decode.d2.loss_dice: 0.4794  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.8032  decode.d3.loss_dice: 0.4810  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8095  decode.d4.loss_dice: 0.4989  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.8007  decode.d5.loss_dice: 0.4889  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7902  decode.d6.loss_dice: 0.4755  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.8060  decode.d7.loss_dice: 0.4721  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7914  decode.d8.loss_dice: 0.4765\n",
      "07/02 17:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0220  data_time: 0.0023  memory: 2163  \n",
      "07/02 17:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0289  data_time: 0.0062  memory: 1077  \n",
      "07/02 17:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 88.34 | 93.62 |\n",
      "|   lesion   | 68.49 | 81.81 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 90.7000  mIoU: 78.4100  mAcc: 87.7100  data_time: 0.0115  time: 0.0369\n",
      "07/02 17:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11050/32000]  base_lr: 4.2690e-06 lr: 4.2690e-07  eta: 0:55:15  time: 0.1588  data_time: 0.0082  memory: 5153  grad_norm: 242.6105  loss: 13.8250  decode.loss_cls: 0.0041  decode.loss_mask: 0.8318  decode.loss_dice: 0.5191  decode.d0.loss_cls: 0.1130  decode.d0.loss_mask: 0.9433  decode.d0.loss_dice: 0.6523  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.8650  decode.d1.loss_dice: 0.5781  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.7741  decode.d2.loss_dice: 0.5215  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.7983  decode.d3.loss_dice: 0.5395  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.8036  decode.d4.loss_dice: 0.5300  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 0.5411  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.8031  decode.d6.loss_dice: 0.4904  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.8009  decode.d7.loss_dice: 0.4863  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.8263  decode.d8.loss_dice: 0.5042\n",
      "07/02 17:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11100/32000]  base_lr: 4.2598e-06 lr: 4.2598e-07  eta: 0:55:08  time: 0.1587  data_time: 0.0093  memory: 5153  grad_norm: 244.0500  loss: 12.6462  decode.loss_cls: 0.0001  decode.loss_mask: 0.7888  decode.loss_dice: 0.4603  decode.d0.loss_cls: 0.0685  decode.d0.loss_mask: 0.9215  decode.d0.loss_dice: 0.5504  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7826  decode.d1.loss_dice: 0.4693  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.7658  decode.d2.loss_dice: 0.4692  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7598  decode.d3.loss_dice: 0.4729  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.7753  decode.d4.loss_dice: 0.4509  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.4596  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7769  decode.d6.loss_dice: 0.4775  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7463  decode.d7.loss_dice: 0.4537  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.7693  decode.d8.loss_dice: 0.4549\n",
      "07/02 17:31:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11150/32000]  base_lr: 4.2506e-06 lr: 4.2506e-07  eta: 0:55:00  time: 0.1558  data_time: 0.0088  memory: 5154  grad_norm: 181.6611  loss: 11.4824  decode.loss_cls: 0.0007  decode.loss_mask: 0.6931  decode.loss_dice: 0.4292  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.8264  decode.d0.loss_dice: 0.5589  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.7028  decode.d1.loss_dice: 0.4229  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.6877  decode.d2.loss_dice: 0.4084  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6903  decode.d3.loss_dice: 0.4193  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7076  decode.d4.loss_dice: 0.4284  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6962  decode.d5.loss_dice: 0.4238  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.6788  decode.d6.loss_dice: 0.4175  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6721  decode.d7.loss_dice: 0.4249  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7045  decode.d8.loss_dice: 0.4186\n",
      "07/02 17:31:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11200/32000]  base_lr: 4.2414e-06 lr: 4.2414e-07  eta: 0:54:52  time: 0.1628  data_time: 0.0095  memory: 5154  grad_norm: 198.2321  loss: 15.7407  decode.loss_cls: 0.0022  decode.loss_mask: 0.9541  decode.loss_dice: 0.6170  decode.d0.loss_cls: 0.0467  decode.d0.loss_mask: 1.2220  decode.d0.loss_dice: 0.7579  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.9423  decode.d1.loss_dice: 0.6117  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.9539  decode.d2.loss_dice: 0.5965  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.9132  decode.d3.loss_dice: 0.6072  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.9111  decode.d4.loss_dice: 0.5932  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.9106  decode.d5.loss_dice: 0.5907  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.9099  decode.d6.loss_dice: 0.5830  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8999  decode.d7.loss_dice: 0.5791  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.9269  decode.d8.loss_dice: 0.5995\n",
      "07/02 17:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11250/32000]  base_lr: 4.2323e-06 lr: 4.2323e-07  eta: 0:54:45  time: 0.1571  data_time: 0.0095  memory: 5155  grad_norm: 177.0280  loss: 14.8076  decode.loss_cls: 0.0003  decode.loss_mask: 0.9122  decode.loss_dice: 0.5116  decode.d0.loss_cls: 0.0451  decode.d0.loss_mask: 1.1450  decode.d0.loss_dice: 0.6560  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.9278  decode.d1.loss_dice: 0.5453  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.9500  decode.d2.loss_dice: 0.5314  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.9141  decode.d3.loss_dice: 0.5315  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.9211  decode.d4.loss_dice: 0.5244  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8991  decode.d5.loss_dice: 0.5107  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.9088  decode.d6.loss_dice: 0.5142  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.9228  decode.d7.loss_dice: 0.5062  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.9195  decode.d8.loss_dice: 0.5055\n",
      "07/02 17:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11300/32000]  base_lr: 4.2231e-06 lr: 4.2231e-07  eta: 0:54:37  time: 0.1632  data_time: 0.0098  memory: 5155  grad_norm: 203.7877  loss: 13.9113  decode.loss_cls: 0.0051  decode.loss_mask: 0.7947  decode.loss_dice: 0.5571  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.9934  decode.d0.loss_dice: 0.7087  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.7824  decode.d1.loss_dice: 0.5752  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.7947  decode.d2.loss_dice: 0.5846  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.7615  decode.d3.loss_dice: 0.5571  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.7697  decode.d4.loss_dice: 0.5343  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.7469  decode.d5.loss_dice: 0.5412  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.8023  decode.d6.loss_dice: 0.5302  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.8083  decode.d7.loss_dice: 0.5576  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.8043  decode.d8.loss_dice: 0.5424\n",
      "07/02 17:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11350/32000]  base_lr: 4.2139e-06 lr: 4.2139e-07  eta: 0:54:30  time: 0.1628  data_time: 0.0096  memory: 5153  grad_norm: 140.6627  loss: 11.7444  decode.loss_cls: 0.0004  decode.loss_mask: 0.6554  decode.loss_dice: 0.4624  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.9017  decode.d0.loss_dice: 0.5810  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 0.4718  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.6934  decode.d2.loss_dice: 0.4504  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.6727  decode.d3.loss_dice: 0.4551  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6961  decode.d4.loss_dice: 0.4562  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.6808  decode.d5.loss_dice: 0.4360  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6737  decode.d6.loss_dice: 0.4401  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6829  decode.d7.loss_dice: 0.4505  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6583  decode.d8.loss_dice: 0.4431\n",
      "07/02 17:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11400/32000]  base_lr: 4.2047e-06 lr: 4.2047e-07  eta: 0:54:22  time: 0.1643  data_time: 0.0095  memory: 5153  grad_norm: 181.5187  loss: 13.0228  decode.loss_cls: 0.0020  decode.loss_mask: 0.7734  decode.loss_dice: 0.4784  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.9986  decode.d0.loss_dice: 0.6309  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.8047  decode.d1.loss_dice: 0.5611  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7502  decode.d2.loss_dice: 0.5202  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7660  decode.d3.loss_dice: 0.5310  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7469  decode.d4.loss_dice: 0.4930  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.7221  decode.d5.loss_dice: 0.4837  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7413  decode.d6.loss_dice: 0.4739  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.7449  decode.d7.loss_dice: 0.4928  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.7525  decode.d8.loss_dice: 0.4730\n",
      "07/02 17:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11450/32000]  base_lr: 4.1955e-06 lr: 4.1955e-07  eta: 0:54:15  time: 0.1623  data_time: 0.0095  memory: 5153  grad_norm: 188.3898  loss: 13.2511  decode.loss_cls: 0.0006  decode.loss_mask: 0.7705  decode.loss_dice: 0.4647  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.9898  decode.d0.loss_dice: 0.6415  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.8129  decode.d1.loss_dice: 0.5043  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.8167  decode.d2.loss_dice: 0.4710  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.8152  decode.d3.loss_dice: 0.4814  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8089  decode.d4.loss_dice: 0.4760  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8154  decode.d5.loss_dice: 0.5001  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7933  decode.d6.loss_dice: 0.4766  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7945  decode.d7.loss_dice: 0.4786  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 0.4633\n",
      "07/02 17:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11500/32000]  base_lr: 4.1864e-06 lr: 4.1864e-07  eta: 0:54:07  time: 0.1555  data_time: 0.0074  memory: 5153  grad_norm: 187.7230  loss: 11.4310  decode.loss_cls: 0.0010  decode.loss_mask: 0.6833  decode.loss_dice: 0.4176  decode.d0.loss_cls: 0.0544  decode.d0.loss_mask: 0.8741  decode.d0.loss_dice: 0.5127  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.7344  decode.d1.loss_dice: 0.4323  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.6875  decode.d2.loss_dice: 0.4281  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.7103  decode.d3.loss_dice: 0.4295  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7124  decode.d4.loss_dice: 0.4257  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.6678  decode.d5.loss_dice: 0.4129  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.6594  decode.d6.loss_dice: 0.3945  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.6764  decode.d7.loss_dice: 0.4120  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 0.4038\n",
      "07/02 17:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11550/32000]  base_lr: 4.1772e-06 lr: 4.1772e-07  eta: 0:53:59  time: 0.1584  data_time: 0.0093  memory: 5153  grad_norm: 206.6778  loss: 13.5147  decode.loss_cls: 0.0007  decode.loss_mask: 0.7918  decode.loss_dice: 0.4874  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.9950  decode.d0.loss_dice: 0.6446  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.8271  decode.d1.loss_dice: 0.4939  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.8530  decode.d2.loss_dice: 0.4977  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.8331  decode.d3.loss_dice: 0.4982  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.8045  decode.d4.loss_dice: 0.4895  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.8142  decode.d5.loss_dice: 0.4881  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.8106  decode.d6.loss_dice: 0.4918  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.8186  decode.d7.loss_dice: 0.4745  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.8113  decode.d8.loss_dice: 0.4723\n",
      "07/02 17:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11600/32000]  base_lr: 4.1680e-06 lr: 4.1680e-07  eta: 0:53:51  time: 0.1633  data_time: 0.0096  memory: 5153  grad_norm: 149.8983  loss: 11.8666  decode.loss_cls: 0.0003  decode.loss_mask: 0.6993  decode.loss_dice: 0.4181  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.8620  decode.d0.loss_dice: 0.5837  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7553  decode.d1.loss_dice: 0.4697  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.7318  decode.d2.loss_dice: 0.4537  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7013  decode.d3.loss_dice: 0.4396  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7035  decode.d4.loss_dice: 0.4392  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6944  decode.d5.loss_dice: 0.4261  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 0.4449  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 0.4318  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7101  decode.d8.loss_dice: 0.4292\n",
      "07/02 17:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11650/32000]  base_lr: 4.1588e-06 lr: 4.1588e-07  eta: 0:53:44  time: 0.1656  data_time: 0.0096  memory: 5154  grad_norm: 228.1716  loss: 13.5617  decode.loss_cls: 0.0006  decode.loss_mask: 0.8146  decode.loss_dice: 0.5071  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.9926  decode.d0.loss_dice: 0.6423  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.8546  decode.d1.loss_dice: 0.5300  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.7870  decode.d2.loss_dice: 0.4785  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.8092  decode.d3.loss_dice: 0.4871  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.8324  decode.d4.loss_dice: 0.4858  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.8484  decode.d5.loss_dice: 0.4962  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.8005  decode.d6.loss_dice: 0.4884  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.8047  decode.d7.loss_dice: 0.4924  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.8020  decode.d8.loss_dice: 0.4915\n",
      "07/02 17:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11700/32000]  base_lr: 4.1496e-06 lr: 4.1496e-07  eta: 0:53:37  time: 0.1671  data_time: 0.0097  memory: 5153  grad_norm: 174.8863  loss: 12.0225  decode.loss_cls: 0.0003  decode.loss_mask: 0.6804  decode.loss_dice: 0.4415  decode.d0.loss_cls: 0.0501  decode.d0.loss_mask: 0.9810  decode.d0.loss_dice: 0.6438  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 0.4923  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7008  decode.d2.loss_dice: 0.4466  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.6945  decode.d3.loss_dice: 0.4540  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.6986  decode.d4.loss_dice: 0.4489  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6864  decode.d5.loss_dice: 0.4437  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7104  decode.d6.loss_dice: 0.4499  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6962  decode.d7.loss_dice: 0.4449  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6899  decode.d8.loss_dice: 0.4359\n",
      "07/02 17:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11750/32000]  base_lr: 4.1404e-06 lr: 4.1404e-07  eta: 0:53:29  time: 0.1583  data_time: 0.0088  memory: 5153  grad_norm: 128.7834  loss: 12.3205  decode.loss_cls: 0.0003  decode.loss_mask: 0.7494  decode.loss_dice: 0.4366  decode.d0.loss_cls: 0.0441  decode.d0.loss_mask: 0.9312  decode.d0.loss_dice: 0.5728  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.7581  decode.d1.loss_dice: 0.4594  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.7678  decode.d2.loss_dice: 0.4412  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.7563  decode.d3.loss_dice: 0.4334  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 0.4411  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.7622  decode.d5.loss_dice: 0.4426  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7359  decode.d6.loss_dice: 0.4262  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7460  decode.d7.loss_dice: 0.4353  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.7495  decode.d8.loss_dice: 0.4249\n",
      "07/02 17:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11800/32000]  base_lr: 4.1312e-06 lr: 4.1312e-07  eta: 0:53:21  time: 0.1627  data_time: 0.0101  memory: 5154  grad_norm: 240.1626  loss: 15.5611  decode.loss_cls: 0.0193  decode.loss_mask: 0.8831  decode.loss_dice: 0.5512  decode.d0.loss_cls: 0.0872  decode.d0.loss_mask: 1.0393  decode.d0.loss_dice: 0.7028  decode.d1.loss_cls: 0.1955  decode.d1.loss_mask: 0.8787  decode.d1.loss_dice: 0.5545  decode.d2.loss_cls: 0.2062  decode.d2.loss_mask: 0.9076  decode.d2.loss_dice: 0.5796  decode.d3.loss_cls: 0.1313  decode.d3.loss_mask: 0.8723  decode.d3.loss_dice: 0.5709  decode.d4.loss_cls: 0.1334  decode.d4.loss_mask: 0.8839  decode.d4.loss_dice: 0.5405  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.8773  decode.d5.loss_dice: 0.5140  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.8505  decode.d6.loss_dice: 0.4727  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.8500  decode.d7.loss_dice: 0.5095  decode.d8.loss_cls: 0.1411  decode.d8.loss_mask: 0.8757  decode.d8.loss_dice: 0.5388\n",
      "07/02 17:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11850/32000]  base_lr: 4.1220e-06 lr: 4.1220e-07  eta: 0:53:14  time: 0.1603  data_time: 0.0095  memory: 5153  grad_norm: 199.3421  loss: 12.4957  decode.loss_cls: 0.0029  decode.loss_mask: 0.6732  decode.loss_dice: 0.5088  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.8589  decode.d0.loss_dice: 0.6472  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.7467  decode.d1.loss_dice: 0.5679  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.7112  decode.d2.loss_dice: 0.5303  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.6893  decode.d3.loss_dice: 0.5242  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6913  decode.d4.loss_dice: 0.5090  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.6904  decode.d5.loss_dice: 0.5025  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.6711  decode.d6.loss_dice: 0.5086  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.6810  decode.d7.loss_dice: 0.4929  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.6800  decode.d8.loss_dice: 0.5120\n",
      "07/02 17:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11900/32000]  base_lr: 4.1128e-06 lr: 4.1128e-07  eta: 0:53:06  time: 0.1627  data_time: 0.0097  memory: 5153  grad_norm: 215.0800  loss: 12.7222  decode.loss_cls: 0.0009  decode.loss_mask: 0.7610  decode.loss_dice: 0.4812  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 0.9458  decode.d0.loss_dice: 0.6197  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.7844  decode.d1.loss_dice: 0.4889  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.7562  decode.d2.loss_dice: 0.4631  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.7588  decode.d3.loss_dice: 0.4769  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7338  decode.d4.loss_dice: 0.4699  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.7485  decode.d5.loss_dice: 0.4772  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.7541  decode.d6.loss_dice: 0.4660  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7701  decode.d7.loss_dice: 0.4715  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.7587  decode.d8.loss_dice: 0.4728\n",
      "07/02 17:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11950/32000]  base_lr: 4.1036e-06 lr: 4.1036e-07  eta: 0:52:58  time: 0.1602  data_time: 0.0100  memory: 5154  grad_norm: 155.5844  loss: 10.4564  decode.loss_cls: 0.0001  decode.loss_mask: 0.6129  decode.loss_dice: 0.3832  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.7848  decode.d0.loss_dice: 0.5331  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.6511  decode.d1.loss_dice: 0.4169  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.6364  decode.d2.loss_dice: 0.4152  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6093  decode.d3.loss_dice: 0.4013  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6091  decode.d4.loss_dice: 0.3960  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.5894  decode.d5.loss_dice: 0.3861  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6154  decode.d6.loss_dice: 0.3930  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.6036  decode.d7.loss_dice: 0.3850  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6208  decode.d8.loss_dice: 0.3870\n",
      "07/02 17:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12000/32000]  base_lr: 4.0943e-06 lr: 4.0943e-07  eta: 0:52:51  time: 0.1591  data_time: 0.0087  memory: 5152  grad_norm: 187.2424  loss: 11.8341  decode.loss_cls: 0.0027  decode.loss_mask: 0.7316  decode.loss_dice: 0.4027  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.8941  decode.d0.loss_dice: 0.5215  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.7210  decode.d1.loss_dice: 0.4362  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7607  decode.d2.loss_dice: 0.4224  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7545  decode.d3.loss_dice: 0.4276  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.7226  decode.d4.loss_dice: 0.4104  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.7324  decode.d5.loss_dice: 0.4147  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7308  decode.d6.loss_dice: 0.4098  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.7267  decode.d7.loss_dice: 0.4062  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.7109  decode.d8.loss_dice: 0.4018\n",
      "07/02 17:33:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0213  data_time: 0.0021  memory: 2166  \n",
      "07/02 17:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0286  data_time: 0.0061  memory: 1078  \n",
      "07/02 17:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 88.72 | 94.55 |\n",
      "|   lesion   | 68.58 | 79.97 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 90.9500  mIoU: 78.6500  mAcc: 87.2600  data_time: 0.0115  time: 0.0367\n",
      "07/02 17:34:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12050/32000]  base_lr: 4.0851e-06 lr: 4.0851e-07  eta: 0:52:43  time: 0.1643  data_time: 0.0102  memory: 5153  grad_norm: 160.4033  loss: 12.2921  decode.loss_cls: 0.0005  decode.loss_mask: 0.7090  decode.loss_dice: 0.4371  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.9570  decode.d0.loss_dice: 0.6280  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.7795  decode.d1.loss_dice: 0.4538  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.7286  decode.d2.loss_dice: 0.4540  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.7327  decode.d3.loss_dice: 0.4669  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.7316  decode.d4.loss_dice: 0.4618  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.7161  decode.d5.loss_dice: 0.4455  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.7172  decode.d6.loss_dice: 0.4546  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7179  decode.d7.loss_dice: 0.4487  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7292  decode.d8.loss_dice: 0.4541\n",
      "07/02 17:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12100/32000]  base_lr: 4.0759e-06 lr: 4.0759e-07  eta: 0:52:35  time: 0.1577  data_time: 0.0089  memory: 5153  grad_norm: 217.0300  loss: 13.3917  decode.loss_cls: 0.0007  decode.loss_mask: 0.7980  decode.loss_dice: 0.5510  decode.d0.loss_cls: 0.0451  decode.d0.loss_mask: 0.9596  decode.d0.loss_dice: 0.6351  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 0.5492  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7829  decode.d2.loss_dice: 0.5346  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7825  decode.d3.loss_dice: 0.5077  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.7476  decode.d4.loss_dice: 0.4934  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7483  decode.d5.loss_dice: 0.4885  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7471  decode.d6.loss_dice: 0.5121  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7928  decode.d7.loss_dice: 0.5302  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7935  decode.d8.loss_dice: 0.5507\n",
      "07/02 17:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12150/32000]  base_lr: 4.0667e-06 lr: 4.0667e-07  eta: 0:52:27  time: 0.1605  data_time: 0.0103  memory: 5153  grad_norm: 229.0716  loss: 13.6438  decode.loss_cls: 0.0009  decode.loss_mask: 0.8545  decode.loss_dice: 0.4895  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 1.0397  decode.d0.loss_dice: 0.5753  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.8514  decode.d1.loss_dice: 0.5152  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.8543  decode.d2.loss_dice: 0.5185  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.8189  decode.d3.loss_dice: 0.4785  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.8145  decode.d4.loss_dice: 0.4586  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8296  decode.d5.loss_dice: 0.4873  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.8357  decode.d6.loss_dice: 0.4984  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.8520  decode.d7.loss_dice: 0.4940  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 0.4940\n",
      "07/02 17:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12200/32000]  base_lr: 4.0575e-06 lr: 4.0575e-07  eta: 0:52:19  time: 0.1595  data_time: 0.0101  memory: 5153  grad_norm: 223.4759  loss: 11.4115  decode.loss_cls: 0.0008  decode.loss_mask: 0.6458  decode.loss_dice: 0.4337  decode.d0.loss_cls: 0.1139  decode.d0.loss_mask: 0.8604  decode.d0.loss_dice: 0.5814  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.6700  decode.d1.loss_dice: 0.4674  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.6915  decode.d2.loss_dice: 0.4490  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.6714  decode.d3.loss_dice: 0.4322  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.6471  decode.d4.loss_dice: 0.4271  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.6399  decode.d5.loss_dice: 0.4156  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.6581  decode.d6.loss_dice: 0.4381  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6420  decode.d7.loss_dice: 0.4337  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.6453  decode.d8.loss_dice: 0.4351\n",
      "07/02 17:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12250/32000]  base_lr: 4.0483e-06 lr: 4.0483e-07  eta: 0:52:11  time: 0.1607  data_time: 0.0098  memory: 5153  grad_norm: 152.4224  loss: 12.7916  decode.loss_cls: 0.0039  decode.loss_mask: 0.6999  decode.loss_dice: 0.4828  decode.d0.loss_cls: 0.1181  decode.d0.loss_mask: 0.9638  decode.d0.loss_dice: 0.6990  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 0.5582  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.7386  decode.d2.loss_dice: 0.5239  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.7419  decode.d3.loss_dice: 0.5005  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.7172  decode.d4.loss_dice: 0.5064  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.6993  decode.d5.loss_dice: 0.4908  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.6958  decode.d6.loss_dice: 0.4766  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.7058  decode.d7.loss_dice: 0.4863  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.6972  decode.d8.loss_dice: 0.4820\n",
      "07/02 17:34:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12300/32000]  base_lr: 4.0390e-06 lr: 4.0390e-07  eta: 0:52:04  time: 0.1615  data_time: 0.0097  memory: 5154  grad_norm: 214.1711  loss: 13.7735  decode.loss_cls: 0.0004  decode.loss_mask: 0.7976  decode.loss_dice: 0.5238  decode.d0.loss_cls: 0.0817  decode.d0.loss_mask: 0.9933  decode.d0.loss_dice: 0.6470  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.8634  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.5549  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.8070  decode.d3.loss_dice: 0.5122  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.8276  decode.d4.loss_dice: 0.5146  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8090  decode.d5.loss_dice: 0.5124  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.8185  decode.d6.loss_dice: 0.4920  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7851  decode.d7.loss_dice: 0.5002  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7990  decode.d8.loss_dice: 0.5146\n",
      "07/02 17:34:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12350/32000]  base_lr: 4.0298e-06 lr: 4.0298e-07  eta: 0:51:56  time: 0.1587  data_time: 0.0097  memory: 5153  grad_norm: 175.8115  loss: 12.2137  decode.loss_cls: 0.0002  decode.loss_mask: 0.7414  decode.loss_dice: 0.4282  decode.d0.loss_cls: 0.0668  decode.d0.loss_mask: 0.9521  decode.d0.loss_dice: 0.6156  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.7878  decode.d1.loss_dice: 0.4586  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.7275  decode.d2.loss_dice: 0.4315  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.7406  decode.d3.loss_dice: 0.4283  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.7495  decode.d4.loss_dice: 0.4367  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7476  decode.d5.loss_dice: 0.4352  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7359  decode.d6.loss_dice: 0.4297  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7309  decode.d7.loss_dice: 0.4204  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7199  decode.d8.loss_dice: 0.4124\n",
      "07/02 17:35:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12400/32000]  base_lr: 4.0206e-06 lr: 4.0206e-07  eta: 0:51:48  time: 0.1602  data_time: 0.0099  memory: 5153  grad_norm: 242.6150  loss: 15.0392  decode.loss_cls: 0.0303  decode.loss_mask: 0.8683  decode.loss_dice: 0.5328  decode.d0.loss_cls: 0.1293  decode.d0.loss_mask: 1.0961  decode.d0.loss_dice: 0.6884  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.9630  decode.d1.loss_dice: 0.5985  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.9193  decode.d2.loss_dice: 0.5761  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.8726  decode.d3.loss_dice: 0.5332  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.8820  decode.d4.loss_dice: 0.5368  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.8738  decode.d5.loss_dice: 0.5238  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.8849  decode.d6.loss_dice: 0.5331  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.8983  decode.d7.loss_dice: 0.5199  decode.d8.loss_cls: 0.0273  decode.d8.loss_mask: 0.8698  decode.d8.loss_dice: 0.5166\n",
      "07/02 17:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12450/32000]  base_lr: 4.0113e-06 lr: 4.0113e-07  eta: 0:51:41  time: 0.1596  data_time: 0.0095  memory: 5154  grad_norm: 250.2123  loss: 13.1478  decode.loss_cls: 0.0022  decode.loss_mask: 0.7739  decode.loss_dice: 0.5087  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.9043  decode.d0.loss_dice: 0.5889  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.8092  decode.d1.loss_dice: 0.5211  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7841  decode.d2.loss_dice: 0.5089  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7973  decode.d3.loss_dice: 0.5020  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7985  decode.d4.loss_dice: 0.4814  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7954  decode.d5.loss_dice: 0.5027  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7771  decode.d6.loss_dice: 0.4827  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 0.5179  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7685  decode.d8.loss_dice: 0.4744\n",
      "07/02 17:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12500/32000]  base_lr: 4.0021e-06 lr: 4.0021e-07  eta: 0:51:33  time: 0.1592  data_time: 0.0098  memory: 5153  grad_norm: 152.8162  loss: 11.8211  decode.loss_cls: 0.0008  decode.loss_mask: 0.6777  decode.loss_dice: 0.4435  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.8300  decode.d0.loss_dice: 0.5462  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.7086  decode.d1.loss_dice: 0.4986  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.7426  decode.d2.loss_dice: 0.4845  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.6978  decode.d3.loss_dice: 0.4607  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.6739  decode.d4.loss_dice: 0.4602  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.6692  decode.d5.loss_dice: 0.4535  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.6867  decode.d6.loss_dice: 0.4540  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6872  decode.d7.loss_dice: 0.4479  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6817  decode.d8.loss_dice: 0.4433\n",
      "07/02 17:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12550/32000]  base_lr: 3.9929e-06 lr: 3.9929e-07  eta: 0:51:25  time: 0.1599  data_time: 0.0098  memory: 5154  grad_norm: 232.5080  loss: 15.9111  decode.loss_cls: 0.0043  decode.loss_mask: 0.9831  decode.loss_dice: 0.5670  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 1.1609  decode.d0.loss_dice: 0.7107  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 1.0027  decode.d1.loss_dice: 0.6046  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.9973  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.9715  decode.d3.loss_dice: 0.5693  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.9535  decode.d4.loss_dice: 0.5715  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.9344  decode.d5.loss_dice: 0.5652  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.9597  decode.d6.loss_dice: 0.5634  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.9615  decode.d7.loss_dice: 0.5688  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.9759  decode.d8.loss_dice: 0.5602\n",
      "07/02 17:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12600/32000]  base_lr: 3.9836e-06 lr: 3.9836e-07  eta: 0:51:18  time: 0.1610  data_time: 0.0094  memory: 5153  grad_norm: 224.9512  loss: 12.0529  decode.loss_cls: 0.0064  decode.loss_mask: 0.7383  decode.loss_dice: 0.4227  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.8757  decode.d0.loss_dice: 0.5353  decode.d1.loss_cls: 0.0190  decode.d1.loss_mask: 0.7196  decode.d1.loss_dice: 0.4372  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.7136  decode.d2.loss_dice: 0.4237  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.7106  decode.d3.loss_dice: 0.4262  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.7293  decode.d4.loss_dice: 0.4311  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.7244  decode.d5.loss_dice: 0.4216  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.7301  decode.d6.loss_dice: 0.4281  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.7399  decode.d7.loss_dice: 0.4177  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.7352  decode.d8.loss_dice: 0.4222\n",
      "07/02 17:35:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12650/32000]  base_lr: 3.9744e-06 lr: 3.9744e-07  eta: 0:51:10  time: 0.1615  data_time: 0.0099  memory: 5154  grad_norm: 119.5254  loss: 10.1039  decode.loss_cls: 0.0002  decode.loss_mask: 0.5834  decode.loss_dice: 0.3872  decode.d0.loss_cls: 0.0208  decode.d0.loss_mask: 0.7182  decode.d0.loss_dice: 0.4865  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.5954  decode.d1.loss_dice: 0.4112  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6136  decode.d2.loss_dice: 0.4128  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5697  decode.d3.loss_dice: 0.3885  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.5928  decode.d4.loss_dice: 0.4009  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5938  decode.d5.loss_dice: 0.4004  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 0.3922  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.5837  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5861  decode.d8.loss_dice: 0.3843\n",
      "07/02 17:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12700/32000]  base_lr: 3.9651e-06 lr: 3.9651e-07  eta: 0:51:02  time: 0.1624  data_time: 0.0097  memory: 5153  grad_norm: 248.3366  loss: 14.0865  decode.loss_cls: 0.0031  decode.loss_mask: 0.8350  decode.loss_dice: 0.5077  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.9717  decode.d0.loss_dice: 0.6428  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.8556  decode.d1.loss_dice: 0.5730  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.8743  decode.d2.loss_dice: 0.5632  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.8559  decode.d3.loss_dice: 0.5067  decode.d4.loss_cls: 0.0216  decode.d4.loss_mask: 0.8355  decode.d4.loss_dice: 0.4792  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.8290  decode.d5.loss_dice: 0.4894  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.8257  decode.d6.loss_dice: 0.4927  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.8286  decode.d7.loss_dice: 0.5046  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.8361  decode.d8.loss_dice: 0.4973\n",
      "07/02 17:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12750/32000]  base_lr: 3.9559e-06 lr: 3.9559e-07  eta: 0:50:55  time: 0.1609  data_time: 0.0097  memory: 5154  grad_norm: 171.9936  loss: 12.7754  decode.loss_cls: 0.0004  decode.loss_mask: 0.7368  decode.loss_dice: 0.4859  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.8643  decode.d0.loss_dice: 0.5767  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.7774  decode.d1.loss_dice: 0.5263  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 0.5058  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.7510  decode.d3.loss_dice: 0.5112  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.7331  decode.d4.loss_dice: 0.5128  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7482  decode.d5.loss_dice: 0.4961  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7279  decode.d6.loss_dice: 0.5069  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7501  decode.d7.loss_dice: 0.4981  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7382  decode.d8.loss_dice: 0.4878\n",
      "07/02 17:36:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12800/32000]  base_lr: 3.9466e-06 lr: 3.9466e-07  eta: 0:50:47  time: 0.1608  data_time: 0.0098  memory: 5153  grad_norm: 216.8168  loss: 13.7502  decode.loss_cls: 0.0003  decode.loss_mask: 0.8028  decode.loss_dice: 0.4853  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 1.0682  decode.d0.loss_dice: 0.6580  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.8490  decode.d1.loss_dice: 0.5235  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.8741  decode.d2.loss_dice: 0.5365  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.8208  decode.d3.loss_dice: 0.5080  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8274  decode.d4.loss_dice: 0.4954  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8163  decode.d5.loss_dice: 0.5046  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8081  decode.d6.loss_dice: 0.4905  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8189  decode.d7.loss_dice: 0.4913  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.8228  decode.d8.loss_dice: 0.4755\n",
      "07/02 17:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12850/32000]  base_lr: 3.9374e-06 lr: 3.9374e-07  eta: 0:50:39  time: 0.1607  data_time: 0.0101  memory: 5153  grad_norm: 136.5890  loss: 10.9001  decode.loss_cls: 0.0005  decode.loss_mask: 0.6559  decode.loss_dice: 0.3817  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.7000  decode.d1.loss_dice: 0.4117  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6502  decode.d2.loss_dice: 0.3983  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6385  decode.d3.loss_dice: 0.3904  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6660  decode.d4.loss_dice: 0.3948  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6690  decode.d5.loss_dice: 0.3952  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6758  decode.d6.loss_dice: 0.3872  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6670  decode.d7.loss_dice: 0.3801  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6543  decode.d8.loss_dice: 0.3688\n",
      "07/02 17:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12900/32000]  base_lr: 3.9281e-06 lr: 3.9281e-07  eta: 0:50:31  time: 0.1566  data_time: 0.0088  memory: 5153  grad_norm: 240.1481  loss: 13.5832  decode.loss_cls: 0.0016  decode.loss_mask: 0.8129  decode.loss_dice: 0.4974  decode.d0.loss_cls: 0.1112  decode.d0.loss_mask: 0.9960  decode.d0.loss_dice: 0.6491  decode.d1.loss_cls: 0.0366  decode.d1.loss_mask: 0.8140  decode.d1.loss_dice: 0.4951  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.8006  decode.d2.loss_dice: 0.4897  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.8204  decode.d3.loss_dice: 0.5166  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.8281  decode.d4.loss_dice: 0.5091  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.7988  decode.d5.loss_dice: 0.5026  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.8204  decode.d6.loss_dice: 0.4879  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.8043  decode.d7.loss_dice: 0.4786  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 0.4860\n",
      "07/02 17:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12950/32000]  base_lr: 3.9189e-06 lr: 3.9189e-07  eta: 0:50:23  time: 0.1598  data_time: 0.0085  memory: 5154  grad_norm: 128.3134  loss: 9.4907  decode.loss_cls: 0.0004  decode.loss_mask: 0.5553  decode.loss_dice: 0.3268  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.7027  decode.d0.loss_dice: 0.4303  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.5815  decode.d1.loss_dice: 0.3530  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.5946  decode.d2.loss_dice: 0.3624  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.5978  decode.d3.loss_dice: 0.3577  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.5890  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.5835  decode.d5.loss_dice: 0.3484  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.5608  decode.d6.loss_dice: 0.3224  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5664  decode.d7.loss_dice: 0.3256  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5720  decode.d8.loss_dice: 0.3355\n",
      "07/02 17:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13000/32000]  base_lr: 3.9096e-06 lr: 3.9096e-07  eta: 0:50:15  time: 0.1568  data_time: 0.0086  memory: 5154  grad_norm: 193.2982  loss: 12.0967  decode.loss_cls: 0.0051  decode.loss_mask: 0.7064  decode.loss_dice: 0.4222  decode.d0.loss_cls: 0.0403  decode.d0.loss_mask: 0.9091  decode.d0.loss_dice: 0.5878  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.7784  decode.d1.loss_dice: 0.4869  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.7474  decode.d2.loss_dice: 0.4450  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.7025  decode.d3.loss_dice: 0.4211  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.7005  decode.d4.loss_dice: 0.4296  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.7250  decode.d5.loss_dice: 0.4258  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.7325  decode.d6.loss_dice: 0.4424  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.7290  decode.d7.loss_dice: 0.4378  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 0.4185\n",
      "07/02 17:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0213  data_time: 0.0020  memory: 2168  \n",
      "07/02 17:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0285  data_time: 0.0060  memory: 1078  \n",
      "07/02 17:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.37 | 95.44 |\n",
      "|   lesion   | 78.91 | 89.86 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.0700  mIoU: 85.6400  mAcc: 92.6500  data_time: 0.0111  time: 0.0362\n",
      "07/02 17:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_9000.pth is removed\n",
      "07/02 17:36:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 85.6400 mIoU at 13000 iter is saved to best_mIoU_iter_13000.pth.\n",
      "07/02 17:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13050/32000]  base_lr: 3.9004e-06 lr: 3.9004e-07  eta: 0:50:10  time: 0.1574  data_time: 0.0086  memory: 5153  grad_norm: 203.9897  loss: 12.2372  decode.loss_cls: 0.0040  decode.loss_mask: 0.7185  decode.loss_dice: 0.4324  decode.d0.loss_cls: 0.1205  decode.d0.loss_mask: 0.9521  decode.d0.loss_dice: 0.5605  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.8061  decode.d1.loss_dice: 0.4667  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.7212  decode.d2.loss_dice: 0.4238  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.7282  decode.d3.loss_dice: 0.4317  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.7306  decode.d4.loss_dice: 0.4324  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.7403  decode.d5.loss_dice: 0.4216  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.7385  decode.d6.loss_dice: 0.4415  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.7358  decode.d7.loss_dice: 0.4315  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.7134  decode.d8.loss_dice: 0.4305\n",
      "07/02 17:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13100/32000]  base_lr: 3.8911e-06 lr: 3.8911e-07  eta: 0:50:02  time: 0.1680  data_time: 0.0095  memory: 5154  grad_norm: 173.0375  loss: 10.6134  decode.loss_cls: 0.0008  decode.loss_mask: 0.6271  decode.loss_dice: 0.3791  decode.d0.loss_cls: 0.1027  decode.d0.loss_mask: 0.7940  decode.d0.loss_dice: 0.5152  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.6668  decode.d1.loss_dice: 0.4182  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.6528  decode.d2.loss_dice: 0.3944  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.6276  decode.d3.loss_dice: 0.3827  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.6308  decode.d4.loss_dice: 0.3843  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.6342  decode.d5.loss_dice: 0.3844  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.6142  decode.d6.loss_dice: 0.3786  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6184  decode.d7.loss_dice: 0.3784  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6219  decode.d8.loss_dice: 0.3784\n",
      "07/02 17:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13150/32000]  base_lr: 3.8818e-06 lr: 3.8818e-07  eta: 0:49:54  time: 0.1570  data_time: 0.0064  memory: 5155  grad_norm: 157.3677  loss: 11.9801  decode.loss_cls: 0.0161  decode.loss_mask: 0.6762  decode.loss_dice: 0.4494  decode.d0.loss_cls: 0.0532  decode.d0.loss_mask: 0.8937  decode.d0.loss_dice: 0.5787  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.7153  decode.d1.loss_dice: 0.4782  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.7157  decode.d2.loss_dice: 0.4645  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.6882  decode.d3.loss_dice: 0.4449  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.7071  decode.d4.loss_dice: 0.4728  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.7040  decode.d5.loss_dice: 0.4566  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 0.4549  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.6789  decode.d7.loss_dice: 0.4613  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.6735  decode.d8.loss_dice: 0.4516\n",
      "07/02 17:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13200/32000]  base_lr: 3.8726e-06 lr: 3.8726e-07  eta: 0:49:46  time: 0.1562  data_time: 0.0084  memory: 5154  grad_norm: 289.6425  loss: 16.2215  decode.loss_cls: 0.0012  decode.loss_mask: 0.9434  decode.loss_dice: 0.6080  decode.d0.loss_cls: 0.1035  decode.d0.loss_mask: 1.1221  decode.d0.loss_dice: 0.7163  decode.d1.loss_cls: 0.2121  decode.d1.loss_mask: 1.0345  decode.d1.loss_dice: 0.6131  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.9731  decode.d2.loss_dice: 0.5765  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.9800  decode.d3.loss_dice: 0.5726  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.9449  decode.d4.loss_dice: 0.5716  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.9450  decode.d5.loss_dice: 0.5599  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.9232  decode.d6.loss_dice: 0.5769  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.9205  decode.d7.loss_dice: 0.5780  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.9566  decode.d8.loss_dice: 0.5720\n",
      "07/02 17:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13250/32000]  base_lr: 3.8633e-06 lr: 3.8633e-07  eta: 0:49:38  time: 0.1574  data_time: 0.0078  memory: 5153  grad_norm: 149.0523  loss: 11.7219  decode.loss_cls: 0.0008  decode.loss_mask: 0.7039  decode.loss_dice: 0.4191  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.8459  decode.d0.loss_dice: 0.5279  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.7377  decode.d1.loss_dice: 0.4343  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.7342  decode.d2.loss_dice: 0.4385  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7355  decode.d3.loss_dice: 0.4215  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.7141  decode.d4.loss_dice: 0.4266  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7342  decode.d5.loss_dice: 0.4124  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7163  decode.d6.loss_dice: 0.4235  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7004  decode.d7.loss_dice: 0.4163  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7010  decode.d8.loss_dice: 0.4146\n",
      "07/02 17:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13300/32000]  base_lr: 3.8540e-06 lr: 3.8540e-07  eta: 0:49:30  time: 0.1575  data_time: 0.0078  memory: 5153  grad_norm: 297.6253  loss: 16.3560  decode.loss_cls: 0.4945  decode.loss_mask: 0.8259  decode.loss_dice: 0.4872  decode.d0.loss_cls: 0.1382  decode.d0.loss_mask: 0.9728  decode.d0.loss_dice: 0.6553  decode.d1.loss_cls: 0.3085  decode.d1.loss_mask: 0.8913  decode.d1.loss_dice: 0.5380  decode.d2.loss_cls: 0.2711  decode.d2.loss_mask: 0.8692  decode.d2.loss_dice: 0.5109  decode.d3.loss_cls: 0.3051  decode.d3.loss_mask: 0.7989  decode.d3.loss_dice: 0.5286  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.8684  decode.d4.loss_dice: 0.5237  decode.d5.loss_cls: 0.2384  decode.d5.loss_mask: 0.8373  decode.d5.loss_dice: 0.5257  decode.d6.loss_cls: 0.2576  decode.d6.loss_mask: 0.8379  decode.d6.loss_dice: 0.4952  decode.d7.loss_cls: 0.2211  decode.d7.loss_mask: 0.8294  decode.d7.loss_dice: 0.5023  decode.d8.loss_cls: 0.2185  decode.d8.loss_mask: 0.8448  decode.d8.loss_dice: 0.4922\n",
      "07/02 17:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13350/32000]  base_lr: 3.8448e-06 lr: 3.8448e-07  eta: 0:49:22  time: 0.1620  data_time: 0.0084  memory: 5154  grad_norm: 146.9524  loss: 11.2077  decode.loss_cls: 0.0004  decode.loss_mask: 0.6677  decode.loss_dice: 0.4191  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.8479  decode.d0.loss_dice: 0.5616  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.7043  decode.d1.loss_dice: 0.4369  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.6809  decode.d2.loss_dice: 0.4072  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6669  decode.d3.loss_dice: 0.4137  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6575  decode.d4.loss_dice: 0.4176  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6629  decode.d5.loss_dice: 0.4164  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.6546  decode.d6.loss_dice: 0.4086  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6617  decode.d7.loss_dice: 0.4104  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6660  decode.d8.loss_dice: 0.4114\n",
      "07/02 17:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13400/32000]  base_lr: 3.8355e-06 lr: 3.8355e-07  eta: 0:49:14  time: 0.1605  data_time: 0.0082  memory: 5153  grad_norm: 158.9743  loss: 10.2952  decode.loss_cls: 0.0008  decode.loss_mask: 0.5769  decode.loss_dice: 0.3899  decode.d0.loss_cls: 0.0539  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 0.5203  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.6352  decode.d1.loss_dice: 0.4264  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.6266  decode.d2.loss_dice: 0.4081  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.5877  decode.d3.loss_dice: 0.3871  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.6128  decode.d4.loss_dice: 0.3880  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.5895  decode.d5.loss_dice: 0.3866  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.5932  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.5940  decode.d7.loss_dice: 0.3874  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.5868  decode.d8.loss_dice: 0.3885\n",
      "07/02 17:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13450/32000]  base_lr: 3.8262e-06 lr: 3.8262e-07  eta: 0:49:06  time: 0.1559  data_time: 0.0076  memory: 5153  grad_norm: 256.5303  loss: 13.1260  decode.loss_cls: 0.0011  decode.loss_mask: 0.7865  decode.loss_dice: 0.5049  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.9360  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.7861  decode.d1.loss_dice: 0.5186  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.7637  decode.d2.loss_dice: 0.4882  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7635  decode.d3.loss_dice: 0.4697  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7811  decode.d4.loss_dice: 0.4850  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.7578  decode.d5.loss_dice: 0.4764  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7928  decode.d6.loss_dice: 0.5274  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 0.5148  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7828  decode.d8.loss_dice: 0.5019\n",
      "07/02 17:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13500/32000]  base_lr: 3.8169e-06 lr: 3.8169e-07  eta: 0:48:58  time: 0.1618  data_time: 0.0077  memory: 5152  grad_norm: 124.7318  loss: 8.8912  decode.loss_cls: 0.0012  decode.loss_mask: 0.5076  decode.loss_dice: 0.3331  decode.d0.loss_cls: 0.0445  decode.d0.loss_mask: 0.6992  decode.d0.loss_dice: 0.4661  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.5440  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.5308  decode.d2.loss_dice: 0.3411  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.5138  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.5204  decode.d4.loss_dice: 0.3308  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.5209  decode.d5.loss_dice: 0.3429  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.5154  decode.d6.loss_dice: 0.3288  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.5053  decode.d7.loss_dice: 0.3323  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.4952  decode.d8.loss_dice: 0.3271\n",
      "07/02 17:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13550/32000]  base_lr: 3.8076e-06 lr: 3.8076e-07  eta: 0:48:50  time: 0.1568  data_time: 0.0087  memory: 5153  grad_norm: 120.7295  loss: 10.0548  decode.loss_cls: 0.0007  decode.loss_mask: 0.5956  decode.loss_dice: 0.3670  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.7790  decode.d0.loss_dice: 0.5002  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.6539  decode.d1.loss_dice: 0.3967  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.6186  decode.d2.loss_dice: 0.3633  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6083  decode.d3.loss_dice: 0.3623  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6148  decode.d4.loss_dice: 0.3630  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5765  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.5940  decode.d6.loss_dice: 0.3595  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.5940  decode.d7.loss_dice: 0.3620  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5895  decode.d8.loss_dice: 0.3586\n",
      "07/02 17:38:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13600/32000]  base_lr: 3.7983e-06 lr: 3.7983e-07  eta: 0:48:42  time: 0.1601  data_time: 0.0101  memory: 5153  grad_norm: 153.4654  loss: 11.6548  decode.loss_cls: 0.0021  decode.loss_mask: 0.6791  decode.loss_dice: 0.4025  decode.d0.loss_cls: 0.0323  decode.d0.loss_mask: 0.9703  decode.d0.loss_dice: 0.5916  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.7258  decode.d1.loss_dice: 0.4273  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.7274  decode.d2.loss_dice: 0.4350  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.6927  decode.d3.loss_dice: 0.4167  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6800  decode.d4.loss_dice: 0.4210  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.6810  decode.d5.loss_dice: 0.4099  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.6996  decode.d6.loss_dice: 0.4194  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7012  decode.d7.loss_dice: 0.4133  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.7010  decode.d8.loss_dice: 0.4147\n",
      "07/02 17:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13650/32000]  base_lr: 3.7890e-06 lr: 3.7890e-07  eta: 0:48:34  time: 0.1606  data_time: 0.0095  memory: 5154  grad_norm: 203.5314  loss: 13.6972  decode.loss_cls: 0.1430  decode.loss_mask: 0.7834  decode.loss_dice: 0.4807  decode.d0.loss_cls: 0.0601  decode.d0.loss_mask: 0.9402  decode.d0.loss_dice: 0.6170  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.8513  decode.d1.loss_dice: 0.5033  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 0.8084  decode.d2.loss_dice: 0.4663  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.7893  decode.d3.loss_dice: 0.4748  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 0.7498  decode.d4.loss_dice: 0.4546  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.7766  decode.d5.loss_dice: 0.4572  decode.d6.loss_cls: 0.0299  decode.d6.loss_mask: 0.7899  decode.d6.loss_dice: 0.4708  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.7840  decode.d7.loss_dice: 0.4669  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.7652  decode.d8.loss_dice: 0.4612\n",
      "07/02 17:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13700/32000]  base_lr: 3.7798e-06 lr: 3.7798e-07  eta: 0:48:27  time: 0.1568  data_time: 0.0078  memory: 5153  grad_norm: 135.9092  loss: 10.4350  decode.loss_cls: 0.0015  decode.loss_mask: 0.6264  decode.loss_dice: 0.3769  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.8085  decode.d0.loss_dice: 0.5244  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.6611  decode.d1.loss_dice: 0.4332  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.6423  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6198  decode.d3.loss_dice: 0.3810  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.5955  decode.d4.loss_dice: 0.3821  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.6031  decode.d5.loss_dice: 0.3752  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.6034  decode.d6.loss_dice: 0.3614  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.5969  decode.d7.loss_dice: 0.3736  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.6124  decode.d8.loss_dice: 0.3757\n",
      "07/02 17:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13750/32000]  base_lr: 3.7705e-06 lr: 3.7705e-07  eta: 0:48:19  time: 0.1557  data_time: 0.0084  memory: 5153  grad_norm: 249.7440  loss: 14.4683  decode.loss_cls: 0.0004  decode.loss_mask: 0.7739  decode.loss_dice: 0.5432  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 1.0181  decode.d0.loss_dice: 0.7069  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.8739  decode.d1.loss_dice: 0.6198  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.8522  decode.d2.loss_dice: 0.6095  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.8384  decode.d3.loss_dice: 0.6058  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.8407  decode.d4.loss_dice: 0.5991  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.8354  decode.d5.loss_dice: 0.5617  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.8543  decode.d6.loss_dice: 0.5586  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7816  decode.d7.loss_dice: 0.5516  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.7779  decode.d8.loss_dice: 0.5562\n",
      "07/02 17:38:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13800/32000]  base_lr: 3.7612e-06 lr: 3.7612e-07  eta: 0:48:11  time: 0.1599  data_time: 0.0086  memory: 5154  grad_norm: 170.7442  loss: 10.7922  decode.loss_cls: 0.0300  decode.loss_mask: 0.6267  decode.loss_dice: 0.3837  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.7710  decode.d0.loss_dice: 0.4967  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.6805  decode.d1.loss_dice: 0.4078  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.6299  decode.d2.loss_dice: 0.3980  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.6250  decode.d3.loss_dice: 0.3931  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.6166  decode.d4.loss_dice: 0.3761  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 0.6244  decode.d5.loss_dice: 0.3908  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.6296  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 0.6270  decode.d7.loss_dice: 0.3837  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 0.6483  decode.d8.loss_dice: 0.3811\n",
      "07/02 17:38:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13850/32000]  base_lr: 3.7519e-06 lr: 3.7519e-07  eta: 0:48:03  time: 0.1630  data_time: 0.0100  memory: 5153  grad_norm: 206.5633  loss: 13.2844  decode.loss_cls: 0.0005  decode.loss_mask: 0.8134  decode.loss_dice: 0.4560  decode.d0.loss_cls: 0.0633  decode.d0.loss_mask: 1.0165  decode.d0.loss_dice: 0.5958  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.7957  decode.d1.loss_dice: 0.4806  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.8166  decode.d2.loss_dice: 0.4846  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.8096  decode.d3.loss_dice: 0.4638  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.8200  decode.d4.loss_dice: 0.4866  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8139  decode.d5.loss_dice: 0.4849  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8234  decode.d6.loss_dice: 0.4736  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8194  decode.d7.loss_dice: 0.4557  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8285  decode.d8.loss_dice: 0.4752\n",
      "07/02 17:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13900/32000]  base_lr: 3.7426e-06 lr: 3.7426e-07  eta: 0:47:55  time: 0.1571  data_time: 0.0086  memory: 5153  grad_norm: 167.6276  loss: 11.7926  decode.loss_cls: 0.0009  decode.loss_mask: 0.6738  decode.loss_dice: 0.4084  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.8663  decode.d0.loss_dice: 0.6240  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.7228  decode.d1.loss_dice: 0.4399  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7821  decode.d2.loss_dice: 0.4529  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7312  decode.d3.loss_dice: 0.4440  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 0.4310  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7106  decode.d5.loss_dice: 0.4133  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 0.4027  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6910  decode.d7.loss_dice: 0.4122  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.6852  decode.d8.loss_dice: 0.4144\n",
      "07/02 17:39:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13950/32000]  base_lr: 3.7332e-06 lr: 3.7332e-07  eta: 0:47:47  time: 0.1549  data_time: 0.0083  memory: 5153  grad_norm: 202.1209  loss: 14.1096  decode.loss_cls: 0.0014  decode.loss_mask: 0.8514  decode.loss_dice: 0.5267  decode.d0.loss_cls: 0.0562  decode.d0.loss_mask: 0.9323  decode.d0.loss_dice: 0.6580  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.8172  decode.d1.loss_dice: 0.5299  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.8136  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.9038  decode.d3.loss_dice: 0.5208  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.8976  decode.d4.loss_dice: 0.5225  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.8677  decode.d5.loss_dice: 0.5146  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.8772  decode.d6.loss_dice: 0.5171  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.8380  decode.d7.loss_dice: 0.5119  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8403  decode.d8.loss_dice: 0.5275\n",
      "07/02 17:39:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:39:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14000/32000]  base_lr: 3.7239e-06 lr: 3.7239e-07  eta: 0:47:39  time: 0.1574  data_time: 0.0084  memory: 5153  grad_norm: 164.4498  loss: 11.7595  decode.loss_cls: 0.0009  decode.loss_mask: 0.6771  decode.loss_dice: 0.4121  decode.d0.loss_cls: 0.0348  decode.d0.loss_mask: 0.9178  decode.d0.loss_dice: 0.5618  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7220  decode.d1.loss_dice: 0.4603  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.7363  decode.d2.loss_dice: 0.4479  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.7022  decode.d3.loss_dice: 0.4464  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.6962  decode.d4.loss_dice: 0.4313  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.7034  decode.d5.loss_dice: 0.4216  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.6905  decode.d6.loss_dice: 0.4144  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.6986  decode.d7.loss_dice: 0.4315  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 0.4267\n",
      "07/02 17:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0219  data_time: 0.0022  memory: 2167  \n",
      "07/02 17:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0297  data_time: 0.0063  memory: 1078  \n",
      "07/02 17:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 91.73 | 95.43 |\n",
      "|   lesion   |  77.0 | 87.74 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.5300  mIoU: 84.3700  mAcc: 91.5800  data_time: 0.0110  time: 0.0366\n",
      "07/02 17:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14050/32000]  base_lr: 3.7146e-06 lr: 3.7146e-07  eta: 0:47:31  time: 0.1569  data_time: 0.0089  memory: 5153  grad_norm: 242.0272  loss: 14.6322  decode.loss_cls: 0.0002  decode.loss_mask: 0.8808  decode.loss_dice: 0.5023  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 1.1762  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.9622  decode.d1.loss_dice: 0.5742  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.8961  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.8698  decode.d3.loss_dice: 0.5164  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.8795  decode.d4.loss_dice: 0.5155  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8989  decode.d5.loss_dice: 0.5253  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8747  decode.d6.loss_dice: 0.5144  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8707  decode.d7.loss_dice: 0.5106  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.9012  decode.d8.loss_dice: 0.5009\n",
      "07/02 17:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14100/32000]  base_lr: 3.7053e-06 lr: 3.7053e-07  eta: 0:47:23  time: 0.1590  data_time: 0.0093  memory: 5153  grad_norm: 155.7795  loss: 11.9732  decode.loss_cls: 0.0011  decode.loss_mask: 0.6935  decode.loss_dice: 0.4545  decode.d0.loss_cls: 0.0505  decode.d0.loss_mask: 0.8509  decode.d0.loss_dice: 0.5688  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.6939  decode.d1.loss_dice: 0.4758  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.6670  decode.d2.loss_dice: 0.4457  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.6850  decode.d3.loss_dice: 0.4506  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 0.4712  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.7083  decode.d5.loss_dice: 0.4755  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.7061  decode.d6.loss_dice: 0.4710  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.7165  decode.d7.loss_dice: 0.4664  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7439  decode.d8.loss_dice: 0.4606\n",
      "07/02 17:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14150/32000]  base_lr: 3.6960e-06 lr: 3.6960e-07  eta: 0:47:15  time: 0.1572  data_time: 0.0091  memory: 5153  grad_norm: 267.3054  loss: 15.2645  decode.loss_cls: 0.0003  decode.loss_mask: 0.9273  decode.loss_dice: 0.5556  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 1.1309  decode.d0.loss_dice: 0.6937  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 0.5642  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.9456  decode.d2.loss_dice: 0.5596  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.9380  decode.d3.loss_dice: 0.5714  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.9098  decode.d4.loss_dice: 0.5719  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.9126  decode.d5.loss_dice: 0.5562  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.9080  decode.d6.loss_dice: 0.5561  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.9180  decode.d7.loss_dice: 0.5506  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.9324  decode.d8.loss_dice: 0.5568\n",
      "07/02 17:39:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14200/32000]  base_lr: 3.6867e-06 lr: 3.6867e-07  eta: 0:47:07  time: 0.1577  data_time: 0.0086  memory: 5154  grad_norm: 258.8815  loss: 13.9230  decode.loss_cls: 0.0015  decode.loss_mask: 0.8628  decode.loss_dice: 0.5051  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 1.0453  decode.d0.loss_dice: 0.6167  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.8869  decode.d1.loss_dice: 0.5369  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.8948  decode.d2.loss_dice: 0.5247  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.8391  decode.d3.loss_dice: 0.4987  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.8268  decode.d4.loss_dice: 0.5223  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.8193  decode.d5.loss_dice: 0.4883  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.8430  decode.d6.loss_dice: 0.4792  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.8339  decode.d7.loss_dice: 0.4957  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.8501  decode.d8.loss_dice: 0.4905\n",
      "07/02 17:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14250/32000]  base_lr: 3.6774e-06 lr: 3.6774e-07  eta: 0:46:59  time: 0.1600  data_time: 0.0097  memory: 5153  grad_norm: 169.1027  loss: 10.9305  decode.loss_cls: 0.0003  decode.loss_mask: 0.6733  decode.loss_dice: 0.3937  decode.d0.loss_cls: 0.0350  decode.d0.loss_mask: 0.8214  decode.d0.loss_dice: 0.4939  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.6582  decode.d1.loss_dice: 0.4138  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.6829  decode.d2.loss_dice: 0.4072  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6754  decode.d3.loss_dice: 0.3965  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.6807  decode.d4.loss_dice: 0.4001  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6615  decode.d5.loss_dice: 0.3983  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6645  decode.d6.loss_dice: 0.3819  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6556  decode.d7.loss_dice: 0.3854  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6676  decode.d8.loss_dice: 0.3772\n",
      "07/02 17:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14300/32000]  base_lr: 3.6680e-06 lr: 3.6680e-07  eta: 0:46:51  time: 0.1604  data_time: 0.0097  memory: 5154  grad_norm: 188.1540  loss: 10.0564  decode.loss_cls: 0.0004  decode.loss_mask: 0.6050  decode.loss_dice: 0.3718  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.7395  decode.d0.loss_dice: 0.4931  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.6013  decode.d1.loss_dice: 0.3818  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.5956  decode.d2.loss_dice: 0.3828  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.5892  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6051  decode.d4.loss_dice: 0.3735  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6213  decode.d5.loss_dice: 0.3696  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.5968  decode.d6.loss_dice: 0.3640  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5984  decode.d7.loss_dice: 0.3705  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6205  decode.d8.loss_dice: 0.3736\n",
      "07/02 17:40:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14350/32000]  base_lr: 3.6587e-06 lr: 3.6587e-07  eta: 0:46:43  time: 0.1617  data_time: 0.0100  memory: 5153  grad_norm: 176.1474  loss: 12.7017  decode.loss_cls: 0.0002  decode.loss_mask: 0.7663  decode.loss_dice: 0.4669  decode.d0.loss_cls: 0.1116  decode.d0.loss_mask: 0.9474  decode.d0.loss_dice: 0.6053  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7974  decode.d1.loss_dice: 0.4830  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7870  decode.d2.loss_dice: 0.4662  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7766  decode.d3.loss_dice: 0.4672  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 0.4531  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7481  decode.d5.loss_dice: 0.4552  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7510  decode.d6.loss_dice: 0.4529  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7534  decode.d7.loss_dice: 0.4469  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7605  decode.d8.loss_dice: 0.4555\n",
      "07/02 17:40:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14400/32000]  base_lr: 3.6494e-06 lr: 3.6494e-07  eta: 0:46:35  time: 0.1558  data_time: 0.0081  memory: 5153  grad_norm: 145.6384  loss: 11.3716  decode.loss_cls: 0.0002  decode.loss_mask: 0.6770  decode.loss_dice: 0.4120  decode.d0.loss_cls: 0.0451  decode.d0.loss_mask: 0.8209  decode.d0.loss_dice: 0.5257  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.7132  decode.d1.loss_dice: 0.4510  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7113  decode.d2.loss_dice: 0.4344  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.6830  decode.d3.loss_dice: 0.4171  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6772  decode.d4.loss_dice: 0.4335  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6716  decode.d5.loss_dice: 0.4154  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6888  decode.d6.loss_dice: 0.4197  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6867  decode.d7.loss_dice: 0.4083  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6630  decode.d8.loss_dice: 0.4119\n",
      "07/02 17:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14450/32000]  base_lr: 3.6400e-06 lr: 3.6400e-07  eta: 0:46:27  time: 0.1566  data_time: 0.0092  memory: 5153  grad_norm: 285.0298  loss: 14.3794  decode.loss_cls: 0.0008  decode.loss_mask: 0.9033  decode.loss_dice: 0.5238  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.9884  decode.d0.loss_dice: 0.6813  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.8844  decode.d1.loss_dice: 0.5621  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.8626  decode.d2.loss_dice: 0.5590  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.8452  decode.d3.loss_dice: 0.5280  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.8505  decode.d4.loss_dice: 0.5143  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.8616  decode.d5.loss_dice: 0.5154  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.8509  decode.d6.loss_dice: 0.5302  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.8823  decode.d7.loss_dice: 0.5301  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8782  decode.d8.loss_dice: 0.5274\n",
      "07/02 17:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14500/32000]  base_lr: 3.6307e-06 lr: 3.6307e-07  eta: 0:46:19  time: 0.1589  data_time: 0.0086  memory: 5153  grad_norm: 160.7225  loss: 12.5058  decode.loss_cls: 0.0010  decode.loss_mask: 0.7190  decode.loss_dice: 0.4535  decode.d0.loss_cls: 0.0342  decode.d0.loss_mask: 0.9310  decode.d0.loss_dice: 0.6114  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.7851  decode.d1.loss_dice: 0.4984  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.7426  decode.d2.loss_dice: 0.4851  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.7298  decode.d3.loss_dice: 0.4594  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7455  decode.d4.loss_dice: 0.4777  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 0.4543  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.7590  decode.d6.loss_dice: 0.4608  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7605  decode.d7.loss_dice: 0.4516  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.7271  decode.d8.loss_dice: 0.4425\n",
      "07/02 17:40:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14550/32000]  base_lr: 3.6214e-06 lr: 3.6214e-07  eta: 0:46:11  time: 0.1563  data_time: 0.0082  memory: 5153  grad_norm: 185.7097  loss: 11.9524  decode.loss_cls: 0.0010  decode.loss_mask: 0.6808  decode.loss_dice: 0.4415  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.9167  decode.d0.loss_dice: 0.5995  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 0.4998  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.7119  decode.d2.loss_dice: 0.4920  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.6897  decode.d3.loss_dice: 0.4624  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.6811  decode.d4.loss_dice: 0.4512  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.6768  decode.d5.loss_dice: 0.4719  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.6710  decode.d6.loss_dice: 0.4387  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.6733  decode.d7.loss_dice: 0.4503  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.6778  decode.d8.loss_dice: 0.4423\n",
      "07/02 17:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14600/32000]  base_lr: 3.6120e-06 lr: 3.6120e-07  eta: 0:46:03  time: 0.1558  data_time: 0.0085  memory: 5152  grad_norm: 215.1900  loss: 13.0925  decode.loss_cls: 0.0018  decode.loss_mask: 0.7622  decode.loss_dice: 0.4626  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.9220  decode.d0.loss_dice: 0.6504  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.8420  decode.d1.loss_dice: 0.5739  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.7598  decode.d2.loss_dice: 0.5046  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.7536  decode.d3.loss_dice: 0.4859  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7910  decode.d4.loss_dice: 0.4990  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7737  decode.d5.loss_dice: 0.4824  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.7909  decode.d6.loss_dice: 0.4763  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7918  decode.d7.loss_dice: 0.4699  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.7626  decode.d8.loss_dice: 0.4686\n",
      "07/02 17:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14650/32000]  base_lr: 3.6027e-06 lr: 3.6027e-07  eta: 0:45:55  time: 0.1565  data_time: 0.0084  memory: 5153  grad_norm: 137.3877  loss: 9.1884  decode.loss_cls: 0.0038  decode.loss_mask: 0.5379  decode.loss_dice: 0.3387  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.6917  decode.d0.loss_dice: 0.4273  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.5837  decode.d1.loss_dice: 0.3687  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.5557  decode.d2.loss_dice: 0.3434  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.5265  decode.d3.loss_dice: 0.3325  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.5264  decode.d4.loss_dice: 0.3502  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.5321  decode.d5.loss_dice: 0.3464  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.5294  decode.d6.loss_dice: 0.3494  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 0.3450  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5255  decode.d8.loss_dice: 0.3405\n",
      "07/02 17:41:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14700/32000]  base_lr: 3.5933e-06 lr: 3.5933e-07  eta: 0:45:47  time: 0.1573  data_time: 0.0088  memory: 5153  grad_norm: 150.7552  loss: 11.8013  decode.loss_cls: 0.0003  decode.loss_mask: 0.6816  decode.loss_dice: 0.4673  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.8281  decode.d0.loss_dice: 0.5856  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.7070  decode.d1.loss_dice: 0.4646  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6761  decode.d2.loss_dice: 0.4782  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.6911  decode.d3.loss_dice: 0.4665  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6877  decode.d4.loss_dice: 0.4650  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.6703  decode.d5.loss_dice: 0.4456  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6909  decode.d6.loss_dice: 0.4625  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6871  decode.d7.loss_dice: 0.4669  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6801  decode.d8.loss_dice: 0.4517\n",
      "07/02 17:41:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14750/32000]  base_lr: 3.5840e-06 lr: 3.5840e-07  eta: 0:45:39  time: 0.1573  data_time: 0.0083  memory: 5153  grad_norm: 204.0687  loss: 13.8873  decode.loss_cls: 0.0021  decode.loss_mask: 0.7774  decode.loss_dice: 0.5443  decode.d0.loss_cls: 0.1221  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.6466  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.8555  decode.d1.loss_dice: 0.5538  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.8300  decode.d2.loss_dice: 0.5660  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.8194  decode.d3.loss_dice: 0.5475  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.8159  decode.d4.loss_dice: 0.5254  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.7977  decode.d5.loss_dice: 0.5246  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7849  decode.d6.loss_dice: 0.5181  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.7971  decode.d7.loss_dice: 0.5211  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.7774  decode.d8.loss_dice: 0.5200\n",
      "07/02 17:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14800/32000]  base_lr: 3.5746e-06 lr: 3.5746e-07  eta: 0:45:31  time: 0.1573  data_time: 0.0088  memory: 5153  grad_norm: 209.0031  loss: 13.4908  decode.loss_cls: 0.0024  decode.loss_mask: 0.7745  decode.loss_dice: 0.5118  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 1.0304  decode.d0.loss_dice: 0.7149  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.8256  decode.d1.loss_dice: 0.5562  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.7748  decode.d2.loss_dice: 0.5212  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.7555  decode.d3.loss_dice: 0.4994  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.7581  decode.d4.loss_dice: 0.5027  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.7679  decode.d5.loss_dice: 0.5381  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.7722  decode.d6.loss_dice: 0.5251  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.7652  decode.d7.loss_dice: 0.5193  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.7785  decode.d8.loss_dice: 0.5229\n",
      "07/02 17:41:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14850/32000]  base_lr: 3.5653e-06 lr: 3.5653e-07  eta: 0:45:23  time: 0.1594  data_time: 0.0088  memory: 5153  grad_norm: 160.7107  loss: 12.4021  decode.loss_cls: 0.0003  decode.loss_mask: 0.7344  decode.loss_dice: 0.4890  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.9023  decode.d0.loss_dice: 0.6091  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.7645  decode.d1.loss_dice: 0.5024  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.7528  decode.d2.loss_dice: 0.4978  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.7281  decode.d3.loss_dice: 0.4597  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.7246  decode.d4.loss_dice: 0.4662  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7008  decode.d5.loss_dice: 0.4517  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7050  decode.d6.loss_dice: 0.4445  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7156  decode.d7.loss_dice: 0.4718  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7240  decode.d8.loss_dice: 0.4726\n",
      "07/02 17:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14900/32000]  base_lr: 3.5559e-06 lr: 3.5559e-07  eta: 0:45:15  time: 0.1589  data_time: 0.0094  memory: 5154  grad_norm: 174.5302  loss: 12.3945  decode.loss_cls: 0.0004  decode.loss_mask: 0.7524  decode.loss_dice: 0.4411  decode.d0.loss_cls: 0.0467  decode.d0.loss_mask: 0.9720  decode.d0.loss_dice: 0.6038  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.7904  decode.d1.loss_dice: 0.4676  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.7503  decode.d2.loss_dice: 0.4594  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7490  decode.d3.loss_dice: 0.4544  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7320  decode.d4.loss_dice: 0.4413  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7579  decode.d5.loss_dice: 0.4500  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7260  decode.d6.loss_dice: 0.4342  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7436  decode.d7.loss_dice: 0.4330  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7503  decode.d8.loss_dice: 0.4325\n",
      "07/02 17:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14950/32000]  base_lr: 3.5466e-06 lr: 3.5466e-07  eta: 0:45:08  time: 0.1611  data_time: 0.0091  memory: 5154  grad_norm: 187.4206  loss: 15.1507  decode.loss_cls: 0.0521  decode.loss_mask: 0.8756  decode.loss_dice: 0.5546  decode.d0.loss_cls: 0.0429  decode.d0.loss_mask: 1.0065  decode.d0.loss_dice: 0.6820  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.9318  decode.d1.loss_dice: 0.5453  decode.d2.loss_cls: 0.1797  decode.d2.loss_mask: 0.8923  decode.d2.loss_dice: 0.5452  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 0.9164  decode.d3.loss_dice: 0.5317  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.8778  decode.d4.loss_dice: 0.5350  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.8472  decode.d5.loss_dice: 0.5571  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.8782  decode.d6.loss_dice: 0.5535  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.8531  decode.d7.loss_dice: 0.5351  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.8635  decode.d8.loss_dice: 0.5514\n",
      "07/02 17:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15000/32000]  base_lr: 3.5372e-06 lr: 3.5372e-07  eta: 0:45:00  time: 0.1597  data_time: 0.0099  memory: 5152  grad_norm: 149.5258  loss: 11.0020  decode.loss_cls: 0.0006  decode.loss_mask: 0.6370  decode.loss_dice: 0.3992  decode.d0.loss_cls: 0.0417  decode.d0.loss_mask: 0.8304  decode.d0.loss_dice: 0.5538  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.7278  decode.d1.loss_dice: 0.4704  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.6926  decode.d2.loss_dice: 0.4252  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.6289  decode.d3.loss_dice: 0.4004  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6337  decode.d4.loss_dice: 0.4121  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.6325  decode.d5.loss_dice: 0.4019  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6411  decode.d6.loss_dice: 0.3962  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6511  decode.d7.loss_dice: 0.3989  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6232  decode.d8.loss_dice: 0.3925\n",
      "07/02 17:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15000 iterations\n",
      "07/02 17:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0215  data_time: 0.0022  memory: 2167  \n",
      "07/02 17:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0306  data_time: 0.0064  memory: 1078  \n",
      "07/02 17:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.26 | 95.31 |\n",
      "|   lesion   | 78.68 | 89.91 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.9800  mIoU: 85.4700  mAcc: 92.6100  data_time: 0.0111  time: 0.0364\n",
      "07/02 17:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15050/32000]  base_lr: 3.5278e-06 lr: 3.5278e-07  eta: 0:44:52  time: 0.1633  data_time: 0.0077  memory: 5154  grad_norm: 208.5316  loss: 14.1534  decode.loss_cls: 0.0004  decode.loss_mask: 0.8362  decode.loss_dice: 0.5523  decode.d0.loss_cls: 0.1025  decode.d0.loss_mask: 0.9661  decode.d0.loss_dice: 0.6468  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.8138  decode.d1.loss_dice: 0.5378  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.8607  decode.d2.loss_dice: 0.5385  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.8471  decode.d3.loss_dice: 0.5188  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 0.5533  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 0.5569  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.8200  decode.d6.loss_dice: 0.5371  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8444  decode.d7.loss_dice: 0.5337  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.8337  decode.d8.loss_dice: 0.5399\n",
      "07/02 17:42:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15100/32000]  base_lr: 3.5185e-06 lr: 3.5185e-07  eta: 0:44:44  time: 0.1585  data_time: 0.0080  memory: 5153  grad_norm: 145.5417  loss: 11.8666  decode.loss_cls: 0.0004  decode.loss_mask: 0.7629  decode.loss_dice: 0.4259  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.8408  decode.d0.loss_dice: 0.4963  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.7308  decode.d1.loss_dice: 0.4259  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7597  decode.d2.loss_dice: 0.4299  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7287  decode.d3.loss_dice: 0.4131  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7328  decode.d4.loss_dice: 0.4185  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7382  decode.d5.loss_dice: 0.4153  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7646  decode.d6.loss_dice: 0.4156  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7497  decode.d7.loss_dice: 0.4160  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7619  decode.d8.loss_dice: 0.4079\n",
      "07/02 17:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15150/32000]  base_lr: 3.5091e-06 lr: 3.5091e-07  eta: 0:44:36  time: 0.1588  data_time: 0.0089  memory: 5152  grad_norm: 157.8177  loss: 10.9451  decode.loss_cls: 0.0313  decode.loss_mask: 0.6619  decode.loss_dice: 0.3960  decode.d0.loss_cls: 0.0502  decode.d0.loss_mask: 0.7579  decode.d0.loss_dice: 0.4857  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.6975  decode.d1.loss_dice: 0.4253  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6515  decode.d2.loss_dice: 0.4162  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6286  decode.d3.loss_dice: 0.3852  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6419  decode.d4.loss_dice: 0.4111  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6488  decode.d5.loss_dice: 0.4167  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6558  decode.d6.loss_dice: 0.4147  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6473  decode.d7.loss_dice: 0.3987  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.6565  decode.d8.loss_dice: 0.4016\n",
      "07/02 17:42:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15200/32000]  base_lr: 3.4997e-06 lr: 3.4997e-07  eta: 0:44:28  time: 0.1594  data_time: 0.0091  memory: 5154  grad_norm: 168.1619  loss: 11.2676  decode.loss_cls: 0.0019  decode.loss_mask: 0.6660  decode.loss_dice: 0.4182  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 0.5373  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.7142  decode.d1.loss_dice: 0.4498  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 0.4177  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.6604  decode.d3.loss_dice: 0.4077  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.6742  decode.d4.loss_dice: 0.4032  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.6690  decode.d5.loss_dice: 0.4125  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.6710  decode.d6.loss_dice: 0.4017  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.6847  decode.d7.loss_dice: 0.4053  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.6827  decode.d8.loss_dice: 0.4138\n",
      "07/02 17:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15250/32000]  base_lr: 3.4904e-06 lr: 3.4904e-07  eta: 0:44:21  time: 0.1627  data_time: 0.0091  memory: 5154  grad_norm: 186.4475  loss: 11.5604  decode.loss_cls: 0.0002  decode.loss_mask: 0.7175  decode.loss_dice: 0.4262  decode.d0.loss_cls: 0.0295  decode.d0.loss_mask: 0.8786  decode.d0.loss_dice: 0.5356  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7206  decode.d1.loss_dice: 0.4514  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.6951  decode.d2.loss_dice: 0.4117  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.7093  decode.d3.loss_dice: 0.4197  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7010  decode.d4.loss_dice: 0.4130  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7093  decode.d5.loss_dice: 0.4255  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6948  decode.d6.loss_dice: 0.4136  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.6845  decode.d7.loss_dice: 0.4081  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6922  decode.d8.loss_dice: 0.4175\n",
      "07/02 17:42:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15300/32000]  base_lr: 3.4810e-06 lr: 3.4810e-07  eta: 0:44:13  time: 0.1556  data_time: 0.0083  memory: 5154  grad_norm: 206.9377  loss: 11.6297  decode.loss_cls: 0.0006  decode.loss_mask: 0.6976  decode.loss_dice: 0.4353  decode.d0.loss_cls: 0.0303  decode.d0.loss_mask: 0.8780  decode.d0.loss_dice: 0.5365  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7280  decode.d1.loss_dice: 0.4290  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7096  decode.d2.loss_dice: 0.4285  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6726  decode.d3.loss_dice: 0.4214  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6898  decode.d4.loss_dice: 0.4216  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7026  decode.d5.loss_dice: 0.4340  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7248  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7032  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6951  decode.d8.loss_dice: 0.4276\n",
      "07/02 17:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15350/32000]  base_lr: 3.4716e-06 lr: 3.4716e-07  eta: 0:44:05  time: 0.1584  data_time: 0.0080  memory: 5153  grad_norm: 220.4028  loss: 13.6529  decode.loss_cls: 0.0007  decode.loss_mask: 0.8653  decode.loss_dice: 0.4812  decode.d0.loss_cls: 0.0486  decode.d0.loss_mask: 0.9309  decode.d0.loss_dice: 0.6073  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.8205  decode.d1.loss_dice: 0.5120  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.8580  decode.d2.loss_dice: 0.5157  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.8119  decode.d3.loss_dice: 0.4965  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 0.4954  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8533  decode.d5.loss_dice: 0.4815  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.8568  decode.d6.loss_dice: 0.4742  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.8643  decode.d7.loss_dice: 0.4788  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.8844  decode.d8.loss_dice: 0.4923\n",
      "07/02 17:43:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15400/32000]  base_lr: 3.4622e-06 lr: 3.4622e-07  eta: 0:43:57  time: 0.1612  data_time: 0.0085  memory: 5153  grad_norm: 175.8174  loss: 13.3695  decode.loss_cls: 0.1743  decode.loss_mask: 0.7613  decode.loss_dice: 0.4458  decode.d0.loss_cls: 0.0384  decode.d0.loss_mask: 0.9335  decode.d0.loss_dice: 0.5619  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.8263  decode.d1.loss_dice: 0.4861  decode.d2.loss_cls: 0.2023  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 0.4605  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.7644  decode.d3.loss_dice: 0.4835  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.7602  decode.d4.loss_dice: 0.4780  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.7588  decode.d5.loss_dice: 0.4747  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.7733  decode.d6.loss_dice: 0.4809  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.7539  decode.d7.loss_dice: 0.4779  decode.d8.loss_cls: 0.1765  decode.d8.loss_mask: 0.7504  decode.d8.loss_dice: 0.4446\n",
      "07/02 17:43:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15450/32000]  base_lr: 3.4528e-06 lr: 3.4528e-07  eta: 0:43:49  time: 0.1551  data_time: 0.0081  memory: 5153  grad_norm: 221.2267  loss: 14.0534  decode.loss_cls: 0.0002  decode.loss_mask: 0.8937  decode.loss_dice: 0.5288  decode.d0.loss_cls: 0.0507  decode.d0.loss_mask: 0.9432  decode.d0.loss_dice: 0.6316  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.8696  decode.d1.loss_dice: 0.5467  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.8493  decode.d2.loss_dice: 0.5369  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.8349  decode.d3.loss_dice: 0.5231  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.8294  decode.d4.loss_dice: 0.5238  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.8192  decode.d5.loss_dice: 0.5097  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.8683  decode.d6.loss_dice: 0.5180  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 0.5160  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.8700  decode.d8.loss_dice: 0.5107\n",
      "07/02 17:43:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15500/32000]  base_lr: 3.4434e-06 lr: 3.4434e-07  eta: 0:43:41  time: 0.1561  data_time: 0.0079  memory: 5154  grad_norm: 203.2112  loss: 11.9080  decode.loss_cls: 0.0300  decode.loss_mask: 0.6360  decode.loss_dice: 0.4551  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.7934  decode.d0.loss_dice: 0.5605  decode.d1.loss_cls: 0.0301  decode.d1.loss_mask: 0.6720  decode.d1.loss_dice: 0.4782  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.6920  decode.d2.loss_dice: 0.4946  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.6568  decode.d3.loss_dice: 0.4853  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.6713  decode.d4.loss_dice: 0.4733  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7105  decode.d5.loss_dice: 0.4785  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.6928  decode.d6.loss_dice: 0.4649  decode.d7.loss_cls: 0.0993  decode.d7.loss_mask: 0.6271  decode.d7.loss_dice: 0.4527  decode.d8.loss_cls: 0.0956  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.4528\n",
      "07/02 17:43:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15550/32000]  base_lr: 3.4340e-06 lr: 3.4340e-07  eta: 0:43:33  time: 0.1612  data_time: 0.0088  memory: 5153  grad_norm: 131.0521  loss: 9.5682  decode.loss_cls: 0.0004  decode.loss_mask: 0.5811  decode.loss_dice: 0.3430  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 0.7120  decode.d0.loss_dice: 0.4605  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.6062  decode.d1.loss_dice: 0.3706  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.5683  decode.d2.loss_dice: 0.3761  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.5655  decode.d3.loss_dice: 0.3612  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.5592  decode.d4.loss_dice: 0.3644  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.5501  decode.d5.loss_dice: 0.3508  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.5515  decode.d6.loss_dice: 0.3343  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.5797  decode.d7.loss_dice: 0.3411  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.5944  decode.d8.loss_dice: 0.3388\n",
      "07/02 17:43:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15600/32000]  base_lr: 3.4247e-06 lr: 3.4247e-07  eta: 0:43:25  time: 0.1613  data_time: 0.0093  memory: 5154  grad_norm: 179.5881  loss: 12.0614  decode.loss_cls: 0.0006  decode.loss_mask: 0.7122  decode.loss_dice: 0.4529  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.8869  decode.d0.loss_dice: 0.5880  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.7672  decode.d1.loss_dice: 0.4837  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7268  decode.d2.loss_dice: 0.4719  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7331  decode.d3.loss_dice: 0.4482  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7136  decode.d4.loss_dice: 0.4428  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7074  decode.d5.loss_dice: 0.4397  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7051  decode.d6.loss_dice: 0.4343  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6927  decode.d7.loss_dice: 0.4367  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6917  decode.d8.loss_dice: 0.4464\n",
      "07/02 17:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15650/32000]  base_lr: 3.4153e-06 lr: 3.4153e-07  eta: 0:43:18  time: 0.1607  data_time: 0.0093  memory: 5153  grad_norm: 181.7904  loss: 12.2126  decode.loss_cls: 0.0002  decode.loss_mask: 0.6962  decode.loss_dice: 0.4971  decode.d0.loss_cls: 0.0508  decode.d0.loss_mask: 0.8862  decode.d0.loss_dice: 0.5965  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.7250  decode.d1.loss_dice: 0.4824  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.7337  decode.d2.loss_dice: 0.4826  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6876  decode.d3.loss_dice: 0.4719  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7012  decode.d4.loss_dice: 0.4867  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.6910  decode.d5.loss_dice: 0.4812  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6922  decode.d6.loss_dice: 0.4774  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6990  decode.d7.loss_dice: 0.4813  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6965  decode.d8.loss_dice: 0.4835\n",
      "07/02 17:44:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15700/32000]  base_lr: 3.4059e-06 lr: 3.4059e-07  eta: 0:43:10  time: 0.1566  data_time: 0.0094  memory: 5153  grad_norm: 190.7669  loss: 13.0064  decode.loss_cls: 0.0002  decode.loss_mask: 0.7988  decode.loss_dice: 0.4599  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.9478  decode.d0.loss_dice: 0.5505  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.8075  decode.d1.loss_dice: 0.4726  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.8291  decode.d2.loss_dice: 0.4691  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.8270  decode.d3.loss_dice: 0.4580  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8414  decode.d4.loss_dice: 0.4608  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.8008  decode.d5.loss_dice: 0.4464  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.8121  decode.d6.loss_dice: 0.4573  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8071  decode.d7.loss_dice: 0.4506  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.8011  decode.d8.loss_dice: 0.4535\n",
      "07/02 17:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15750/32000]  base_lr: 3.3965e-06 lr: 3.3965e-07  eta: 0:43:02  time: 0.1599  data_time: 0.0093  memory: 5153  grad_norm: 110.9669  loss: 9.1939  decode.loss_cls: 0.0006  decode.loss_mask: 0.5228  decode.loss_dice: 0.3608  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 0.6537  decode.d0.loss_dice: 0.4761  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.5304  decode.d1.loss_dice: 0.3754  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.5424  decode.d2.loss_dice: 0.3842  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5142  decode.d3.loss_dice: 0.3631  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.5174  decode.d4.loss_dice: 0.3681  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.5176  decode.d5.loss_dice: 0.3721  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5301  decode.d6.loss_dice: 0.3655  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.5292  decode.d7.loss_dice: 0.3594  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.5187  decode.d8.loss_dice: 0.3519\n",
      "07/02 17:44:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15800/32000]  base_lr: 3.3870e-06 lr: 3.3870e-07  eta: 0:42:54  time: 0.1593  data_time: 0.0097  memory: 5153  grad_norm: 209.7472  loss: 13.1122  decode.loss_cls: 0.0005  decode.loss_mask: 0.8035  decode.loss_dice: 0.4628  decode.d0.loss_cls: 0.0317  decode.d0.loss_mask: 1.0038  decode.d0.loss_dice: 0.6155  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.8421  decode.d1.loss_dice: 0.5147  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.7824  decode.d2.loss_dice: 0.4811  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.7701  decode.d3.loss_dice: 0.4886  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.7945  decode.d4.loss_dice: 0.4913  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.7698  decode.d5.loss_dice: 0.4799  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.7653  decode.d6.loss_dice: 0.4626  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7973  decode.d7.loss_dice: 0.4649  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.8070  decode.d8.loss_dice: 0.4655\n",
      "07/02 17:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15850/32000]  base_lr: 3.3776e-06 lr: 3.3776e-07  eta: 0:42:46  time: 0.1611  data_time: 0.0103  memory: 5155  grad_norm: 213.5933  loss: 14.7013  decode.loss_cls: 0.2498  decode.loss_mask: 0.6799  decode.loss_dice: 0.4209  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.9212  decode.d0.loss_dice: 0.6013  decode.d1.loss_cls: 0.2344  decode.d1.loss_mask: 0.7492  decode.d1.loss_dice: 0.4761  decode.d2.loss_cls: 0.2577  decode.d2.loss_mask: 0.6825  decode.d2.loss_dice: 0.4340  decode.d3.loss_cls: 0.5061  decode.d3.loss_mask: 0.6845  decode.d3.loss_dice: 0.4323  decode.d4.loss_cls: 0.4943  decode.d4.loss_mask: 0.6992  decode.d4.loss_dice: 0.4592  decode.d5.loss_cls: 0.4567  decode.d5.loss_mask: 0.6787  decode.d5.loss_dice: 0.4298  decode.d6.loss_cls: 0.2439  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 0.4331  decode.d7.loss_cls: 0.2500  decode.d7.loss_mask: 0.6715  decode.d7.loss_dice: 0.4232  decode.d8.loss_cls: 0.2535  decode.d8.loss_mask: 0.6860  decode.d8.loss_dice: 0.4253\n",
      "07/02 17:44:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15900/32000]  base_lr: 3.3682e-06 lr: 3.3682e-07  eta: 0:42:38  time: 0.1565  data_time: 0.0096  memory: 5154  grad_norm: 173.2048  loss: 12.3338  decode.loss_cls: 0.0560  decode.loss_mask: 0.7146  decode.loss_dice: 0.4643  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.5544  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.7738  decode.d1.loss_dice: 0.4883  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.7425  decode.d2.loss_dice: 0.4620  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.7482  decode.d3.loss_dice: 0.4485  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.7430  decode.d4.loss_dice: 0.4463  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7514  decode.d5.loss_dice: 0.4687  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.7072  decode.d6.loss_dice: 0.4611  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.7139  decode.d7.loss_dice: 0.4550  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.7102  decode.d8.loss_dice: 0.4458\n",
      "07/02 17:44:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15950/32000]  base_lr: 3.3588e-06 lr: 3.3588e-07  eta: 0:42:30  time: 0.1631  data_time: 0.0098  memory: 5153  grad_norm: 186.8227  loss: 12.8422  decode.loss_cls: 0.0147  decode.loss_mask: 0.7054  decode.loss_dice: 0.4902  decode.d0.loss_cls: 0.1500  decode.d0.loss_mask: 0.9428  decode.d0.loss_dice: 0.6531  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.7736  decode.d1.loss_dice: 0.5381  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.7457  decode.d2.loss_dice: 0.4861  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.7505  decode.d3.loss_dice: 0.4823  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.7349  decode.d4.loss_dice: 0.4681  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.7144  decode.d5.loss_dice: 0.4704  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.7157  decode.d6.loss_dice: 0.4857  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.7193  decode.d7.loss_dice: 0.4740  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.7047  decode.d8.loss_dice: 0.4968\n",
      "07/02 17:44:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:44:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16000/32000]  base_lr: 3.3494e-06 lr: 3.3494e-07  eta: 0:42:22  time: 0.1607  data_time: 0.0087  memory: 5152  grad_norm: 119.0498  loss: 9.9188  decode.loss_cls: 0.0002  decode.loss_mask: 0.5874  decode.loss_dice: 0.3510  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.7627  decode.d0.loss_dice: 0.4940  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.6156  decode.d1.loss_dice: 0.3797  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6231  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6028  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 0.3657  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5882  decode.d5.loss_dice: 0.3684  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5937  decode.d6.loss_dice: 0.3543  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5899  decode.d7.loss_dice: 0.3427  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5900  decode.d8.loss_dice: 0.3462\n",
      "07/02 17:44:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0213  data_time: 0.0021  memory: 2167  \n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0286  data_time: 0.0059  memory: 1078  \n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.33 | 94.91 |\n",
      "|   lesion   | 79.21 |  91.5 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.0700  mIoU: 85.7700  mAcc: 93.2100  data_time: 0.0112  time: 0.0364\n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_13000.pth is removed\n",
      "07/02 17:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 85.7700 mIoU at 16000 iter is saved to best_mIoU_iter_16000.pth.\n",
      "07/02 17:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16050/32000]  base_lr: 3.3400e-06 lr: 3.3400e-07  eta: 0:42:16  time: 0.1586  data_time: 0.0094  memory: 5154  grad_norm: 170.9871  loss: 11.9596  decode.loss_cls: 0.0010  decode.loss_mask: 0.7216  decode.loss_dice: 0.4216  decode.d0.loss_cls: 0.0949  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 0.5174  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.7416  decode.d1.loss_dice: 0.4359  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.7247  decode.d2.loss_dice: 0.4303  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7632  decode.d3.loss_dice: 0.4293  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7234  decode.d4.loss_dice: 0.4323  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7374  decode.d5.loss_dice: 0.4279  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.7497  decode.d6.loss_dice: 0.4238  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.7198  decode.d7.loss_dice: 0.4165  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7298  decode.d8.loss_dice: 0.4237\n",
      "07/02 17:45:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16100/32000]  base_lr: 3.3305e-06 lr: 3.3305e-07  eta: 0:42:08  time: 0.1583  data_time: 0.0087  memory: 5153  grad_norm: 308.5316  loss: 14.8929  decode.loss_cls: 0.0022  decode.loss_mask: 0.8938  decode.loss_dice: 0.5090  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 1.0937  decode.d0.loss_dice: 0.6466  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.9854  decode.d1.loss_dice: 0.5478  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.9839  decode.d2.loss_dice: 0.5436  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.9415  decode.d3.loss_dice: 0.4968  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.9369  decode.d4.loss_dice: 0.5400  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.9193  decode.d5.loss_dice: 0.5191  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.9140  decode.d6.loss_dice: 0.5218  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.9239  decode.d7.loss_dice: 0.4995  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.8899  decode.d8.loss_dice: 0.4950\n",
      "07/02 17:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16150/32000]  base_lr: 3.3211e-06 lr: 3.3211e-07  eta: 0:42:00  time: 0.1587  data_time: 0.0090  memory: 5154  grad_norm: 206.5837  loss: 13.9121  decode.loss_cls: 0.0005  decode.loss_mask: 0.8407  decode.loss_dice: 0.5204  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 1.1168  decode.d0.loss_dice: 0.6615  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.8558  decode.d1.loss_dice: 0.5077  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.8501  decode.d2.loss_dice: 0.5026  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.8215  decode.d3.loss_dice: 0.5248  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.8357  decode.d4.loss_dice: 0.5204  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.8395  decode.d5.loss_dice: 0.5095  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.7998  decode.d6.loss_dice: 0.4979  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.8015  decode.d7.loss_dice: 0.4933  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8137  decode.d8.loss_dice: 0.5189\n",
      "07/02 17:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16200/32000]  base_lr: 3.3117e-06 lr: 3.3117e-07  eta: 0:41:52  time: 0.1595  data_time: 0.0094  memory: 5153  grad_norm: 203.9115  loss: 12.6210  decode.loss_cls: 0.0006  decode.loss_mask: 0.7881  decode.loss_dice: 0.4443  decode.d0.loss_cls: 0.0439  decode.d0.loss_mask: 0.9280  decode.d0.loss_dice: 0.5374  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.7865  decode.d1.loss_dice: 0.4596  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.7609  decode.d2.loss_dice: 0.4531  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.7595  decode.d3.loss_dice: 0.4407  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.7754  decode.d4.loss_dice: 0.4483  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.8050  decode.d5.loss_dice: 0.4617  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.7798  decode.d6.loss_dice: 0.4501  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.7812  decode.d7.loss_dice: 0.4456  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.8086  decode.d8.loss_dice: 0.4477\n",
      "07/02 17:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16250/32000]  base_lr: 3.3022e-06 lr: 3.3022e-07  eta: 0:41:44  time: 0.1591  data_time: 0.0090  memory: 5152  grad_norm: 124.6109  loss: 10.6061  decode.loss_cls: 0.0026  decode.loss_mask: 0.5677  decode.loss_dice: 0.4394  decode.d0.loss_cls: 0.0524  decode.d0.loss_mask: 0.7255  decode.d0.loss_dice: 0.5730  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.5911  decode.d1.loss_dice: 0.4652  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.5998  decode.d2.loss_dice: 0.4488  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.5963  decode.d3.loss_dice: 0.4534  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.5781  decode.d4.loss_dice: 0.4400  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.5844  decode.d5.loss_dice: 0.4469  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.5685  decode.d6.loss_dice: 0.4502  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.5617  decode.d7.loss_dice: 0.4447  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.5612  decode.d8.loss_dice: 0.4450\n",
      "07/02 17:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16300/32000]  base_lr: 3.2928e-06 lr: 3.2928e-07  eta: 0:41:36  time: 0.1590  data_time: 0.0099  memory: 5153  grad_norm: 162.2109  loss: 10.4819  decode.loss_cls: 0.0009  decode.loss_mask: 0.5983  decode.loss_dice: 0.3883  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.7955  decode.d0.loss_dice: 0.5178  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.6933  decode.d1.loss_dice: 0.4221  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.6754  decode.d2.loss_dice: 0.4075  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.6027  decode.d3.loss_dice: 0.3718  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.6130  decode.d4.loss_dice: 0.3839  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.6111  decode.d5.loss_dice: 0.3869  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.6051  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6115  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6057  decode.d8.loss_dice: 0.3829\n",
      "07/02 17:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16350/32000]  base_lr: 3.2834e-06 lr: 3.2834e-07  eta: 0:41:28  time: 0.1584  data_time: 0.0095  memory: 5154  grad_norm: 162.2827  loss: 10.8626  decode.loss_cls: 0.0003  decode.loss_mask: 0.6475  decode.loss_dice: 0.3998  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.8458  decode.d0.loss_dice: 0.5337  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.6817  decode.d1.loss_dice: 0.4240  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.6500  decode.d2.loss_dice: 0.4104  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6514  decode.d3.loss_dice: 0.4047  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6316  decode.d4.loss_dice: 0.3948  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6438  decode.d5.loss_dice: 0.3993  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.6406  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6298  decode.d7.loss_dice: 0.3863  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6258  decode.d8.loss_dice: 0.3950\n",
      "07/02 17:45:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16400/32000]  base_lr: 3.2739e-06 lr: 3.2739e-07  eta: 0:41:20  time: 0.1596  data_time: 0.0098  memory: 5154  grad_norm: 189.7465  loss: 14.1057  decode.loss_cls: 0.0010  decode.loss_mask: 0.8584  decode.loss_dice: 0.5548  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 1.0513  decode.d0.loss_dice: 0.7035  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.8986  decode.d1.loss_dice: 0.5691  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.8574  decode.d2.loss_dice: 0.5307  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.8084  decode.d3.loss_dice: 0.5148  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.8043  decode.d4.loss_dice: 0.5127  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 0.5251  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.8114  decode.d6.loss_dice: 0.5014  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.8210  decode.d7.loss_dice: 0.5129  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8320  decode.d8.loss_dice: 0.5252\n",
      "07/02 17:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16450/32000]  base_lr: 3.2645e-06 lr: 3.2645e-07  eta: 0:41:12  time: 0.1603  data_time: 0.0099  memory: 5153  grad_norm: 231.1776  loss: 11.4452  decode.loss_cls: 0.0030  decode.loss_mask: 0.6565  decode.loss_dice: 0.4718  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.8077  decode.d0.loss_dice: 0.6022  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.6855  decode.d1.loss_dice: 0.5119  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.6537  decode.d2.loss_dice: 0.4519  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.6363  decode.d3.loss_dice: 0.4202  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.6457  decode.d4.loss_dice: 0.4354  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.6414  decode.d5.loss_dice: 0.4345  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.6523  decode.d6.loss_dice: 0.4580  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.6355  decode.d7.loss_dice: 0.4401  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.6526  decode.d8.loss_dice: 0.4522\n",
      "07/02 17:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16500/32000]  base_lr: 3.2550e-06 lr: 3.2550e-07  eta: 0:41:05  time: 0.1602  data_time: 0.0100  memory: 5155  grad_norm: 168.2633  loss: 12.0994  decode.loss_cls: 0.0007  decode.loss_mask: 0.7162  decode.loss_dice: 0.4467  decode.d0.loss_cls: 0.0442  decode.d0.loss_mask: 0.9207  decode.d0.loss_dice: 0.6022  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.7651  decode.d1.loss_dice: 0.4595  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.7454  decode.d2.loss_dice: 0.4318  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7495  decode.d3.loss_dice: 0.4358  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7405  decode.d4.loss_dice: 0.4382  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7402  decode.d5.loss_dice: 0.4414  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7202  decode.d6.loss_dice: 0.4240  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7208  decode.d7.loss_dice: 0.4144  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.7056  decode.d8.loss_dice: 0.4288\n",
      "07/02 17:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16550/32000]  base_lr: 3.2456e-06 lr: 3.2456e-07  eta: 0:40:57  time: 0.1575  data_time: 0.0091  memory: 5154  grad_norm: 115.1330  loss: 10.5767  decode.loss_cls: 0.0007  decode.loss_mask: 0.6697  decode.loss_dice: 0.3740  decode.d0.loss_cls: 0.0345  decode.d0.loss_mask: 0.8033  decode.d0.loss_dice: 0.5117  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.6548  decode.d1.loss_dice: 0.4003  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6372  decode.d2.loss_dice: 0.3816  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.6404  decode.d3.loss_dice: 0.3672  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6401  decode.d4.loss_dice: 0.3736  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.6517  decode.d5.loss_dice: 0.3637  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.6486  decode.d6.loss_dice: 0.3770  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6480  decode.d7.loss_dice: 0.3720  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6545  decode.d8.loss_dice: 0.3640\n",
      "07/02 17:46:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16600/32000]  base_lr: 3.2361e-06 lr: 3.2361e-07  eta: 0:40:49  time: 0.1585  data_time: 0.0095  memory: 5153  grad_norm: 239.0233  loss: 13.4942  decode.loss_cls: 0.0043  decode.loss_mask: 0.7919  decode.loss_dice: 0.4944  decode.d0.loss_cls: 0.1197  decode.d0.loss_mask: 0.9316  decode.d0.loss_dice: 0.6486  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.8337  decode.d1.loss_dice: 0.5586  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.8142  decode.d2.loss_dice: 0.5134  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.7568  decode.d3.loss_dice: 0.4880  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.7784  decode.d4.loss_dice: 0.4888  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.7868  decode.d5.loss_dice: 0.4771  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.8260  decode.d6.loss_dice: 0.4882  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.8391  decode.d7.loss_dice: 0.4923  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.8246  decode.d8.loss_dice: 0.4798\n",
      "07/02 17:46:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16650/32000]  base_lr: 3.2267e-06 lr: 3.2267e-07  eta: 0:40:41  time: 0.1601  data_time: 0.0091  memory: 5153  grad_norm: 137.2803  loss: 11.0150  decode.loss_cls: 0.0006  decode.loss_mask: 0.6554  decode.loss_dice: 0.3868  decode.d0.loss_cls: 0.0520  decode.d0.loss_mask: 0.8310  decode.d0.loss_dice: 0.5219  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.6841  decode.d1.loss_dice: 0.4044  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6910  decode.d2.loss_dice: 0.3942  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6924  decode.d3.loss_dice: 0.3997  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6769  decode.d4.loss_dice: 0.4077  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6633  decode.d5.loss_dice: 0.4063  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6604  decode.d6.loss_dice: 0.3908  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6590  decode.d7.loss_dice: 0.3970  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6482  decode.d8.loss_dice: 0.3857\n",
      "07/02 17:46:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16700/32000]  base_lr: 3.2172e-06 lr: 3.2172e-07  eta: 0:40:33  time: 0.1608  data_time: 0.0097  memory: 5153  grad_norm: 194.7312  loss: 12.0334  decode.loss_cls: 0.0043  decode.loss_mask: 0.7303  decode.loss_dice: 0.4273  decode.d0.loss_cls: 0.0404  decode.d0.loss_mask: 0.9484  decode.d0.loss_dice: 0.5363  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.7498  decode.d1.loss_dice: 0.4426  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.7462  decode.d2.loss_dice: 0.4549  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.7085  decode.d3.loss_dice: 0.4294  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.7291  decode.d4.loss_dice: 0.4274  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.7559  decode.d5.loss_dice: 0.4307  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.7276  decode.d6.loss_dice: 0.4124  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.7337  decode.d7.loss_dice: 0.4085  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.7178  decode.d8.loss_dice: 0.4147\n",
      "07/02 17:46:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16750/32000]  base_lr: 3.2077e-06 lr: 3.2077e-07  eta: 0:40:25  time: 0.1604  data_time: 0.0095  memory: 5153  grad_norm: 227.3526  loss: 14.8766  decode.loss_cls: 0.0009  decode.loss_mask: 0.8594  decode.loss_dice: 0.5991  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 1.0730  decode.d0.loss_dice: 0.7247  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.8759  decode.d1.loss_dice: 0.6166  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 0.5916  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.8399  decode.d3.loss_dice: 0.5620  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.8661  decode.d4.loss_dice: 0.5912  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.8736  decode.d5.loss_dice: 0.5914  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.8797  decode.d6.loss_dice: 0.5666  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.8654  decode.d7.loss_dice: 0.5576  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8758  decode.d8.loss_dice: 0.5853\n",
      "07/02 17:47:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16800/32000]  base_lr: 3.1983e-06 lr: 3.1983e-07  eta: 0:40:17  time: 0.1574  data_time: 0.0082  memory: 5153  grad_norm: 169.7287  loss: 13.3780  decode.loss_cls: 0.1701  decode.loss_mask: 0.7792  decode.loss_dice: 0.4309  decode.d0.loss_cls: 0.0424  decode.d0.loss_mask: 0.9158  decode.d0.loss_dice: 0.5532  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7640  decode.d1.loss_dice: 0.4437  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.8132  decode.d2.loss_dice: 0.4527  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.7895  decode.d3.loss_dice: 0.4515  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.8039  decode.d4.loss_dice: 0.4609  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.8037  decode.d5.loss_dice: 0.4660  decode.d6.loss_cls: 0.1993  decode.d6.loss_mask: 0.8160  decode.d6.loss_dice: 0.4364  decode.d7.loss_cls: 0.1765  decode.d7.loss_mask: 0.7869  decode.d7.loss_dice: 0.4359  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 0.4242\n",
      "07/02 17:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16850/32000]  base_lr: 3.1888e-06 lr: 3.1888e-07  eta: 0:40:09  time: 0.1582  data_time: 0.0095  memory: 5153  grad_norm: 144.6760  loss: 10.7523  decode.loss_cls: 0.0003  decode.loss_mask: 0.6186  decode.loss_dice: 0.3963  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.7694  decode.d0.loss_dice: 0.5048  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.6554  decode.d1.loss_dice: 0.4354  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.6416  decode.d2.loss_dice: 0.4124  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6420  decode.d3.loss_dice: 0.3977  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6517  decode.d4.loss_dice: 0.3980  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6355  decode.d5.loss_dice: 0.4079  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6412  decode.d6.loss_dice: 0.4064  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 0.4068  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.3975\n",
      "07/02 17:47:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16900/32000]  base_lr: 3.1793e-06 lr: 3.1793e-07  eta: 0:40:01  time: 0.1588  data_time: 0.0098  memory: 5153  grad_norm: 157.1464  loss: 11.3628  decode.loss_cls: 0.0009  decode.loss_mask: 0.6768  decode.loss_dice: 0.4103  decode.d0.loss_cls: 0.0521  decode.d0.loss_mask: 0.8492  decode.d0.loss_dice: 0.5707  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.7028  decode.d1.loss_dice: 0.4543  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7037  decode.d2.loss_dice: 0.4454  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6881  decode.d3.loss_dice: 0.4135  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.6593  decode.d4.loss_dice: 0.4170  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.6653  decode.d5.loss_dice: 0.4235  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.6627  decode.d6.loss_dice: 0.4039  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6661  decode.d7.loss_dice: 0.4088  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6691  decode.d8.loss_dice: 0.4094\n",
      "07/02 17:47:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16950/32000]  base_lr: 3.1699e-06 lr: 3.1699e-07  eta: 0:39:53  time: 0.1600  data_time: 0.0095  memory: 5153  grad_norm: 155.1738  loss: 11.0644  decode.loss_cls: 0.0002  decode.loss_mask: 0.6498  decode.loss_dice: 0.4127  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.7857  decode.d0.loss_dice: 0.5251  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.6766  decode.d1.loss_dice: 0.4603  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6764  decode.d2.loss_dice: 0.4426  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.6459  decode.d3.loss_dice: 0.4444  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6365  decode.d4.loss_dice: 0.4336  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6342  decode.d5.loss_dice: 0.4189  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6301  decode.d6.loss_dice: 0.4109  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6418  decode.d7.loss_dice: 0.4144  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6506  decode.d8.loss_dice: 0.4217\n",
      "07/02 17:47:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:47:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17000/32000]  base_lr: 3.1604e-06 lr: 3.1604e-07  eta: 0:39:45  time: 0.1587  data_time: 0.0092  memory: 5154  grad_norm: 150.6392  loss: 10.9742  decode.loss_cls: 0.0005  decode.loss_mask: 0.6237  decode.loss_dice: 0.4048  decode.d0.loss_cls: 0.0356  decode.d0.loss_mask: 0.7936  decode.d0.loss_dice: 0.5506  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.6678  decode.d1.loss_dice: 0.4626  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.6677  decode.d2.loss_dice: 0.4388  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6482  decode.d3.loss_dice: 0.4280  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 0.4403  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6275  decode.d5.loss_dice: 0.4295  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.6304  decode.d6.loss_dice: 0.4140  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6391  decode.d7.loss_dice: 0.4052  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6265  decode.d8.loss_dice: 0.3903\n",
      "07/02 17:47:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0212  data_time: 0.0021  memory: 2167  \n",
      "07/02 17:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0289  data_time: 0.0059  memory: 1078  \n",
      "07/02 17:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.72 | 96.12 |\n",
      "|   lesion   | 79.43 | 88.83 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.3200  mIoU: 86.0800  mAcc: 92.4700  data_time: 0.0110  time: 0.0361\n",
      "07/02 17:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_16000.pth is removed\n",
      "07/02 17:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 86.0800 mIoU at 17000 iter is saved to best_mIoU_iter_17000.pth.\n",
      "07/02 17:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17050/32000]  base_lr: 3.1509e-06 lr: 3.1509e-07  eta: 0:39:39  time: 0.1579  data_time: 0.0076  memory: 5153  grad_norm: 128.6780  loss: 9.8173  decode.loss_cls: 0.0006  decode.loss_mask: 0.5953  decode.loss_dice: 0.3535  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 0.4730  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.6077  decode.d1.loss_dice: 0.3840  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.5740  decode.d2.loss_dice: 0.3379  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.5868  decode.d3.loss_dice: 0.3578  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6067  decode.d4.loss_dice: 0.3573  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6051  decode.d5.loss_dice: 0.3515  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6105  decode.d6.loss_dice: 0.3487  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6054  decode.d7.loss_dice: 0.3440  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6002  decode.d8.loss_dice: 0.3556\n",
      "07/02 17:47:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17100/32000]  base_lr: 3.1414e-06 lr: 3.1414e-07  eta: 0:39:31  time: 0.1592  data_time: 0.0085  memory: 5153  grad_norm: 248.7642  loss: 13.6159  decode.loss_cls: 0.0010  decode.loss_mask: 0.8007  decode.loss_dice: 0.5115  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.9661  decode.d0.loss_dice: 0.6558  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.8006  decode.d1.loss_dice: 0.5352  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.7950  decode.d2.loss_dice: 0.5124  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.7887  decode.d3.loss_dice: 0.5142  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7964  decode.d4.loss_dice: 0.5257  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.8081  decode.d5.loss_dice: 0.5291  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7989  decode.d6.loss_dice: 0.5247  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7992  decode.d7.loss_dice: 0.5276  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.8034  decode.d8.loss_dice: 0.5328\n",
      "07/02 17:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17150/32000]  base_lr: 3.1319e-06 lr: 3.1319e-07  eta: 0:39:23  time: 0.1564  data_time: 0.0075  memory: 5154  grad_norm: 163.8050  loss: 8.4514  decode.loss_cls: 0.0014  decode.loss_mask: 0.5116  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.0422  decode.d0.loss_mask: 0.6012  decode.d0.loss_dice: 0.4137  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.5152  decode.d1.loss_dice: 0.3167  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.4854  decode.d2.loss_dice: 0.3123  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.5126  decode.d3.loss_dice: 0.3019  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.5308  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.5476  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 0.3175  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.5079  decode.d7.loss_dice: 0.2962  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.5091  decode.d8.loss_dice: 0.2944\n",
      "07/02 17:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17200/32000]  base_lr: 3.1224e-06 lr: 3.1224e-07  eta: 0:39:15  time: 0.1560  data_time: 0.0079  memory: 5154  grad_norm: 182.5022  loss: 13.1717  decode.loss_cls: 0.0008  decode.loss_mask: 0.7811  decode.loss_dice: 0.4778  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.9202  decode.d0.loss_dice: 0.6292  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.8130  decode.d1.loss_dice: 0.5129  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 0.4910  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.7866  decode.d3.loss_dice: 0.4917  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.8081  decode.d4.loss_dice: 0.5108  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.8096  decode.d5.loss_dice: 0.4801  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.7912  decode.d6.loss_dice: 0.4738  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.7724  decode.d7.loss_dice: 0.4807  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7694  decode.d8.loss_dice: 0.4765\n",
      "07/02 17:48:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17250/32000]  base_lr: 3.1129e-06 lr: 3.1129e-07  eta: 0:39:07  time: 0.1566  data_time: 0.0086  memory: 5154  grad_norm: 138.3707  loss: 11.8641  decode.loss_cls: 0.0003  decode.loss_mask: 0.7073  decode.loss_dice: 0.4410  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.9394  decode.d0.loss_dice: 0.5944  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.7357  decode.d1.loss_dice: 0.5010  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.6987  decode.d2.loss_dice: 0.4540  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7000  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6837  decode.d4.loss_dice: 0.4276  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6827  decode.d5.loss_dice: 0.4528  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6800  decode.d6.loss_dice: 0.4285  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6840  decode.d7.loss_dice: 0.4367  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6857  decode.d8.loss_dice: 0.4360\n",
      "07/02 17:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17300/32000]  base_lr: 3.1034e-06 lr: 3.1034e-07  eta: 0:38:59  time: 0.1601  data_time: 0.0098  memory: 5154  grad_norm: 196.9082  loss: 13.2936  decode.loss_cls: 0.0037  decode.loss_mask: 0.8101  decode.loss_dice: 0.4966  decode.d0.loss_cls: 0.0568  decode.d0.loss_mask: 0.9677  decode.d0.loss_dice: 0.6396  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.8083  decode.d1.loss_dice: 0.5119  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.8032  decode.d2.loss_dice: 0.4957  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7824  decode.d3.loss_dice: 0.4975  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7903  decode.d4.loss_dice: 0.4919  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7844  decode.d5.loss_dice: 0.5031  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.8002  decode.d6.loss_dice: 0.4850  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7974  decode.d7.loss_dice: 0.4754  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.8025  decode.d8.loss_dice: 0.4805\n",
      "07/02 17:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17350/32000]  base_lr: 3.0939e-06 lr: 3.0939e-07  eta: 0:38:51  time: 0.1601  data_time: 0.0091  memory: 5153  grad_norm: 170.8803  loss: 13.2169  decode.loss_cls: 0.0005  decode.loss_mask: 0.7745  decode.loss_dice: 0.4801  decode.d0.loss_cls: 0.0599  decode.d0.loss_mask: 1.0073  decode.d0.loss_dice: 0.6090  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.7930  decode.d1.loss_dice: 0.5115  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.8214  decode.d2.loss_dice: 0.5048  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.8047  decode.d3.loss_dice: 0.4896  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.7979  decode.d4.loss_dice: 0.4940  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.7622  decode.d5.loss_dice: 0.4823  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7868  decode.d6.loss_dice: 0.4836  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 0.4799  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.8046  decode.d8.loss_dice: 0.4832\n",
      "07/02 17:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17400/32000]  base_lr: 3.0844e-06 lr: 3.0844e-07  eta: 0:38:43  time: 0.1581  data_time: 0.0084  memory: 5153  grad_norm: 144.8761  loss: 13.2207  decode.loss_cls: 0.0011  decode.loss_mask: 0.8341  decode.loss_dice: 0.4608  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 1.0022  decode.d0.loss_dice: 0.6033  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.8359  decode.d1.loss_dice: 0.4666  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.8245  decode.d2.loss_dice: 0.4448  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.8206  decode.d3.loss_dice: 0.4685  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.8013  decode.d4.loss_dice: 0.4556  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.8190  decode.d5.loss_dice: 0.4668  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.8334  decode.d6.loss_dice: 0.4575  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.8315  decode.d7.loss_dice: 0.4465  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8343  decode.d8.loss_dice: 0.4577\n",
      "07/02 17:48:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17450/32000]  base_lr: 3.0749e-06 lr: 3.0749e-07  eta: 0:38:35  time: 0.1627  data_time: 0.0129  memory: 5153  grad_norm: 186.6569  loss: 11.5653  decode.loss_cls: 0.0006  decode.loss_mask: 0.6758  decode.loss_dice: 0.4169  decode.d0.loss_cls: 0.0317  decode.d0.loss_mask: 0.8798  decode.d0.loss_dice: 0.5876  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.7375  decode.d1.loss_dice: 0.4610  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6995  decode.d2.loss_dice: 0.4275  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7026  decode.d3.loss_dice: 0.4272  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6925  decode.d4.loss_dice: 0.4372  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6917  decode.d5.loss_dice: 0.4208  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6800  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6873  decode.d7.loss_dice: 0.4080  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6785  decode.d8.loss_dice: 0.4127\n",
      "07/02 17:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17500/32000]  base_lr: 3.0654e-06 lr: 3.0654e-07  eta: 0:38:27  time: 0.1599  data_time: 0.0104  memory: 5153  grad_norm: 288.1008  loss: 16.2190  decode.loss_cls: 0.0020  decode.loss_mask: 0.9261  decode.loss_dice: 0.6050  decode.d0.loss_cls: 0.1280  decode.d0.loss_mask: 1.1528  decode.d0.loss_dice: 0.7664  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 1.0144  decode.d1.loss_dice: 0.6428  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 1.0011  decode.d2.loss_dice: 0.6374  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.9649  decode.d3.loss_dice: 0.6388  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.9669  decode.d4.loss_dice: 0.6330  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.9327  decode.d5.loss_dice: 0.6331  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.9091  decode.d6.loss_dice: 0.6001  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 0.5924  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.9271  decode.d8.loss_dice: 0.6098\n",
      "07/02 17:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17550/32000]  base_lr: 3.0559e-06 lr: 3.0559e-07  eta: 0:38:19  time: 0.1600  data_time: 0.0101  memory: 5154  grad_norm: 162.9959  loss: 10.6226  decode.loss_cls: 0.0015  decode.loss_mask: 0.5868  decode.loss_dice: 0.4306  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.6843  decode.d0.loss_dice: 0.5343  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.6240  decode.d1.loss_dice: 0.4724  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6114  decode.d2.loss_dice: 0.4515  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6093  decode.d3.loss_dice: 0.4444  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6106  decode.d4.loss_dice: 0.4320  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6134  decode.d5.loss_dice: 0.4165  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.5969  decode.d6.loss_dice: 0.4204  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.5969  decode.d7.loss_dice: 0.4223  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.5936  decode.d8.loss_dice: 0.4298\n",
      "07/02 17:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17600/32000]  base_lr: 3.0464e-06 lr: 3.0464e-07  eta: 0:38:11  time: 0.1615  data_time: 0.0101  memory: 5153  grad_norm: 147.7085  loss: 12.1177  decode.loss_cls: 0.0007  decode.loss_mask: 0.6856  decode.loss_dice: 0.4588  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.8966  decode.d0.loss_dice: 0.6487  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7025  decode.d1.loss_dice: 0.4929  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.6997  decode.d2.loss_dice: 0.4742  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7279  decode.d3.loss_dice: 0.4754  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6933  decode.d4.loss_dice: 0.4575  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7069  decode.d5.loss_dice: 0.4545  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7138  decode.d6.loss_dice: 0.4633  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7041  decode.d7.loss_dice: 0.4614  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6933  decode.d8.loss_dice: 0.4625\n",
      "07/02 17:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17650/32000]  base_lr: 3.0369e-06 lr: 3.0369e-07  eta: 0:38:03  time: 0.1614  data_time: 0.0097  memory: 5153  grad_norm: 226.2367  loss: 14.9649  decode.loss_cls: 0.2187  decode.loss_mask: 0.8278  decode.loss_dice: 0.5125  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.9410  decode.d0.loss_dice: 0.6471  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 0.7982  decode.d1.loss_dice: 0.5248  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.7988  decode.d2.loss_dice: 0.5116  decode.d3.loss_cls: 0.1447  decode.d3.loss_mask: 0.8103  decode.d3.loss_dice: 0.5280  decode.d4.loss_cls: 0.1503  decode.d4.loss_mask: 0.8018  decode.d4.loss_dice: 0.5214  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.8038  decode.d5.loss_dice: 0.5263  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.8227  decode.d6.loss_dice: 0.5167  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.8409  decode.d7.loss_dice: 0.5176  decode.d8.loss_cls: 0.2174  decode.d8.loss_mask: 0.8234  decode.d8.loss_dice: 0.5095\n",
      "07/02 17:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17700/32000]  base_lr: 3.0273e-06 lr: 3.0273e-07  eta: 0:37:55  time: 0.1597  data_time: 0.0100  memory: 5154  grad_norm: 123.5661  loss: 11.3981  decode.loss_cls: 0.0008  decode.loss_mask: 0.6756  decode.loss_dice: 0.4074  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.8249  decode.d0.loss_dice: 0.5088  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.7412  decode.d1.loss_dice: 0.4338  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6839  decode.d2.loss_dice: 0.4207  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6990  decode.d3.loss_dice: 0.4295  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.7027  decode.d4.loss_dice: 0.4242  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7033  decode.d5.loss_dice: 0.4194  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6959  decode.d6.loss_dice: 0.4257  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6726  decode.d7.loss_dice: 0.4092  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6760  decode.d8.loss_dice: 0.4080\n",
      "07/02 17:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17750/32000]  base_lr: 3.0178e-06 lr: 3.0178e-07  eta: 0:37:48  time: 0.1582  data_time: 0.0094  memory: 5153  grad_norm: 116.3455  loss: 9.9827  decode.loss_cls: 0.0043  decode.loss_mask: 0.5236  decode.loss_dice: 0.4464  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.6623  decode.d0.loss_dice: 0.5618  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.5398  decode.d1.loss_dice: 0.4758  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 0.4608  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.5294  decode.d3.loss_dice: 0.4512  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.5214  decode.d4.loss_dice: 0.4391  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.5285  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.5237  decode.d6.loss_dice: 0.4332  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.5220  decode.d7.loss_dice: 0.3970  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.5220  decode.d8.loss_dice: 0.4291\n",
      "07/02 17:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17800/32000]  base_lr: 3.0083e-06 lr: 3.0083e-07  eta: 0:37:40  time: 0.1584  data_time: 0.0093  memory: 5154  grad_norm: 175.5615  loss: 12.0916  decode.loss_cls: 0.0002  decode.loss_mask: 0.7428  decode.loss_dice: 0.4217  decode.d0.loss_cls: 0.0238  decode.d0.loss_mask: 0.9319  decode.d0.loss_dice: 0.5237  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.7463  decode.d1.loss_dice: 0.4562  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7497  decode.d2.loss_dice: 0.4231  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.7471  decode.d3.loss_dice: 0.4204  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7410  decode.d4.loss_dice: 0.4345  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7442  decode.d5.loss_dice: 0.4319  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7613  decode.d6.loss_dice: 0.4317  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7515  decode.d7.loss_dice: 0.4321  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7475  decode.d8.loss_dice: 0.4247\n",
      "07/02 17:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17850/32000]  base_lr: 2.9987e-06 lr: 2.9987e-07  eta: 0:37:32  time: 0.1604  data_time: 0.0102  memory: 5152  grad_norm: 96.7400  loss: 8.8293  decode.loss_cls: 0.0004  decode.loss_mask: 0.5216  decode.loss_dice: 0.3272  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.6470  decode.d0.loss_dice: 0.4494  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.5355  decode.d1.loss_dice: 0.3444  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.5182  decode.d2.loss_dice: 0.3291  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.5263  decode.d3.loss_dice: 0.3271  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5255  decode.d4.loss_dice: 0.3352  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5245  decode.d5.loss_dice: 0.3260  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.5318  decode.d6.loss_dice: 0.3390  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.5296  decode.d7.loss_dice: 0.3282  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5160  decode.d8.loss_dice: 0.3202\n",
      "07/02 17:50:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17900/32000]  base_lr: 2.9892e-06 lr: 2.9892e-07  eta: 0:37:24  time: 0.1598  data_time: 0.0103  memory: 5153  grad_norm: 212.5411  loss: 13.9457  decode.loss_cls: 0.0118  decode.loss_mask: 0.8197  decode.loss_dice: 0.5053  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 1.0272  decode.d0.loss_dice: 0.6376  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.8319  decode.d1.loss_dice: 0.5210  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.8614  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.8695  decode.d3.loss_dice: 0.5059  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.8460  decode.d4.loss_dice: 0.5150  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.8101  decode.d5.loss_dice: 0.5240  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.8011  decode.d6.loss_dice: 0.5250  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 0.5122  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.8060  decode.d8.loss_dice: 0.4979\n",
      "07/02 17:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17950/32000]  base_lr: 2.9797e-06 lr: 2.9797e-07  eta: 0:37:16  time: 0.1599  data_time: 0.0099  memory: 5153  grad_norm: 153.1301  loss: 11.6828  decode.loss_cls: 0.0005  decode.loss_mask: 0.7169  decode.loss_dice: 0.4292  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.8917  decode.d0.loss_dice: 0.5814  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.7479  decode.d1.loss_dice: 0.4510  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.7287  decode.d2.loss_dice: 0.4284  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.6847  decode.d3.loss_dice: 0.4246  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7009  decode.d4.loss_dice: 0.4229  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6946  decode.d5.loss_dice: 0.4092  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6905  decode.d6.loss_dice: 0.4044  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6985  decode.d7.loss_dice: 0.4019  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7077  decode.d8.loss_dice: 0.4205\n",
      "07/02 17:50:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:50:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18000/32000]  base_lr: 2.9701e-06 lr: 2.9701e-07  eta: 0:37:08  time: 0.1588  data_time: 0.0099  memory: 5153  grad_norm: 192.2569  loss: 12.1314  decode.loss_cls: 0.0024  decode.loss_mask: 0.7143  decode.loss_dice: 0.4537  decode.d0.loss_cls: 0.0378  decode.d0.loss_mask: 0.8989  decode.d0.loss_dice: 0.5985  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.7321  decode.d1.loss_dice: 0.4717  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.7388  decode.d2.loss_dice: 0.4867  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.7060  decode.d3.loss_dice: 0.4652  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.7145  decode.d4.loss_dice: 0.4693  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6975  decode.d5.loss_dice: 0.4608  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.7040  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.7080  decode.d7.loss_dice: 0.4372  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 0.4510\n",
      "07/02 17:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0212  data_time: 0.0020  memory: 2166  \n",
      "07/02 17:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0286  data_time: 0.0061  memory: 1078  \n",
      "07/02 17:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 91.76 | 95.45 |\n",
      "|   lesion   | 77.06 | 87.74 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.5400  mIoU: 84.4100  mAcc: 91.6000  data_time: 0.0111  time: 0.0361\n",
      "07/02 17:50:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18050/32000]  base_lr: 2.9606e-06 lr: 2.9606e-07  eta: 0:37:00  time: 0.1598  data_time: 0.0102  memory: 5153  grad_norm: 116.7900  loss: 10.6791  decode.loss_cls: 0.0002  decode.loss_mask: 0.6549  decode.loss_dice: 0.3619  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.8239  decode.d0.loss_dice: 0.4871  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.6708  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7036  decode.d2.loss_dice: 0.3890  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.6853  decode.d3.loss_dice: 0.3727  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.6769  decode.d4.loss_dice: 0.3766  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 0.3676  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6492  decode.d6.loss_dice: 0.3640  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6466  decode.d7.loss_dice: 0.3627  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6623  decode.d8.loss_dice: 0.3669\n",
      "07/02 17:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18100/32000]  base_lr: 2.9510e-06 lr: 2.9510e-07  eta: 0:36:52  time: 0.1575  data_time: 0.0092  memory: 5154  grad_norm: 179.2288  loss: 12.0656  decode.loss_cls: 0.0005  decode.loss_mask: 0.7194  decode.loss_dice: 0.4327  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.8808  decode.d0.loss_dice: 0.5527  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.7511  decode.d1.loss_dice: 0.4418  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.7477  decode.d2.loss_dice: 0.4669  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7439  decode.d3.loss_dice: 0.4497  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7389  decode.d4.loss_dice: 0.4463  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7245  decode.d5.loss_dice: 0.4346  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 0.4284  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7199  decode.d7.loss_dice: 0.4294  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7090  decode.d8.loss_dice: 0.4320\n",
      "07/02 17:50:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18150/32000]  base_lr: 2.9415e-06 lr: 2.9415e-07  eta: 0:36:44  time: 0.1545  data_time: 0.0064  memory: 5154  grad_norm: 159.5129  loss: 10.6842  decode.loss_cls: 0.0001  decode.loss_mask: 0.6307  decode.loss_dice: 0.3823  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.8287  decode.d0.loss_dice: 0.5157  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.6613  decode.d1.loss_dice: 0.4097  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6984  decode.d2.loss_dice: 0.3944  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6607  decode.d3.loss_dice: 0.3973  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.6488  decode.d4.loss_dice: 0.3883  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.6403  decode.d5.loss_dice: 0.3821  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6253  decode.d6.loss_dice: 0.3745  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6354  decode.d7.loss_dice: 0.3733  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6313  decode.d8.loss_dice: 0.3802\n",
      "07/02 17:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18200/32000]  base_lr: 2.9319e-06 lr: 2.9319e-07  eta: 0:36:36  time: 0.1610  data_time: 0.0097  memory: 5153  grad_norm: 103.6688  loss: 9.1068  decode.loss_cls: 0.0004  decode.loss_mask: 0.5457  decode.loss_dice: 0.3337  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.6913  decode.d0.loss_dice: 0.4371  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.5694  decode.d1.loss_dice: 0.3569  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.5485  decode.d2.loss_dice: 0.3491  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.5428  decode.d3.loss_dice: 0.3410  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5448  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5433  decode.d5.loss_dice: 0.3379  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.5378  decode.d6.loss_dice: 0.3289  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.5390  decode.d7.loss_dice: 0.3280  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5418  decode.d8.loss_dice: 0.3344\n",
      "07/02 17:51:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18250/32000]  base_lr: 2.9223e-06 lr: 2.9223e-07  eta: 0:36:28  time: 0.1596  data_time: 0.0099  memory: 5153  grad_norm: 136.5439  loss: 11.3012  decode.loss_cls: 0.0007  decode.loss_mask: 0.7059  decode.loss_dice: 0.3805  decode.d0.loss_cls: 0.0620  decode.d0.loss_mask: 0.8276  decode.d0.loss_dice: 0.5167  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.6984  decode.d1.loss_dice: 0.4083  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6872  decode.d2.loss_dice: 0.4106  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7000  decode.d3.loss_dice: 0.4003  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7064  decode.d4.loss_dice: 0.3859  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 0.3848  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.7207  decode.d6.loss_dice: 0.3905  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7227  decode.d7.loss_dice: 0.3880  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7111  decode.d8.loss_dice: 0.3924\n",
      "07/02 17:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18300/32000]  base_lr: 2.9128e-06 lr: 2.9128e-07  eta: 0:36:20  time: 0.1593  data_time: 0.0100  memory: 5153  grad_norm: 182.8252  loss: 13.9032  decode.loss_cls: 0.2315  decode.loss_mask: 0.7284  decode.loss_dice: 0.5038  decode.d0.loss_cls: 0.0392  decode.d0.loss_mask: 0.9494  decode.d0.loss_dice: 0.6478  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.7706  decode.d1.loss_dice: 0.5114  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.7351  decode.d2.loss_dice: 0.5038  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7367  decode.d3.loss_dice: 0.4864  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.7668  decode.d4.loss_dice: 0.4922  decode.d5.loss_cls: 0.1846  decode.d5.loss_mask: 0.7334  decode.d5.loss_dice: 0.5022  decode.d6.loss_cls: 0.2310  decode.d6.loss_mask: 0.7316  decode.d6.loss_dice: 0.4919  decode.d7.loss_cls: 0.2480  decode.d7.loss_mask: 0.7227  decode.d7.loss_dice: 0.4946  decode.d8.loss_cls: 0.2455  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 0.4888\n",
      "07/02 17:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18350/32000]  base_lr: 2.9032e-06 lr: 2.9032e-07  eta: 0:36:12  time: 0.1592  data_time: 0.0094  memory: 5153  grad_norm: 227.4263  loss: 12.0342  decode.loss_cls: 0.0005  decode.loss_mask: 0.7363  decode.loss_dice: 0.4367  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.8927  decode.d0.loss_dice: 0.5857  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.7452  decode.d1.loss_dice: 0.4637  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.7223  decode.d2.loss_dice: 0.4412  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7001  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.7134  decode.d4.loss_dice: 0.4497  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7216  decode.d5.loss_dice: 0.4328  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7348  decode.d6.loss_dice: 0.4378  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7392  decode.d7.loss_dice: 0.4345  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7319  decode.d8.loss_dice: 0.4289\n",
      "07/02 17:51:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18400/32000]  base_lr: 2.8936e-06 lr: 2.8936e-07  eta: 0:36:04  time: 0.1578  data_time: 0.0086  memory: 5154  grad_norm: 252.7863  loss: 16.3950  decode.loss_cls: 0.0006  decode.loss_mask: 0.9816  decode.loss_dice: 0.6014  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 1.2181  decode.d0.loss_dice: 0.8040  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 1.0259  decode.d1.loss_dice: 0.6388  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 1.0059  decode.d2.loss_dice: 0.6098  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.9657  decode.d3.loss_dice: 0.6022  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.9851  decode.d4.loss_dice: 0.6172  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.9450  decode.d5.loss_dice: 0.5823  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.9629  decode.d6.loss_dice: 0.5882  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.9821  decode.d7.loss_dice: 0.5946  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.9832  decode.d8.loss_dice: 0.5982\n",
      "07/02 17:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18450/32000]  base_lr: 2.8840e-06 lr: 2.8840e-07  eta: 0:35:56  time: 0.1592  data_time: 0.0102  memory: 5152  grad_norm: 189.2337  loss: 12.0266  decode.loss_cls: 0.0004  decode.loss_mask: 0.7203  decode.loss_dice: 0.4511  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.9174  decode.d0.loss_dice: 0.5813  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.7806  decode.d1.loss_dice: 0.4769  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.7221  decode.d2.loss_dice: 0.4447  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.6965  decode.d3.loss_dice: 0.4527  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7046  decode.d4.loss_dice: 0.4466  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7068  decode.d5.loss_dice: 0.4404  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7086  decode.d6.loss_dice: 0.4357  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7019  decode.d7.loss_dice: 0.4323  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7153  decode.d8.loss_dice: 0.4429\n",
      "07/02 17:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18500/32000]  base_lr: 2.8745e-06 lr: 2.8745e-07  eta: 0:35:48  time: 0.1588  data_time: 0.0098  memory: 5153  grad_norm: 220.1585  loss: 14.2573  decode.loss_cls: 0.0022  decode.loss_mask: 0.8363  decode.loss_dice: 0.5470  decode.d0.loss_cls: 0.1159  decode.d0.loss_mask: 1.0081  decode.d0.loss_dice: 0.6640  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.8677  decode.d1.loss_dice: 0.5608  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.8543  decode.d2.loss_dice: 0.5376  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.8432  decode.d3.loss_dice: 0.5348  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.8600  decode.d4.loss_dice: 0.5483  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.8306  decode.d5.loss_dice: 0.5321  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.8228  decode.d6.loss_dice: 0.5338  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.8151  decode.d7.loss_dice: 0.5298  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.8278  decode.d8.loss_dice: 0.5396\n",
      "07/02 17:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18550/32000]  base_lr: 2.8649e-06 lr: 2.8649e-07  eta: 0:35:40  time: 0.1594  data_time: 0.0096  memory: 5153  grad_norm: 169.3054  loss: 10.6889  decode.loss_cls: 0.0005  decode.loss_mask: 0.6297  decode.loss_dice: 0.3821  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.7882  decode.d0.loss_dice: 0.5634  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.6622  decode.d1.loss_dice: 0.4068  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.6583  decode.d2.loss_dice: 0.3971  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6452  decode.d3.loss_dice: 0.3838  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.6378  decode.d4.loss_dice: 0.3901  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.6212  decode.d5.loss_dice: 0.3945  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6358  decode.d6.loss_dice: 0.3836  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6271  decode.d7.loss_dice: 0.3889  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.6354  decode.d8.loss_dice: 0.3902\n",
      "07/02 17:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18600/32000]  base_lr: 2.8553e-06 lr: 2.8553e-07  eta: 0:35:32  time: 0.1558  data_time: 0.0087  memory: 5153  grad_norm: 118.9665  loss: 9.4418  decode.loss_cls: 0.0463  decode.loss_mask: 0.4663  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.0552  decode.d0.loss_mask: 0.6381  decode.d0.loss_dice: 0.4444  decode.d1.loss_cls: 0.1337  decode.d1.loss_mask: 0.5134  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.1840  decode.d2.loss_mask: 0.4788  decode.d2.loss_dice: 0.3205  decode.d3.loss_cls: 0.1821  decode.d3.loss_mask: 0.4869  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.1773  decode.d4.loss_mask: 0.4844  decode.d4.loss_dice: 0.3106  decode.d5.loss_cls: 0.1575  decode.d5.loss_mask: 0.4822  decode.d5.loss_dice: 0.3113  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 0.4729  decode.d6.loss_dice: 0.2994  decode.d7.loss_cls: 0.1162  decode.d7.loss_mask: 0.4719  decode.d7.loss_dice: 0.3026  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 0.3084\n",
      "07/02 17:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18650/32000]  base_lr: 2.8457e-06 lr: 2.8457e-07  eta: 0:35:24  time: 0.1579  data_time: 0.0091  memory: 5154  grad_norm: 152.3630  loss: 10.6068  decode.loss_cls: 0.0008  decode.loss_mask: 0.6385  decode.loss_dice: 0.3778  decode.d0.loss_cls: 0.0261  decode.d0.loss_mask: 0.8185  decode.d0.loss_dice: 0.4970  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.6765  decode.d1.loss_dice: 0.3995  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.6649  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.6451  decode.d3.loss_dice: 0.3689  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.6544  decode.d4.loss_dice: 0.3646  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.6365  decode.d5.loss_dice: 0.3655  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.6416  decode.d6.loss_dice: 0.3739  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6375  decode.d7.loss_dice: 0.3795  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6520  decode.d8.loss_dice: 0.3772\n",
      "07/02 17:52:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18700/32000]  base_lr: 2.8361e-06 lr: 2.8361e-07  eta: 0:35:16  time: 0.1597  data_time: 0.0100  memory: 5153  grad_norm: 208.5370  loss: 13.9157  decode.loss_cls: 0.0012  decode.loss_mask: 0.7796  decode.loss_dice: 0.5037  decode.d0.loss_cls: 0.0595  decode.d0.loss_mask: 1.0420  decode.d0.loss_dice: 0.6979  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.8653  decode.d1.loss_dice: 0.5482  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.8361  decode.d2.loss_dice: 0.5484  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.8314  decode.d3.loss_dice: 0.5341  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.8154  decode.d4.loss_dice: 0.5348  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.8057  decode.d5.loss_dice: 0.5212  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.8091  decode.d6.loss_dice: 0.5202  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.7935  decode.d7.loss_dice: 0.5163  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.7952  decode.d8.loss_dice: 0.5323\n",
      "07/02 17:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18750/32000]  base_lr: 2.8265e-06 lr: 2.8265e-07  eta: 0:35:08  time: 0.1562  data_time: 0.0086  memory: 5153  grad_norm: 200.7942  loss: 10.7826  decode.loss_cls: 0.0007  decode.loss_mask: 0.6037  decode.loss_dice: 0.4409  decode.d0.loss_cls: 0.0472  decode.d0.loss_mask: 0.7134  decode.d0.loss_dice: 0.5642  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.5971  decode.d1.loss_dice: 0.4483  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.5995  decode.d2.loss_dice: 0.4383  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.5877  decode.d3.loss_dice: 0.4312  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.6223  decode.d4.loss_dice: 0.4530  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 0.4397  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6114  decode.d6.loss_dice: 0.4356  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.6183  decode.d7.loss_dice: 0.4470  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6053  decode.d8.loss_dice: 0.4316\n",
      "07/02 17:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18800/32000]  base_lr: 2.8169e-06 lr: 2.8169e-07  eta: 0:35:00  time: 0.1567  data_time: 0.0087  memory: 5153  grad_norm: 251.1420  loss: 14.2388  decode.loss_cls: 0.3563  decode.loss_mask: 0.7982  decode.loss_dice: 0.4423  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.9756  decode.d0.loss_dice: 0.6075  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.8487  decode.d1.loss_dice: 0.4778  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.8055  decode.d2.loss_dice: 0.4982  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.7822  decode.d3.loss_dice: 0.4670  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 0.4474  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.8053  decode.d5.loss_dice: 0.4490  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 0.8343  decode.d6.loss_dice: 0.4537  decode.d7.loss_cls: 0.1464  decode.d7.loss_mask: 0.8426  decode.d7.loss_dice: 0.4390  decode.d8.loss_cls: 0.3625  decode.d8.loss_mask: 0.8082  decode.d8.loss_dice: 0.4486\n",
      "07/02 17:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18850/32000]  base_lr: 2.8073e-06 lr: 2.8073e-07  eta: 0:34:52  time: 0.1565  data_time: 0.0086  memory: 5153  grad_norm: 172.8228  loss: 13.4418  decode.loss_cls: 0.0006  decode.loss_mask: 0.8011  decode.loss_dice: 0.4768  decode.d0.loss_cls: 0.0337  decode.d0.loss_mask: 1.0539  decode.d0.loss_dice: 0.6367  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.8807  decode.d1.loss_dice: 0.5114  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.8608  decode.d2.loss_dice: 0.4677  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.8243  decode.d3.loss_dice: 0.4707  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7978  decode.d4.loss_dice: 0.4697  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7987  decode.d5.loss_dice: 0.4723  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8118  decode.d6.loss_dice: 0.4851  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8042  decode.d7.loss_dice: 0.4800  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8059  decode.d8.loss_dice: 0.4897\n",
      "07/02 17:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18900/32000]  base_lr: 2.7977e-06 lr: 2.7977e-07  eta: 0:34:44  time: 0.1562  data_time: 0.0084  memory: 5153  grad_norm: 196.0367  loss: 11.9240  decode.loss_cls: 0.0006  decode.loss_mask: 0.7004  decode.loss_dice: 0.4146  decode.d0.loss_cls: 0.0399  decode.d0.loss_mask: 0.8991  decode.d0.loss_dice: 0.5829  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7443  decode.d1.loss_dice: 0.4666  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.7326  decode.d2.loss_dice: 0.4338  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.7301  decode.d3.loss_dice: 0.4393  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 0.4348  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 0.4235  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7116  decode.d6.loss_dice: 0.4065  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7198  decode.d7.loss_dice: 0.4156  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7187  decode.d8.loss_dice: 0.4231\n",
      "07/02 17:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18950/32000]  base_lr: 2.7881e-06 lr: 2.7881e-07  eta: 0:34:36  time: 0.1563  data_time: 0.0084  memory: 5153  grad_norm: 191.1581  loss: 13.7017  decode.loss_cls: 0.0002  decode.loss_mask: 0.8200  decode.loss_dice: 0.4624  decode.d0.loss_cls: 0.0643  decode.d0.loss_mask: 1.0305  decode.d0.loss_dice: 0.6231  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.8442  decode.d1.loss_dice: 0.5085  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.9419  decode.d2.loss_dice: 0.5203  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.8379  decode.d3.loss_dice: 0.4659  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.8432  decode.d4.loss_dice: 0.4827  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.8234  decode.d5.loss_dice: 0.4809  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8408  decode.d6.loss_dice: 0.4798  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.8267  decode.d7.loss_dice: 0.4736  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.8270  decode.d8.loss_dice: 0.4678\n",
      "07/02 17:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19000/32000]  base_lr: 2.7785e-06 lr: 2.7785e-07  eta: 0:34:28  time: 0.1575  data_time: 0.0091  memory: 5154  grad_norm: 150.8539  loss: 12.5244  decode.loss_cls: 0.0005  decode.loss_mask: 0.7636  decode.loss_dice: 0.4443  decode.d0.loss_cls: 0.0441  decode.d0.loss_mask: 0.9025  decode.d0.loss_dice: 0.6200  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.7891  decode.d1.loss_dice: 0.4976  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.7607  decode.d2.loss_dice: 0.4713  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7410  decode.d3.loss_dice: 0.4499  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7402  decode.d4.loss_dice: 0.4534  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7823  decode.d5.loss_dice: 0.4643  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7633  decode.d6.loss_dice: 0.4433  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7553  decode.d7.loss_dice: 0.4415  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7477  decode.d8.loss_dice: 0.4406\n",
      "07/02 17:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0210  data_time: 0.0020  memory: 2168  \n",
      "07/02 17:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0286  data_time: 0.0060  memory: 1078  \n",
      "07/02 17:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 93.01 | 96.61 |\n",
      "|   lesion   | 79.95 | 88.21 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.5300  mIoU: 86.4800  mAcc: 92.4100  data_time: 0.0111  time: 0.0361\n",
      "07/02 17:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_17000.pth is removed\n",
      "07/02 17:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 86.4800 mIoU at 19000 iter is saved to best_mIoU_iter_19000.pth.\n",
      "07/02 17:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19050/32000]  base_lr: 2.7689e-06 lr: 2.7689e-07  eta: 0:34:21  time: 0.1549  data_time: 0.0071  memory: 5153  grad_norm: 173.7377  loss: 11.4564  decode.loss_cls: 0.0005  decode.loss_mask: 0.6021  decode.loss_dice: 0.4407  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.8760  decode.d0.loss_dice: 0.6370  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.6898  decode.d1.loss_dice: 0.5377  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.6392  decode.d2.loss_dice: 0.4745  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.6161  decode.d3.loss_dice: 0.4674  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6410  decode.d4.loss_dice: 0.4787  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.6140  decode.d5.loss_dice: 0.4686  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.6162  decode.d6.loss_dice: 0.4510  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 0.4538  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5977  decode.d8.loss_dice: 0.4375\n",
      "07/02 17:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19100/32000]  base_lr: 2.7592e-06 lr: 2.7592e-07  eta: 0:34:13  time: 0.1559  data_time: 0.0082  memory: 5153  grad_norm: 196.1880  loss: 13.9855  decode.loss_cls: 0.0034  decode.loss_mask: 0.8545  decode.loss_dice: 0.5082  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.9712  decode.d0.loss_dice: 0.6312  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.8252  decode.d1.loss_dice: 0.5299  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.8489  decode.d2.loss_dice: 0.5081  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.8495  decode.d3.loss_dice: 0.5433  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.8362  decode.d4.loss_dice: 0.5132  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.8501  decode.d5.loss_dice: 0.4999  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.8685  decode.d6.loss_dice: 0.5088  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.8548  decode.d7.loss_dice: 0.5184  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.8637  decode.d8.loss_dice: 0.5206\n",
      "07/02 17:53:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19150/32000]  base_lr: 2.7496e-06 lr: 2.7496e-07  eta: 0:34:05  time: 0.1555  data_time: 0.0078  memory: 5153  grad_norm: 148.9984  loss: 11.5321  decode.loss_cls: 0.0002  decode.loss_mask: 0.6819  decode.loss_dice: 0.4185  decode.d0.loss_cls: 0.0288  decode.d0.loss_mask: 0.8679  decode.d0.loss_dice: 0.5564  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.6890  decode.d1.loss_dice: 0.4461  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6956  decode.d2.loss_dice: 0.4245  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 0.4326  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6883  decode.d4.loss_dice: 0.4282  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6855  decode.d5.loss_dice: 0.4243  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6996  decode.d6.loss_dice: 0.4326  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6942  decode.d7.loss_dice: 0.4261  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6929  decode.d8.loss_dice: 0.4304\n",
      "07/02 17:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19200/32000]  base_lr: 2.7400e-06 lr: 2.7400e-07  eta: 0:33:57  time: 0.1580  data_time: 0.0088  memory: 5154  grad_norm: 199.7018  loss: 12.1035  decode.loss_cls: 0.0134  decode.loss_mask: 0.6990  decode.loss_dice: 0.4140  decode.d0.loss_cls: 0.1072  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 0.5397  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.7349  decode.d1.loss_dice: 0.4634  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.7371  decode.d2.loss_dice: 0.4532  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.7141  decode.d3.loss_dice: 0.4549  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.7383  decode.d4.loss_dice: 0.4502  decode.d5.loss_cls: 0.0814  decode.d5.loss_mask: 0.6827  decode.d5.loss_dice: 0.4279  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.6625  decode.d6.loss_dice: 0.4092  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.6716  decode.d7.loss_dice: 0.4098  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.6880  decode.d8.loss_dice: 0.4141\n",
      "07/02 17:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19250/32000]  base_lr: 2.7303e-06 lr: 2.7303e-07  eta: 0:33:49  time: 0.1579  data_time: 0.0089  memory: 5153  grad_norm: 263.0189  loss: 12.7757  decode.loss_cls: 0.0010  decode.loss_mask: 0.7629  decode.loss_dice: 0.4778  decode.d0.loss_cls: 0.0354  decode.d0.loss_mask: 0.8995  decode.d0.loss_dice: 0.5805  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.7782  decode.d1.loss_dice: 0.4750  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.7899  decode.d2.loss_dice: 0.4951  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.7825  decode.d3.loss_dice: 0.5019  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.7690  decode.d4.loss_dice: 0.4733  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.7787  decode.d5.loss_dice: 0.4677  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.7373  decode.d6.loss_dice: 0.4659  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.7719  decode.d7.loss_dice: 0.4734  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.7519  decode.d8.loss_dice: 0.4769\n",
      "07/02 17:53:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19300/32000]  base_lr: 2.7207e-06 lr: 2.7207e-07  eta: 0:33:41  time: 0.1563  data_time: 0.0080  memory: 5153  grad_norm: 130.2788  loss: 10.4674  decode.loss_cls: 0.0006  decode.loss_mask: 0.5757  decode.loss_dice: 0.3804  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.7707  decode.d0.loss_dice: 0.5897  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.6380  decode.d1.loss_dice: 0.4413  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 0.4179  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.6167  decode.d3.loss_dice: 0.4140  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.6176  decode.d4.loss_dice: 0.4123  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.5952  decode.d5.loss_dice: 0.3946  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.5918  decode.d6.loss_dice: 0.3898  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6043  decode.d7.loss_dice: 0.3993  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.5876  decode.d8.loss_dice: 0.3786\n",
      "07/02 17:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19350/32000]  base_lr: 2.7111e-06 lr: 2.7111e-07  eta: 0:33:33  time: 0.1562  data_time: 0.0083  memory: 5153  grad_norm: 174.4725  loss: 14.2092  decode.loss_cls: 0.2412  decode.loss_mask: 0.7579  decode.loss_dice: 0.4462  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.8405  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 0.7184  decode.d1.loss_dice: 0.4621  decode.d2.loss_cls: 0.1943  decode.d2.loss_mask: 0.7822  decode.d2.loss_dice: 0.4524  decode.d3.loss_cls: 0.1454  decode.d3.loss_mask: 0.7329  decode.d3.loss_dice: 0.4524  decode.d4.loss_cls: 0.2706  decode.d4.loss_mask: 0.7174  decode.d4.loss_dice: 0.4437  decode.d5.loss_cls: 0.2726  decode.d5.loss_mask: 0.7241  decode.d5.loss_dice: 0.4428  decode.d6.loss_cls: 0.2574  decode.d6.loss_mask: 0.7285  decode.d6.loss_dice: 0.4355  decode.d7.loss_cls: 0.2605  decode.d7.loss_mask: 0.7409  decode.d7.loss_dice: 0.4451  decode.d8.loss_cls: 0.2576  decode.d8.loss_mask: 0.7369  decode.d8.loss_dice: 0.4284\n",
      "07/02 17:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19400/32000]  base_lr: 2.7014e-06 lr: 2.7014e-07  eta: 0:33:25  time: 0.1556  data_time: 0.0078  memory: 5153  grad_norm: 133.9322  loss: 10.9027  decode.loss_cls: 0.0001  decode.loss_mask: 0.6415  decode.loss_dice: 0.3901  decode.d0.loss_cls: 0.0528  decode.d0.loss_mask: 0.8615  decode.d0.loss_dice: 0.5163  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.6949  decode.d1.loss_dice: 0.4234  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.6602  decode.d2.loss_dice: 0.3839  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.6527  decode.d3.loss_dice: 0.3894  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6712  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6508  decode.d5.loss_dice: 0.3946  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.6489  decode.d6.loss_dice: 0.3915  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6498  decode.d7.loss_dice: 0.3895  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6508  decode.d8.loss_dice: 0.3872\n",
      "07/02 17:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19450/32000]  base_lr: 2.6918e-06 lr: 2.6918e-07  eta: 0:33:17  time: 0.1584  data_time: 0.0086  memory: 5153  grad_norm: 228.3580  loss: 13.9574  decode.loss_cls: 0.0010  decode.loss_mask: 0.8464  decode.loss_dice: 0.4944  decode.d0.loss_cls: 0.0992  decode.d0.loss_mask: 1.0237  decode.d0.loss_dice: 0.6337  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.8914  decode.d1.loss_dice: 0.5338  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.9103  decode.d2.loss_dice: 0.5123  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 0.4949  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.8033  decode.d4.loss_dice: 0.4766  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.8259  decode.d5.loss_dice: 0.4956  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.8345  decode.d6.loss_dice: 0.4697  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.8840  decode.d7.loss_dice: 0.4833  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.8617  decode.d8.loss_dice: 0.4742\n",
      "07/02 17:54:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19500/32000]  base_lr: 2.6821e-06 lr: 2.6821e-07  eta: 0:33:09  time: 0.1585  data_time: 0.0087  memory: 5153  grad_norm: 280.0947  loss: 15.9544  decode.loss_cls: 0.1815  decode.loss_mask: 0.7874  decode.loss_dice: 0.5485  decode.d0.loss_cls: 0.1629  decode.d0.loss_mask: 0.9884  decode.d0.loss_dice: 0.7193  decode.d1.loss_cls: 0.1656  decode.d1.loss_mask: 0.8290  decode.d1.loss_dice: 0.6013  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.8726  decode.d2.loss_dice: 0.5925  decode.d3.loss_cls: 0.1255  decode.d3.loss_mask: 0.8659  decode.d3.loss_dice: 0.6114  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.8911  decode.d4.loss_dice: 0.6138  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.8455  decode.d5.loss_dice: 0.5922  decode.d6.loss_cls: 0.1649  decode.d6.loss_mask: 0.8337  decode.d6.loss_dice: 0.5584  decode.d7.loss_cls: 0.1564  decode.d7.loss_mask: 0.8068  decode.d7.loss_dice: 0.5677  decode.d8.loss_cls: 0.1950  decode.d8.loss_mask: 0.7935  decode.d8.loss_dice: 0.5446\n",
      "07/02 17:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19550/32000]  base_lr: 2.6725e-06 lr: 2.6725e-07  eta: 0:33:01  time: 0.1583  data_time: 0.0090  memory: 5153  grad_norm: 360.8209  loss: 16.5651  decode.loss_cls: 0.0011  decode.loss_mask: 1.0694  decode.loss_dice: 0.5679  decode.d0.loss_cls: 0.1075  decode.d0.loss_mask: 1.1751  decode.d0.loss_dice: 0.6858  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 1.0324  decode.d1.loss_dice: 0.6272  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.9671  decode.d2.loss_dice: 0.5789  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.9895  decode.d3.loss_dice: 0.5686  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 1.0261  decode.d4.loss_dice: 0.5694  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 1.0611  decode.d5.loss_dice: 0.5831  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 1.0194  decode.d6.loss_dice: 0.5830  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 1.0510  decode.d7.loss_dice: 0.5920  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 1.0475  decode.d8.loss_dice: 0.5805\n",
      "07/02 17:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19600/32000]  base_lr: 2.6628e-06 lr: 2.6628e-07  eta: 0:32:53  time: 0.1585  data_time: 0.0095  memory: 5153  grad_norm: 188.0912  loss: 13.3153  decode.loss_cls: 0.0010  decode.loss_mask: 0.7943  decode.loss_dice: 0.4622  decode.d0.loss_cls: 0.0276  decode.d0.loss_mask: 0.9877  decode.d0.loss_dice: 0.6595  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.8512  decode.d1.loss_dice: 0.5083  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.8275  decode.d2.loss_dice: 0.4941  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.8198  decode.d3.loss_dice: 0.5076  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8106  decode.d4.loss_dice: 0.4759  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.8037  decode.d5.loss_dice: 0.4874  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7898  decode.d6.loss_dice: 0.4638  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8050  decode.d7.loss_dice: 0.4704  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7967  decode.d8.loss_dice: 0.4636\n",
      "07/02 17:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19650/32000]  base_lr: 2.6531e-06 lr: 2.6531e-07  eta: 0:32:45  time: 0.1543  data_time: 0.0076  memory: 5154  grad_norm: 145.5062  loss: 10.1268  decode.loss_cls: 0.0003  decode.loss_mask: 0.5639  decode.loss_dice: 0.3888  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.7239  decode.d0.loss_dice: 0.5279  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.5919  decode.d1.loss_dice: 0.4318  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6041  decode.d2.loss_dice: 0.4180  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.6030  decode.d3.loss_dice: 0.4170  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5947  decode.d4.loss_dice: 0.4035  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5865  decode.d5.loss_dice: 0.4005  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5599  decode.d6.loss_dice: 0.3825  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5655  decode.d7.loss_dice: 0.3837  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5674  decode.d8.loss_dice: 0.3880\n",
      "07/02 17:54:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19700/32000]  base_lr: 2.6435e-06 lr: 2.6435e-07  eta: 0:32:37  time: 0.1550  data_time: 0.0079  memory: 5153  grad_norm: 167.3860  loss: 11.8305  decode.loss_cls: 0.0014  decode.loss_mask: 0.6615  decode.loss_dice: 0.4459  decode.d0.loss_cls: 0.0442  decode.d0.loss_mask: 0.8738  decode.d0.loss_dice: 0.6005  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.7226  decode.d1.loss_dice: 0.4761  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.6907  decode.d2.loss_dice: 0.4556  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.6948  decode.d3.loss_dice: 0.4651  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.6853  decode.d4.loss_dice: 0.4384  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.6952  decode.d5.loss_dice: 0.4585  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.6832  decode.d6.loss_dice: 0.4593  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.6843  decode.d7.loss_dice: 0.4551  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.6745  decode.d8.loss_dice: 0.4520\n",
      "07/02 17:55:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19750/32000]  base_lr: 2.6338e-06 lr: 2.6338e-07  eta: 0:32:29  time: 0.1563  data_time: 0.0089  memory: 5152  grad_norm: 158.8598  loss: 10.6111  decode.loss_cls: 0.0017  decode.loss_mask: 0.6445  decode.loss_dice: 0.3557  decode.d0.loss_cls: 0.0415  decode.d0.loss_mask: 0.8297  decode.d0.loss_dice: 0.5095  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.6762  decode.d1.loss_dice: 0.4156  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.6567  decode.d2.loss_dice: 0.3773  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.6628  decode.d3.loss_dice: 0.3803  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6654  decode.d4.loss_dice: 0.3698  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.6466  decode.d5.loss_dice: 0.3597  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.6339  decode.d6.loss_dice: 0.3617  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.6387  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.6474  decode.d8.loss_dice: 0.3591\n",
      "07/02 17:55:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19800/32000]  base_lr: 2.6241e-06 lr: 2.6241e-07  eta: 0:32:21  time: 0.1561  data_time: 0.0087  memory: 5153  grad_norm: 92.4626  loss: 7.3683  decode.loss_cls: 0.0003  decode.loss_mask: 0.4142  decode.loss_dice: 0.2663  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.6099  decode.d0.loss_dice: 0.4084  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.4423  decode.d1.loss_dice: 0.2972  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.4267  decode.d2.loss_dice: 0.2784  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.4251  decode.d3.loss_dice: 0.2711  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.4317  decode.d4.loss_dice: 0.2813  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.4349  decode.d5.loss_dice: 0.2731  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.4217  decode.d6.loss_dice: 0.2704  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.4193  decode.d7.loss_dice: 0.2715  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.4225  decode.d8.loss_dice: 0.2723\n",
      "07/02 17:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19850/32000]  base_lr: 2.6144e-06 lr: 2.6144e-07  eta: 0:32:13  time: 0.1570  data_time: 0.0095  memory: 5153  grad_norm: 275.3044  loss: 13.3270  decode.loss_cls: 0.0024  decode.loss_mask: 0.7914  decode.loss_dice: 0.4879  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 1.0070  decode.d0.loss_dice: 0.6438  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.7826  decode.d1.loss_dice: 0.4999  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.7982  decode.d2.loss_dice: 0.4933  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.8135  decode.d3.loss_dice: 0.4981  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.7929  decode.d4.loss_dice: 0.4729  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.8184  decode.d5.loss_dice: 0.5001  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7974  decode.d6.loss_dice: 0.4679  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7892  decode.d7.loss_dice: 0.4708  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 0.4823\n",
      "07/02 17:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19900/32000]  base_lr: 2.6047e-06 lr: 2.6047e-07  eta: 0:32:05  time: 0.1583  data_time: 0.0094  memory: 5153  grad_norm: 107.7579  loss: 9.1634  decode.loss_cls: 0.0002  decode.loss_mask: 0.5523  decode.loss_dice: 0.3367  decode.d0.loss_cls: 0.0208  decode.d0.loss_mask: 0.6910  decode.d0.loss_dice: 0.4553  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.5652  decode.d1.loss_dice: 0.3595  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.5561  decode.d2.loss_dice: 0.3401  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.5377  decode.d3.loss_dice: 0.3389  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5512  decode.d4.loss_dice: 0.3404  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5369  decode.d5.loss_dice: 0.3311  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5419  decode.d6.loss_dice: 0.3278  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.5505  decode.d7.loss_dice: 0.3287  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.5618  decode.d8.loss_dice: 0.3365\n",
      "07/02 17:55:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19950/32000]  base_lr: 2.5950e-06 lr: 2.5950e-07  eta: 0:31:57  time: 0.1586  data_time: 0.0088  memory: 5152  grad_norm: 155.9357  loss: 11.7100  decode.loss_cls: 0.0005  decode.loss_mask: 0.6725  decode.loss_dice: 0.4019  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.9525  decode.d0.loss_dice: 0.5771  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.7352  decode.d1.loss_dice: 0.4419  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7136  decode.d2.loss_dice: 0.4208  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.6969  decode.d3.loss_dice: 0.4203  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.7119  decode.d4.loss_dice: 0.4079  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.7252  decode.d5.loss_dice: 0.4281  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.7090  decode.d6.loss_dice: 0.4223  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6987  decode.d7.loss_dice: 0.4167  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.6888  decode.d8.loss_dice: 0.4089\n",
      "07/02 17:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20000/32000]  base_lr: 2.5854e-06 lr: 2.5854e-07  eta: 0:31:49  time: 0.1571  data_time: 0.0090  memory: 5154  grad_norm: 202.6370  loss: 15.6624  decode.loss_cls: 0.2484  decode.loss_mask: 0.8343  decode.loss_dice: 0.5181  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 1.0351  decode.d0.loss_dice: 0.6522  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.8375  decode.d1.loss_dice: 0.5351  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.8808  decode.d2.loss_dice: 0.5164  decode.d3.loss_cls: 0.2157  decode.d3.loss_mask: 0.8710  decode.d3.loss_dice: 0.5227  decode.d4.loss_cls: 0.2170  decode.d4.loss_mask: 0.8740  decode.d4.loss_dice: 0.5293  decode.d5.loss_cls: 0.2021  decode.d5.loss_mask: 0.8570  decode.d5.loss_dice: 0.5229  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 0.8398  decode.d6.loss_dice: 0.5038  decode.d7.loss_cls: 0.2586  decode.d7.loss_mask: 0.8205  decode.d7.loss_dice: 0.5017  decode.d8.loss_cls: 0.2604  decode.d8.loss_mask: 0.8291  decode.d8.loss_dice: 0.5090\n",
      "07/02 17:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20000 iterations\n",
      "07/02 17:55:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0210  data_time: 0.0020  memory: 2166  \n",
      "07/02 17:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0282  data_time: 0.0059  memory: 1078  \n",
      "07/02 17:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background |  91.8 | 94.37 |\n",
      "|   lesion   | 78.08 | 91.48 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.6600  mIoU: 84.9400  mAcc: 92.9200  data_time: 0.0110  time: 0.0359\n",
      "07/02 17:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20050/32000]  base_lr: 2.5757e-06 lr: 2.5757e-07  eta: 0:31:41  time: 0.1545  data_time: 0.0075  memory: 5153  grad_norm: 180.4346  loss: 13.2523  decode.loss_cls: 0.0004  decode.loss_mask: 0.7730  decode.loss_dice: 0.5021  decode.d0.loss_cls: 0.0592  decode.d0.loss_mask: 0.9797  decode.d0.loss_dice: 0.6251  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.8384  decode.d1.loss_dice: 0.5422  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.7780  decode.d2.loss_dice: 0.5263  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7785  decode.d3.loss_dice: 0.5170  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7667  decode.d4.loss_dice: 0.5051  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7609  decode.d5.loss_dice: 0.5071  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7574  decode.d6.loss_dice: 0.4952  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.7639  decode.d7.loss_dice: 0.5005  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7608  decode.d8.loss_dice: 0.5055\n",
      "07/02 17:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20100/32000]  base_lr: 2.5660e-06 lr: 2.5660e-07  eta: 0:31:33  time: 0.1561  data_time: 0.0083  memory: 5153  grad_norm: 190.7871  loss: 14.5150  decode.loss_cls: 0.0005  decode.loss_mask: 0.8889  decode.loss_dice: 0.5127  decode.d0.loss_cls: 0.0513  decode.d0.loss_mask: 1.1005  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.9317  decode.d1.loss_dice: 0.5396  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.9308  decode.d2.loss_dice: 0.5189  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.9132  decode.d3.loss_dice: 0.5152  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.8988  decode.d4.loss_dice: 0.5011  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.9226  decode.d5.loss_dice: 0.5205  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8800  decode.d6.loss_dice: 0.5033  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.8665  decode.d7.loss_dice: 0.4970  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.8736  decode.d8.loss_dice: 0.4992\n",
      "07/02 17:56:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20150/32000]  base_lr: 2.5563e-06 lr: 2.5563e-07  eta: 0:31:25  time: 0.1550  data_time: 0.0077  memory: 5153  grad_norm: 204.7698  loss: 13.8934  decode.loss_cls: 0.0009  decode.loss_mask: 0.8231  decode.loss_dice: 0.5185  decode.d0.loss_cls: 0.1087  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 0.6239  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.8535  decode.d1.loss_dice: 0.5637  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.8041  decode.d2.loss_dice: 0.5096  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.8171  decode.d3.loss_dice: 0.5139  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.8271  decode.d4.loss_dice: 0.5255  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.8471  decode.d5.loss_dice: 0.5288  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.8224  decode.d6.loss_dice: 0.5117  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.8350  decode.d7.loss_dice: 0.5173  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.8191  decode.d8.loss_dice: 0.5044\n",
      "07/02 17:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20200/32000]  base_lr: 2.5465e-06 lr: 2.5465e-07  eta: 0:31:17  time: 0.1558  data_time: 0.0079  memory: 5153  grad_norm: 180.8570  loss: 12.3995  decode.loss_cls: 0.0046  decode.loss_mask: 0.6557  decode.loss_dice: 0.4661  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.8930  decode.d0.loss_dice: 0.6467  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.7103  decode.d1.loss_dice: 0.5238  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.7978  decode.d2.loss_dice: 0.5318  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.6931  decode.d3.loss_dice: 0.4886  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.6866  decode.d4.loss_dice: 0.4879  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.6974  decode.d5.loss_dice: 0.4975  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.6808  decode.d6.loss_dice: 0.4780  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.6776  decode.d7.loss_dice: 0.4787  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.6510  decode.d8.loss_dice: 0.4627\n",
      "07/02 17:56:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20250/32000]  base_lr: 2.5368e-06 lr: 2.5368e-07  eta: 0:31:09  time: 0.1569  data_time: 0.0079  memory: 5152  grad_norm: 148.4750  loss: 10.6816  decode.loss_cls: 0.0005  decode.loss_mask: 0.6093  decode.loss_dice: 0.4213  decode.d0.loss_cls: 0.0549  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 0.5626  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.6401  decode.d1.loss_dice: 0.4400  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.6080  decode.d2.loss_dice: 0.4157  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.6115  decode.d3.loss_dice: 0.4140  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.5999  decode.d4.loss_dice: 0.4170  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6057  decode.d5.loss_dice: 0.4208  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 0.4150  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6074  decode.d7.loss_dice: 0.4114  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.6099  decode.d8.loss_dice: 0.4211\n",
      "07/02 17:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20300/32000]  base_lr: 2.5271e-06 lr: 2.5271e-07  eta: 0:31:01  time: 0.1585  data_time: 0.0088  memory: 5153  grad_norm: 190.2651  loss: 12.1976  decode.loss_cls: 0.0002  decode.loss_mask: 0.7320  decode.loss_dice: 0.4453  decode.d0.loss_cls: 0.0198  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 0.6134  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.7637  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.7424  decode.d2.loss_dice: 0.4618  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.7272  decode.d3.loss_dice: 0.4609  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.7096  decode.d4.loss_dice: 0.4470  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7244  decode.d5.loss_dice: 0.4444  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.7210  decode.d6.loss_dice: 0.4304  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7224  decode.d7.loss_dice: 0.4429  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7292  decode.d8.loss_dice: 0.4396\n",
      "07/02 17:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20350/32000]  base_lr: 2.5174e-06 lr: 2.5174e-07  eta: 0:30:53  time: 0.1592  data_time: 0.0096  memory: 5153  grad_norm: 202.8787  loss: 10.6795  decode.loss_cls: 0.0009  decode.loss_mask: 0.6065  decode.loss_dice: 0.4084  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.8006  decode.d0.loss_dice: 0.5800  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.6456  decode.d1.loss_dice: 0.4434  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.6206  decode.d2.loss_dice: 0.4368  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.6305  decode.d3.loss_dice: 0.4320  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.5843  decode.d4.loss_dice: 0.3947  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.6110  decode.d5.loss_dice: 0.3949  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.5837  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6067  decode.d7.loss_dice: 0.4043  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6074  decode.d8.loss_dice: 0.4046\n",
      "07/02 17:56:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20400/32000]  base_lr: 2.5077e-06 lr: 2.5077e-07  eta: 0:30:45  time: 0.1580  data_time: 0.0090  memory: 5152  grad_norm: 162.4255  loss: 12.8902  decode.loss_cls: 0.0012  decode.loss_mask: 0.7448  decode.loss_dice: 0.4898  decode.d0.loss_cls: 0.0468  decode.d0.loss_mask: 0.8800  decode.d0.loss_dice: 0.6016  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.7723  decode.d1.loss_dice: 0.5232  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.7944  decode.d2.loss_dice: 0.5579  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 0.5201  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.7444  decode.d4.loss_dice: 0.5154  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7211  decode.d5.loss_dice: 0.4921  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.7525  decode.d6.loss_dice: 0.4993  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7401  decode.d7.loss_dice: 0.4941  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7388  decode.d8.loss_dice: 0.5030\n",
      "07/02 17:56:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20450/32000]  base_lr: 2.4979e-06 lr: 2.4979e-07  eta: 0:30:37  time: 0.1573  data_time: 0.0086  memory: 5153  grad_norm: 171.1025  loss: 12.4720  decode.loss_cls: 0.0007  decode.loss_mask: 0.7342  decode.loss_dice: 0.4732  decode.d0.loss_cls: 0.0161  decode.d0.loss_mask: 0.9207  decode.d0.loss_dice: 0.6040  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7698  decode.d1.loss_dice: 0.4859  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7599  decode.d2.loss_dice: 0.4716  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7488  decode.d3.loss_dice: 0.4768  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7364  decode.d4.loss_dice: 0.4703  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7253  decode.d5.loss_dice: 0.4734  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7226  decode.d6.loss_dice: 0.4601  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7282  decode.d7.loss_dice: 0.4734  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7397  decode.d8.loss_dice: 0.4748\n",
      "07/02 17:57:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20500/32000]  base_lr: 2.4882e-06 lr: 2.4882e-07  eta: 0:30:29  time: 0.1556  data_time: 0.0084  memory: 5154  grad_norm: 181.9723  loss: 13.2706  decode.loss_cls: 0.0006  decode.loss_mask: 0.8132  decode.loss_dice: 0.4771  decode.d0.loss_cls: 0.0579  decode.d0.loss_mask: 0.9233  decode.d0.loss_dice: 0.6161  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.8428  decode.d1.loss_dice: 0.5254  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.8132  decode.d2.loss_dice: 0.5045  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.8162  decode.d3.loss_dice: 0.4995  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.8066  decode.d4.loss_dice: 0.4855  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.8026  decode.d5.loss_dice: 0.4863  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.8057  decode.d6.loss_dice: 0.4866  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 0.4626  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7936  decode.d8.loss_dice: 0.4682\n",
      "07/02 17:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20550/32000]  base_lr: 2.4785e-06 lr: 2.4785e-07  eta: 0:30:21  time: 0.1572  data_time: 0.0088  memory: 5153  grad_norm: 335.2926  loss: 15.8081  decode.loss_cls: 0.0011  decode.loss_mask: 0.9614  decode.loss_dice: 0.5627  decode.d0.loss_cls: 0.1328  decode.d0.loss_mask: 1.0279  decode.d0.loss_dice: 0.6334  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 1.0116  decode.d1.loss_dice: 0.6049  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.9496  decode.d2.loss_dice: 0.5678  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.9615  decode.d3.loss_dice: 0.5694  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 1.0051  decode.d4.loss_dice: 0.5828  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.9920  decode.d5.loss_dice: 0.5687  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.9688  decode.d6.loss_dice: 0.5696  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.9794  decode.d7.loss_dice: 0.5671  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.9805  decode.d8.loss_dice: 0.5587\n",
      "07/02 17:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20600/32000]  base_lr: 2.4687e-06 lr: 2.4687e-07  eta: 0:30:13  time: 0.1563  data_time: 0.0090  memory: 5153  grad_norm: 249.3231  loss: 14.4214  decode.loss_cls: 0.0016  decode.loss_mask: 0.8708  decode.loss_dice: 0.5103  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 1.1188  decode.d0.loss_dice: 0.6541  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.9536  decode.d1.loss_dice: 0.5408  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.8751  decode.d2.loss_dice: 0.5049  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.8496  decode.d3.loss_dice: 0.4949  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.8699  decode.d4.loss_dice: 0.5111  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.8956  decode.d5.loss_dice: 0.5203  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.8904  decode.d6.loss_dice: 0.4938  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.8986  decode.d7.loss_dice: 0.5021  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.8971  decode.d8.loss_dice: 0.5047\n",
      "07/02 17:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20650/32000]  base_lr: 2.4590e-06 lr: 2.4590e-07  eta: 0:30:05  time: 0.1557  data_time: 0.0087  memory: 5154  grad_norm: 156.1310  loss: 11.0363  decode.loss_cls: 0.0007  decode.loss_mask: 0.6511  decode.loss_dice: 0.4059  decode.d0.loss_cls: 0.0383  decode.d0.loss_mask: 0.7959  decode.d0.loss_dice: 0.5276  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.6780  decode.d1.loss_dice: 0.4428  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.6820  decode.d2.loss_dice: 0.4250  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.6554  decode.d3.loss_dice: 0.4177  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.6676  decode.d4.loss_dice: 0.4065  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.6554  decode.d5.loss_dice: 0.4056  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6490  decode.d6.loss_dice: 0.4016  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.6551  decode.d7.loss_dice: 0.4035  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6590  decode.d8.loss_dice: 0.4056\n",
      "07/02 17:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20700/32000]  base_lr: 2.4492e-06 lr: 2.4492e-07  eta: 0:29:57  time: 0.1570  data_time: 0.0091  memory: 5153  grad_norm: 223.3946  loss: 14.7382  decode.loss_cls: 0.0020  decode.loss_mask: 0.8854  decode.loss_dice: 0.5239  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 1.0799  decode.d0.loss_dice: 0.6698  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.9255  decode.d1.loss_dice: 0.5527  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.9317  decode.d2.loss_dice: 0.5556  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.9194  decode.d3.loss_dice: 0.5464  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.8971  decode.d4.loss_dice: 0.5384  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.8926  decode.d5.loss_dice: 0.5367  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.9076  decode.d6.loss_dice: 0.5185  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.8709  decode.d7.loss_dice: 0.5085  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.8870  decode.d8.loss_dice: 0.5065\n",
      "07/02 17:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20750/32000]  base_lr: 2.4395e-06 lr: 2.4395e-07  eta: 0:29:49  time: 0.1586  data_time: 0.0093  memory: 5153  grad_norm: 199.5040  loss: 12.6276  decode.loss_cls: 0.0004  decode.loss_mask: 0.7392  decode.loss_dice: 0.4680  decode.d0.loss_cls: 0.0848  decode.d0.loss_mask: 0.8926  decode.d0.loss_dice: 0.6053  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.8046  decode.d1.loss_dice: 0.5322  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.7631  decode.d2.loss_dice: 0.4887  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.7249  decode.d3.loss_dice: 0.4536  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7336  decode.d4.loss_dice: 0.4653  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7330  decode.d5.loss_dice: 0.4624  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7433  decode.d6.loss_dice: 0.4720  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7558  decode.d7.loss_dice: 0.4895  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7386  decode.d8.loss_dice: 0.4702\n",
      "07/02 17:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20800/32000]  base_lr: 2.4297e-06 lr: 2.4297e-07  eta: 0:29:41  time: 0.1578  data_time: 0.0093  memory: 5153  grad_norm: 287.5015  loss: 17.3712  decode.loss_cls: 0.0039  decode.loss_mask: 0.9939  decode.loss_dice: 0.6517  decode.d0.loss_cls: 0.1389  decode.d0.loss_mask: 1.2182  decode.d0.loss_dice: 0.7936  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 1.0771  decode.d1.loss_dice: 0.6978  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 1.0341  decode.d2.loss_dice: 0.6624  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 1.0194  decode.d3.loss_dice: 0.6783  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.9982  decode.d4.loss_dice: 0.6535  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 1.0007  decode.d5.loss_dice: 0.6497  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 1.0220  decode.d6.loss_dice: 0.6791  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 1.0052  decode.d7.loss_dice: 0.6498  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 1.0231  decode.d8.loss_dice: 0.6809\n",
      "07/02 17:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20850/32000]  base_lr: 2.4199e-06 lr: 2.4199e-07  eta: 0:29:33  time: 0.1571  data_time: 0.0086  memory: 5153  grad_norm: 88.7877  loss: 9.0244  decode.loss_cls: 0.0002  decode.loss_mask: 0.5175  decode.loss_dice: 0.3377  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.6512  decode.d0.loss_dice: 0.4850  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.5696  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.5132  decode.d2.loss_dice: 0.3517  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.5207  decode.d3.loss_dice: 0.3633  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.5247  decode.d4.loss_dice: 0.3571  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.5304  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.5044  decode.d6.loss_dice: 0.3391  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5105  decode.d7.loss_dice: 0.3366  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5153  decode.d8.loss_dice: 0.3415\n",
      "07/02 17:58:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20900/32000]  base_lr: 2.4102e-06 lr: 2.4102e-07  eta: 0:29:25  time: 0.1598  data_time: 0.0107  memory: 5153  grad_norm: 206.6110  loss: 12.5826  decode.loss_cls: 0.0005  decode.loss_mask: 0.7678  decode.loss_dice: 0.4780  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.8722  decode.d0.loss_dice: 0.5861  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.8079  decode.d1.loss_dice: 0.5166  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.7415  decode.d2.loss_dice: 0.4862  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 0.4691  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7357  decode.d4.loss_dice: 0.4576  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7381  decode.d5.loss_dice: 0.4647  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7435  decode.d6.loss_dice: 0.4445  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7505  decode.d7.loss_dice: 0.4552  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7599  decode.d8.loss_dice: 0.4692\n",
      "07/02 17:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20950/32000]  base_lr: 2.4004e-06 lr: 2.4004e-07  eta: 0:29:17  time: 0.1582  data_time: 0.0097  memory: 5153  grad_norm: 93.7094  loss: 8.8388  decode.loss_cls: 0.0002  decode.loss_mask: 0.5427  decode.loss_dice: 0.3062  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.6806  decode.d0.loss_dice: 0.4284  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.5475  decode.d1.loss_dice: 0.3166  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.5570  decode.d2.loss_dice: 0.3065  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.5572  decode.d3.loss_dice: 0.3065  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.5404  decode.d4.loss_dice: 0.3095  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5525  decode.d5.loss_dice: 0.3134  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5402  decode.d6.loss_dice: 0.3107  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.5442  decode.d7.loss_dice: 0.3081  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5367  decode.d8.loss_dice: 0.3085\n",
      "07/02 17:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 17:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21000/32000]  base_lr: 2.3906e-06 lr: 2.3906e-07  eta: 0:29:09  time: 0.1575  data_time: 0.0089  memory: 5153  grad_norm: 175.2232  loss: 11.1612  decode.loss_cls: 0.0030  decode.loss_mask: 0.6425  decode.loss_dice: 0.4593  decode.d0.loss_cls: 0.0310  decode.d0.loss_mask: 0.7580  decode.d0.loss_dice: 0.5540  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.6301  decode.d1.loss_dice: 0.4548  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6392  decode.d2.loss_dice: 0.4516  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.6400  decode.d3.loss_dice: 0.4533  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6418  decode.d4.loss_dice: 0.4536  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6395  decode.d5.loss_dice: 0.4345  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.6421  decode.d6.loss_dice: 0.4454  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.6268  decode.d7.loss_dice: 0.4606  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.6326  decode.d8.loss_dice: 0.4524\n",
      "07/02 17:58:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0217  data_time: 0.0023  memory: 2167  \n",
      "07/02 17:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0289  data_time: 0.0061  memory: 1078  \n",
      "07/02 17:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 17:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.46 | 94.95 |\n",
      "|   lesion   | 79.56 | 91.79 |\n",
      "+------------+-------+-------+\n",
      "07/02 17:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.1700  mIoU: 86.0100  mAcc: 93.3700  data_time: 0.0113  time: 0.0367\n",
      "07/02 17:58:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21050/32000]  base_lr: 2.3808e-06 lr: 2.3808e-07  eta: 0:29:01  time: 0.1596  data_time: 0.0097  memory: 5153  grad_norm: 208.2662  loss: 13.6348  decode.loss_cls: 0.0033  decode.loss_mask: 0.7490  decode.loss_dice: 0.5151  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.8453  decode.d0.loss_dice: 0.6822  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.7731  decode.d1.loss_dice: 0.5597  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.7764  decode.d2.loss_dice: 0.5800  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.7755  decode.d3.loss_dice: 0.5801  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.7795  decode.d4.loss_dice: 0.5936  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.8128  decode.d5.loss_dice: 0.6026  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.7569  decode.d6.loss_dice: 0.5600  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.7452  decode.d7.loss_dice: 0.5587  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.7561  decode.d8.loss_dice: 0.5252\n",
      "07/02 17:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21100/32000]  base_lr: 2.3711e-06 lr: 2.3711e-07  eta: 0:28:53  time: 0.1618  data_time: 0.0101  memory: 5153  grad_norm: 296.3607  loss: 13.8572  decode.loss_cls: 0.0011  decode.loss_mask: 0.7995  decode.loss_dice: 0.4714  decode.d0.loss_cls: 0.0788  decode.d0.loss_mask: 0.8948  decode.d0.loss_dice: 0.5612  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.9064  decode.d1.loss_dice: 0.5675  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.8201  decode.d2.loss_dice: 0.5469  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.9360  decode.d3.loss_dice: 0.5304  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.9217  decode.d4.loss_dice: 0.5300  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.8789  decode.d5.loss_dice: 0.5204  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.8106  decode.d6.loss_dice: 0.4693  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.8058  decode.d7.loss_dice: 0.4665  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.8064  decode.d8.loss_dice: 0.4626\n",
      "07/02 17:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21150/32000]  base_lr: 2.3613e-06 lr: 2.3613e-07  eta: 0:28:45  time: 0.1603  data_time: 0.0096  memory: 5153  grad_norm: 181.2892  loss: 11.6623  decode.loss_cls: 0.0003  decode.loss_mask: 0.7072  decode.loss_dice: 0.4091  decode.d0.loss_cls: 0.0303  decode.d0.loss_mask: 0.9150  decode.d0.loss_dice: 0.5675  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.7069  decode.d1.loss_dice: 0.4265  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.7161  decode.d2.loss_dice: 0.4133  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.7105  decode.d3.loss_dice: 0.4051  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.7083  decode.d4.loss_dice: 0.4117  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7330  decode.d5.loss_dice: 0.4171  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7100  decode.d6.loss_dice: 0.4068  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7215  decode.d7.loss_dice: 0.4116  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.7187  decode.d8.loss_dice: 0.4105\n",
      "07/02 17:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21200/32000]  base_lr: 2.3515e-06 lr: 2.3515e-07  eta: 0:28:37  time: 0.1602  data_time: 0.0096  memory: 5153  grad_norm: 164.8812  loss: 11.8054  decode.loss_cls: 0.0045  decode.loss_mask: 0.6701  decode.loss_dice: 0.4530  decode.d0.loss_cls: 0.1109  decode.d0.loss_mask: 0.8657  decode.d0.loss_dice: 0.6121  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.7282  decode.d1.loss_dice: 0.4962  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.6962  decode.d2.loss_dice: 0.4741  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.6351  decode.d3.loss_dice: 0.4404  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.6621  decode.d4.loss_dice: 0.4393  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.6443  decode.d5.loss_dice: 0.4453  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.6780  decode.d6.loss_dice: 0.4571  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.6655  decode.d7.loss_dice: 0.4477  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.6643  decode.d8.loss_dice: 0.4491\n",
      "07/02 17:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21250/32000]  base_lr: 2.3417e-06 lr: 2.3417e-07  eta: 0:28:29  time: 0.1662  data_time: 0.0107  memory: 5153  grad_norm: 182.4368  loss: 13.5444  decode.loss_cls: 0.0007  decode.loss_mask: 0.7873  decode.loss_dice: 0.5222  decode.d0.loss_cls: 0.0621  decode.d0.loss_mask: 0.8874  decode.d0.loss_dice: 0.6676  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.8017  decode.d1.loss_dice: 0.5716  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.8181  decode.d2.loss_dice: 0.5179  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7842  decode.d3.loss_dice: 0.5280  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7909  decode.d4.loss_dice: 0.5392  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.8037  decode.d5.loss_dice: 0.5374  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7791  decode.d6.loss_dice: 0.5193  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7808  decode.d7.loss_dice: 0.5238  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7856  decode.d8.loss_dice: 0.5293\n",
      "07/02 17:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21300/32000]  base_lr: 2.3319e-06 lr: 2.3319e-07  eta: 0:28:21  time: 0.1578  data_time: 0.0092  memory: 5154  grad_norm: 176.6198  loss: 13.2341  decode.loss_cls: 0.0005  decode.loss_mask: 0.7738  decode.loss_dice: 0.4527  decode.d0.loss_cls: 0.0407  decode.d0.loss_mask: 1.0637  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.8574  decode.d1.loss_dice: 0.4651  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.8261  decode.d2.loss_dice: 0.4964  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.8024  decode.d3.loss_dice: 0.4756  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 0.4724  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.7850  decode.d5.loss_dice: 0.4688  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.7962  decode.d6.loss_dice: 0.4875  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.7869  decode.d7.loss_dice: 0.4744  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7742  decode.d8.loss_dice: 0.4708\n",
      "07/02 17:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21350/32000]  base_lr: 2.3221e-06 lr: 2.3221e-07  eta: 0:28:13  time: 0.1574  data_time: 0.0089  memory: 5153  grad_norm: 237.6647  loss: 13.4007  decode.loss_cls: 0.0012  decode.loss_mask: 0.7558  decode.loss_dice: 0.4892  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 1.0517  decode.d0.loss_dice: 0.6743  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.8117  decode.d1.loss_dice: 0.5228  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.8185  decode.d2.loss_dice: 0.5126  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.8017  decode.d3.loss_dice: 0.5184  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.7531  decode.d4.loss_dice: 0.5183  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.7768  decode.d5.loss_dice: 0.5158  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7525  decode.d6.loss_dice: 0.5030  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.7619  decode.d7.loss_dice: 0.4993  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.7582  decode.d8.loss_dice: 0.4871\n",
      "07/02 17:59:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21400/32000]  base_lr: 2.3122e-06 lr: 2.3122e-07  eta: 0:28:06  time: 0.1595  data_time: 0.0097  memory: 5153  grad_norm: 179.4089  loss: 10.8182  decode.loss_cls: 0.0004  decode.loss_mask: 0.6267  decode.loss_dice: 0.4052  decode.d0.loss_cls: 0.0455  decode.d0.loss_mask: 0.8166  decode.d0.loss_dice: 0.5341  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.6600  decode.d1.loss_dice: 0.4274  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.6490  decode.d2.loss_dice: 0.4203  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6473  decode.d3.loss_dice: 0.4067  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6481  decode.d4.loss_dice: 0.4201  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6301  decode.d5.loss_dice: 0.4060  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6158  decode.d6.loss_dice: 0.3996  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6288  decode.d7.loss_dice: 0.4082  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6113  decode.d8.loss_dice: 0.4074\n",
      "07/02 17:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21450/32000]  base_lr: 2.3024e-06 lr: 2.3024e-07  eta: 0:27:58  time: 0.1586  data_time: 0.0096  memory: 5153  grad_norm: 155.7578  loss: 12.8552  decode.loss_cls: 0.0005  decode.loss_mask: 0.7656  decode.loss_dice: 0.4374  decode.d0.loss_cls: 0.0168  decode.d0.loss_mask: 1.0037  decode.d0.loss_dice: 0.6368  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 0.5086  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.8073  decode.d2.loss_dice: 0.4753  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.7835  decode.d3.loss_dice: 0.4627  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.7816  decode.d4.loss_dice: 0.4695  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 0.4562  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7688  decode.d6.loss_dice: 0.4418  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7700  decode.d7.loss_dice: 0.4488  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7638  decode.d8.loss_dice: 0.4478\n",
      "07/02 17:59:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21500/32000]  base_lr: 2.2926e-06 lr: 2.2926e-07  eta: 0:27:50  time: 0.1585  data_time: 0.0095  memory: 5153  grad_norm: 342.2508  loss: 16.4713  decode.loss_cls: 0.0096  decode.loss_mask: 1.0207  decode.loss_dice: 0.5630  decode.d0.loss_cls: 0.1696  decode.d0.loss_mask: 1.1069  decode.d0.loss_dice: 0.6857  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 1.0107  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.9857  decode.d2.loss_dice: 0.6089  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 1.0018  decode.d3.loss_dice: 0.5951  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.9818  decode.d4.loss_dice: 0.5980  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.9823  decode.d5.loss_dice: 0.5901  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 1.0056  decode.d6.loss_dice: 0.5830  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.9731  decode.d7.loss_dice: 0.5728  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 1.0035  decode.d8.loss_dice: 0.5892\n",
      "07/02 17:59:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21550/32000]  base_lr: 2.2828e-06 lr: 2.2828e-07  eta: 0:27:42  time: 0.1600  data_time: 0.0107  memory: 5153  grad_norm: 160.9810  loss: 12.9125  decode.loss_cls: 0.0011  decode.loss_mask: 0.7711  decode.loss_dice: 0.4531  decode.d0.loss_cls: 0.0363  decode.d0.loss_mask: 1.0088  decode.d0.loss_dice: 0.5875  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.8281  decode.d1.loss_dice: 0.5050  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.8148  decode.d2.loss_dice: 0.4820  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.7604  decode.d3.loss_dice: 0.4611  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.7721  decode.d4.loss_dice: 0.4658  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.7862  decode.d5.loss_dice: 0.4601  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7867  decode.d6.loss_dice: 0.4599  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7748  decode.d7.loss_dice: 0.4625  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7713  decode.d8.loss_dice: 0.4580\n",
      "07/02 18:00:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21600/32000]  base_lr: 2.2729e-06 lr: 2.2729e-07  eta: 0:27:34  time: 0.1560  data_time: 0.0083  memory: 5154  grad_norm: 167.4487  loss: 11.3062  decode.loss_cls: 0.0028  decode.loss_mask: 0.6420  decode.loss_dice: 0.4297  decode.d0.loss_cls: 0.0627  decode.d0.loss_mask: 0.7807  decode.d0.loss_dice: 0.5839  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.6507  decode.d1.loss_dice: 0.4463  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.6913  decode.d2.loss_dice: 0.4462  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.6463  decode.d3.loss_dice: 0.4223  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.6628  decode.d4.loss_dice: 0.4413  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.6539  decode.d5.loss_dice: 0.4320  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.4450  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.6638  decode.d7.loss_dice: 0.4397  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.6497  decode.d8.loss_dice: 0.4310\n",
      "07/02 18:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21650/32000]  base_lr: 2.2631e-06 lr: 2.2631e-07  eta: 0:27:26  time: 0.1602  data_time: 0.0089  memory: 5152  grad_norm: 165.1276  loss: 14.6548  decode.loss_cls: 0.2509  decode.loss_mask: 0.7782  decode.loss_dice: 0.4727  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 0.7652  decode.d0.loss_dice: 0.5643  decode.d1.loss_cls: 0.2927  decode.d1.loss_mask: 0.7596  decode.d1.loss_dice: 0.5029  decode.d2.loss_cls: 0.2331  decode.d2.loss_mask: 0.7696  decode.d2.loss_dice: 0.4923  decode.d3.loss_cls: 0.2773  decode.d3.loss_mask: 0.7863  decode.d3.loss_dice: 0.4610  decode.d4.loss_cls: 0.2757  decode.d4.loss_mask: 0.7984  decode.d4.loss_dice: 0.4666  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.6557  decode.d5.loss_dice: 0.4875  decode.d6.loss_cls: 0.2586  decode.d6.loss_mask: 0.7742  decode.d6.loss_dice: 0.4694  decode.d7.loss_cls: 0.2503  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 0.4638  decode.d8.loss_cls: 0.2496  decode.d8.loss_mask: 0.7809  decode.d8.loss_dice: 0.4697\n",
      "07/02 18:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21700/32000]  base_lr: 2.2533e-06 lr: 2.2533e-07  eta: 0:27:18  time: 0.1587  data_time: 0.0091  memory: 5153  grad_norm: 185.0816  loss: 11.8807  decode.loss_cls: 0.0005  decode.loss_mask: 0.7139  decode.loss_dice: 0.4201  decode.d0.loss_cls: 0.0438  decode.d0.loss_mask: 0.9010  decode.d0.loss_dice: 0.5814  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.7395  decode.d1.loss_dice: 0.4430  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7288  decode.d2.loss_dice: 0.4353  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7231  decode.d3.loss_dice: 0.4350  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7139  decode.d4.loss_dice: 0.4253  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7148  decode.d5.loss_dice: 0.4328  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.7126  decode.d6.loss_dice: 0.4236  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7176  decode.d7.loss_dice: 0.4317  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7091  decode.d8.loss_dice: 0.4246\n",
      "07/02 18:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21750/32000]  base_lr: 2.2434e-06 lr: 2.2434e-07  eta: 0:27:10  time: 0.1592  data_time: 0.0094  memory: 5153  grad_norm: 170.1678  loss: 11.4903  decode.loss_cls: 0.0005  decode.loss_mask: 0.6957  decode.loss_dice: 0.4073  decode.d0.loss_cls: 0.0488  decode.d0.loss_mask: 0.9061  decode.d0.loss_dice: 0.5831  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7422  decode.d1.loss_dice: 0.4381  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.6937  decode.d2.loss_dice: 0.4073  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.7086  decode.d3.loss_dice: 0.4040  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6876  decode.d4.loss_dice: 0.3953  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6836  decode.d5.loss_dice: 0.4013  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6791  decode.d6.loss_dice: 0.4061  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6881  decode.d7.loss_dice: 0.4058  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6895  decode.d8.loss_dice: 0.4133\n",
      "07/02 18:00:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21800/32000]  base_lr: 2.2336e-06 lr: 2.2336e-07  eta: 0:27:02  time: 0.1593  data_time: 0.0092  memory: 5153  grad_norm: 227.4607  loss: 12.5578  decode.loss_cls: 0.0003  decode.loss_mask: 0.7550  decode.loss_dice: 0.4551  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.9520  decode.d0.loss_dice: 0.5952  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.7872  decode.d1.loss_dice: 0.4913  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.7907  decode.d2.loss_dice: 0.4846  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7608  decode.d3.loss_dice: 0.4590  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7499  decode.d4.loss_dice: 0.4445  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7325  decode.d5.loss_dice: 0.4496  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.7387  decode.d6.loss_dice: 0.4554  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7339  decode.d7.loss_dice: 0.4485  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7515  decode.d8.loss_dice: 0.4588\n",
      "07/02 18:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21850/32000]  base_lr: 2.2237e-06 lr: 2.2237e-07  eta: 0:26:54  time: 0.1587  data_time: 0.0093  memory: 5153  grad_norm: 214.8041  loss: 12.8738  decode.loss_cls: 0.0023  decode.loss_mask: 0.7804  decode.loss_dice: 0.4462  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 1.0430  decode.d0.loss_dice: 0.5905  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.8306  decode.d1.loss_dice: 0.4661  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.7902  decode.d2.loss_dice: 0.4494  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7929  decode.d3.loss_dice: 0.4468  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.8035  decode.d4.loss_dice: 0.4453  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.8076  decode.d5.loss_dice: 0.4712  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7667  decode.d6.loss_dice: 0.4486  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7661  decode.d7.loss_dice: 0.4553  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.7810  decode.d8.loss_dice: 0.4506\n",
      "07/02 18:00:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21900/32000]  base_lr: 2.2138e-06 lr: 2.2138e-07  eta: 0:26:46  time: 0.1571  data_time: 0.0088  memory: 5154  grad_norm: 135.6919  loss: 11.2122  decode.loss_cls: 0.0008  decode.loss_mask: 0.6534  decode.loss_dice: 0.4180  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.8130  decode.d0.loss_dice: 0.5584  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.6553  decode.d1.loss_dice: 0.4411  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.6505  decode.d2.loss_dice: 0.4362  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.6671  decode.d3.loss_dice: 0.4267  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6765  decode.d4.loss_dice: 0.4262  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6652  decode.d5.loss_dice: 0.4383  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6620  decode.d6.loss_dice: 0.4295  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.6524  decode.d7.loss_dice: 0.4309  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6577  decode.d8.loss_dice: 0.4195\n",
      "07/02 18:00:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21950/32000]  base_lr: 2.2040e-06 lr: 2.2040e-07  eta: 0:26:38  time: 0.1568  data_time: 0.0087  memory: 5152  grad_norm: 177.1513  loss: 11.4681  decode.loss_cls: 0.0005  decode.loss_mask: 0.6610  decode.loss_dice: 0.4509  decode.d0.loss_cls: 0.0480  decode.d0.loss_mask: 0.8268  decode.d0.loss_dice: 0.5792  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.6633  decode.d1.loss_dice: 0.4637  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.6512  decode.d2.loss_dice: 0.4377  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.6805  decode.d3.loss_dice: 0.4538  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6528  decode.d4.loss_dice: 0.4383  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6586  decode.d5.loss_dice: 0.4367  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.6577  decode.d6.loss_dice: 0.4297  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6640  decode.d7.loss_dice: 0.4540  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.6760  decode.d8.loss_dice: 0.4512\n",
      "07/02 18:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 18:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22000/32000]  base_lr: 2.1941e-06 lr: 2.1941e-07  eta: 0:26:30  time: 0.1582  data_time: 0.0079  memory: 5155  grad_norm: 169.9627  loss: 12.1333  decode.loss_cls: 0.0009  decode.loss_mask: 0.7374  decode.loss_dice: 0.4500  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.8339  decode.d0.loss_dice: 0.5540  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.7485  decode.d1.loss_dice: 0.4816  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.7450  decode.d2.loss_dice: 0.4694  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.7184  decode.d3.loss_dice: 0.4606  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 0.4509  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7092  decode.d5.loss_dice: 0.4524  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7083  decode.d6.loss_dice: 0.4511  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7419  decode.d7.loss_dice: 0.4591  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7422  decode.d8.loss_dice: 0.4647\n",
      "07/02 18:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0212  data_time: 0.0020  memory: 2167  \n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0290  data_time: 0.0060  memory: 1078  \n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 93.01 | 95.54 |\n",
      "|   lesion   | 80.74 | 91.71 |\n",
      "+------------+-------+-------+\n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.5900  mIoU: 86.8800  mAcc: 93.6300  data_time: 0.0112  time: 0.0366\n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /home/test/carasml/segmentation/Mask2former/mmsegmentation/work_dirs/best_mIoU_iter_19000.pth is removed\n",
      "07/02 18:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 86.8800 mIoU at 22000 iter is saved to best_mIoU_iter_22000.pth.\n",
      "07/02 18:01:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22050/32000]  base_lr: 2.1842e-06 lr: 2.1842e-07  eta: 0:26:23  time: 0.1617  data_time: 0.0092  memory: 5153  grad_norm: 125.2179  loss: 8.9865  decode.loss_cls: 0.0010  decode.loss_mask: 0.5093  decode.loss_dice: 0.3409  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.6614  decode.d0.loss_dice: 0.4859  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.5354  decode.d1.loss_dice: 0.3574  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.5242  decode.d2.loss_dice: 0.3540  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.5109  decode.d3.loss_dice: 0.3587  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5222  decode.d4.loss_dice: 0.3510  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.5306  decode.d5.loss_dice: 0.3624  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.5275  decode.d6.loss_dice: 0.3493  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.5006  decode.d7.loss_dice: 0.3446  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.4998  decode.d8.loss_dice: 0.3343\n",
      "07/02 18:01:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22100/32000]  base_lr: 2.1743e-06 lr: 2.1743e-07  eta: 0:26:15  time: 0.1586  data_time: 0.0085  memory: 5153  grad_norm: 211.2928  loss: 12.8132  decode.loss_cls: 0.0008  decode.loss_mask: 0.7442  decode.loss_dice: 0.4431  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 1.0192  decode.d0.loss_dice: 0.6074  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.8209  decode.d1.loss_dice: 0.5146  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.8121  decode.d2.loss_dice: 0.4580  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7944  decode.d3.loss_dice: 0.4528  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7972  decode.d4.loss_dice: 0.4484  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7898  decode.d5.loss_dice: 0.4561  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.7651  decode.d6.loss_dice: 0.4506  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7634  decode.d7.loss_dice: 0.4459  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7378  decode.d8.loss_dice: 0.4461\n",
      "07/02 18:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22150/32000]  base_lr: 2.1645e-06 lr: 2.1645e-07  eta: 0:26:07  time: 0.1600  data_time: 0.0087  memory: 5153  grad_norm: 149.3228  loss: 11.9660  decode.loss_cls: 0.0012  decode.loss_mask: 0.7218  decode.loss_dice: 0.4160  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.9043  decode.d0.loss_dice: 0.5586  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.7612  decode.d1.loss_dice: 0.4699  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7200  decode.d2.loss_dice: 0.4527  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.7316  decode.d3.loss_dice: 0.4361  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7396  decode.d4.loss_dice: 0.4325  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.7314  decode.d5.loss_dice: 0.4157  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.7206  decode.d6.loss_dice: 0.4180  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7271  decode.d7.loss_dice: 0.4168  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.7219  decode.d8.loss_dice: 0.4206\n",
      "07/02 18:01:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22200/32000]  base_lr: 2.1546e-06 lr: 2.1546e-07  eta: 0:25:59  time: 0.1597  data_time: 0.0089  memory: 5153  grad_norm: 193.4766  loss: 11.9795  decode.loss_cls: 0.0004  decode.loss_mask: 0.7040  decode.loss_dice: 0.4259  decode.d0.loss_cls: 0.0306  decode.d0.loss_mask: 0.8621  decode.d0.loss_dice: 0.5758  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.7287  decode.d1.loss_dice: 0.4259  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.7199  decode.d2.loss_dice: 0.4444  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7162  decode.d3.loss_dice: 0.4358  decode.d4.loss_cls: 0.1122  decode.d4.loss_mask: 0.6757  decode.d4.loss_dice: 0.4503  decode.d5.loss_cls: 0.1197  decode.d5.loss_mask: 0.6861  decode.d5.loss_dice: 0.4343  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6803  decode.d6.loss_dice: 0.4123  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6849  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6999  decode.d8.loss_dice: 0.4317\n",
      "07/02 18:01:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22250/32000]  base_lr: 2.1447e-06 lr: 2.1447e-07  eta: 0:25:51  time: 0.1606  data_time: 0.0090  memory: 5154  grad_norm: 220.3873  loss: 13.2637  decode.loss_cls: 0.0006  decode.loss_mask: 0.7898  decode.loss_dice: 0.4966  decode.d0.loss_cls: 0.0423  decode.d0.loss_mask: 0.9385  decode.d0.loss_dice: 0.6259  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.8410  decode.d1.loss_dice: 0.4992  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.8477  decode.d2.loss_dice: 0.5108  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.7958  decode.d3.loss_dice: 0.4909  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 0.4910  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.7747  decode.d5.loss_dice: 0.4758  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 0.4751  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 0.4734  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7921  decode.d8.loss_dice: 0.4784\n",
      "07/02 18:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22300/32000]  base_lr: 2.1348e-06 lr: 2.1348e-07  eta: 0:25:43  time: 0.1608  data_time: 0.0091  memory: 5152  grad_norm: 234.8626  loss: 15.5800  decode.loss_cls: 0.0006  decode.loss_mask: 0.9110  decode.loss_dice: 0.5648  decode.d0.loss_cls: 0.0722  decode.d0.loss_mask: 1.1838  decode.d0.loss_dice: 0.7008  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 1.0116  decode.d1.loss_dice: 0.6153  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.9749  decode.d2.loss_dice: 0.5854  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.9310  decode.d3.loss_dice: 0.5977  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.9101  decode.d4.loss_dice: 0.5669  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.9430  decode.d5.loss_dice: 0.5864  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.9121  decode.d6.loss_dice: 0.5678  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.9099  decode.d7.loss_dice: 0.5698  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.8954  decode.d8.loss_dice: 0.5582\n",
      "07/02 18:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22350/32000]  base_lr: 2.1249e-06 lr: 2.1249e-07  eta: 0:25:35  time: 0.1591  data_time: 0.0082  memory: 5154  grad_norm: 244.6794  loss: 12.7848  decode.loss_cls: 0.0006  decode.loss_mask: 0.7160  decode.loss_dice: 0.4770  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.8631  decode.d0.loss_dice: 0.6239  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.7546  decode.d1.loss_dice: 0.5249  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.8108  decode.d2.loss_dice: 0.5318  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.7594  decode.d3.loss_dice: 0.5128  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.7257  decode.d4.loss_dice: 0.5067  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7316  decode.d5.loss_dice: 0.5057  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7276  decode.d6.loss_dice: 0.4931  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.7179  decode.d7.loss_dice: 0.4891  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.7198  decode.d8.loss_dice: 0.4925\n",
      "07/02 18:02:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22400/32000]  base_lr: 2.1150e-06 lr: 2.1150e-07  eta: 0:25:27  time: 0.1614  data_time: 0.0088  memory: 5153  grad_norm: 199.8877  loss: 12.2404  decode.loss_cls: 0.0006  decode.loss_mask: 0.7448  decode.loss_dice: 0.4577  decode.d0.loss_cls: 0.0333  decode.d0.loss_mask: 0.8760  decode.d0.loss_dice: 0.5655  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.7417  decode.d1.loss_dice: 0.4651  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7541  decode.d2.loss_dice: 0.4546  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.7237  decode.d3.loss_dice: 0.4793  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.7364  decode.d4.loss_dice: 0.4718  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7233  decode.d5.loss_dice: 0.4633  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.7062  decode.d6.loss_dice: 0.4545  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7205  decode.d7.loss_dice: 0.4626  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7369  decode.d8.loss_dice: 0.4640\n",
      "07/02 18:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22450/32000]  base_lr: 2.1050e-06 lr: 2.1050e-07  eta: 0:25:19  time: 0.1606  data_time: 0.0085  memory: 5154  grad_norm: 113.1274  loss: 8.8083  decode.loss_cls: 0.0005  decode.loss_mask: 0.5186  decode.loss_dice: 0.3121  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.6621  decode.d0.loss_dice: 0.4282  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.5665  decode.d1.loss_dice: 0.3460  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.5542  decode.d2.loss_dice: 0.3343  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.5401  decode.d3.loss_dice: 0.3179  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.5289  decode.d4.loss_dice: 0.3236  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.5262  decode.d5.loss_dice: 0.3118  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.5237  decode.d6.loss_dice: 0.3071  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.5270  decode.d7.loss_dice: 0.3100  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.5198  decode.d8.loss_dice: 0.3167\n",
      "07/02 18:02:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22500/32000]  base_lr: 2.0951e-06 lr: 2.0951e-07  eta: 0:25:11  time: 0.1614  data_time: 0.0101  memory: 5154  grad_norm: 183.4030  loss: 11.4085  decode.loss_cls: 0.0030  decode.loss_mask: 0.6761  decode.loss_dice: 0.3951  decode.d0.loss_cls: 0.0885  decode.d0.loss_mask: 0.8643  decode.d0.loss_dice: 0.5367  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7216  decode.d1.loss_dice: 0.4245  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.7139  decode.d2.loss_dice: 0.4300  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.7172  decode.d3.loss_dice: 0.4271  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.7009  decode.d4.loss_dice: 0.4079  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.6700  decode.d5.loss_dice: 0.3947  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.6686  decode.d6.loss_dice: 0.3812  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.6668  decode.d7.loss_dice: 0.3982  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.6803  decode.d8.loss_dice: 0.4049\n",
      "07/02 18:02:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22550/32000]  base_lr: 2.0852e-06 lr: 2.0852e-07  eta: 0:25:03  time: 0.1597  data_time: 0.0098  memory: 5153  grad_norm: 223.2560  loss: 13.2091  decode.loss_cls: 0.0007  decode.loss_mask: 0.7932  decode.loss_dice: 0.4614  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.9735  decode.d0.loss_dice: 0.5911  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 0.5342  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 0.4896  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.7946  decode.d3.loss_dice: 0.5137  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.7866  decode.d4.loss_dice: 0.4754  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7986  decode.d5.loss_dice: 0.4635  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.8025  decode.d6.loss_dice: 0.4667  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.7904  decode.d7.loss_dice: 0.4693  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.7932  decode.d8.loss_dice: 0.4595\n",
      "07/02 18:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22600/32000]  base_lr: 2.0753e-06 lr: 2.0753e-07  eta: 0:24:56  time: 0.1580  data_time: 0.0084  memory: 5153  grad_norm: 214.0285  loss: 12.8741  decode.loss_cls: 0.0004  decode.loss_mask: 0.7834  decode.loss_dice: 0.4409  decode.d0.loss_cls: 0.0678  decode.d0.loss_mask: 0.8743  decode.d0.loss_dice: 0.5685  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.8528  decode.d1.loss_dice: 0.5060  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 0.7951  decode.d2.loss_dice: 0.4742  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.7825  decode.d3.loss_dice: 0.4638  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.8018  decode.d4.loss_dice: 0.4740  decode.d5.loss_cls: 0.0128  decode.d5.loss_mask: 0.7917  decode.d5.loss_dice: 0.4663  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7624  decode.d6.loss_dice: 0.4316  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7848  decode.d7.loss_dice: 0.4422  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7772  decode.d8.loss_dice: 0.4451\n",
      "07/02 18:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22650/32000]  base_lr: 2.0653e-06 lr: 2.0653e-07  eta: 0:24:48  time: 0.1583  data_time: 0.0088  memory: 5153  grad_norm: 156.2668  loss: 11.6771  decode.loss_cls: 0.0004  decode.loss_mask: 0.6593  decode.loss_dice: 0.4523  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.8396  decode.d0.loss_dice: 0.6123  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.7040  decode.d1.loss_dice: 0.4964  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.6936  decode.d2.loss_dice: 0.4756  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.6417  decode.d3.loss_dice: 0.4521  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.6749  decode.d4.loss_dice: 0.4692  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6645  decode.d5.loss_dice: 0.4640  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6566  decode.d6.loss_dice: 0.4465  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6699  decode.d7.loss_dice: 0.4557  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.6602  decode.d8.loss_dice: 0.4549\n",
      "07/02 18:03:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22700/32000]  base_lr: 2.0554e-06 lr: 2.0554e-07  eta: 0:24:40  time: 0.1612  data_time: 0.0103  memory: 5153  grad_norm: 197.5811  loss: 11.9243  decode.loss_cls: 0.0177  decode.loss_mask: 0.6591  decode.loss_dice: 0.4749  decode.d0.loss_cls: 0.0606  decode.d0.loss_mask: 0.7555  decode.d0.loss_dice: 0.5905  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.6622  decode.d1.loss_dice: 0.5084  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.6583  decode.d2.loss_dice: 0.5059  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.6644  decode.d3.loss_dice: 0.4869  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.6788  decode.d4.loss_dice: 0.4922  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.6990  decode.d5.loss_dice: 0.5071  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.6654  decode.d6.loss_dice: 0.4807  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.6669  decode.d7.loss_dice: 0.4938  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.6607  decode.d8.loss_dice: 0.4827\n",
      "07/02 18:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22750/32000]  base_lr: 2.0454e-06 lr: 2.0454e-07  eta: 0:24:32  time: 0.1599  data_time: 0.0094  memory: 5153  grad_norm: 216.7468  loss: 11.3637  decode.loss_cls: 0.0008  decode.loss_mask: 0.6804  decode.loss_dice: 0.4300  decode.d0.loss_cls: 0.0493  decode.d0.loss_mask: 0.8701  decode.d0.loss_dice: 0.5553  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.6642  decode.d1.loss_dice: 0.4414  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.6632  decode.d2.loss_dice: 0.4129  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.6482  decode.d3.loss_dice: 0.4227  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.6529  decode.d4.loss_dice: 0.4193  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.6670  decode.d5.loss_dice: 0.4260  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.6835  decode.d6.loss_dice: 0.4147  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6922  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.6996  decode.d8.loss_dice: 0.4276\n",
      "07/02 18:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22800/32000]  base_lr: 2.0355e-06 lr: 2.0355e-07  eta: 0:24:24  time: 0.1596  data_time: 0.0095  memory: 5153  grad_norm: 256.8048  loss: 13.9075  decode.loss_cls: 0.0011  decode.loss_mask: 0.8415  decode.loss_dice: 0.4866  decode.d0.loss_cls: 0.0389  decode.d0.loss_mask: 1.0349  decode.d0.loss_dice: 0.6388  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.8615  decode.d1.loss_dice: 0.5262  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.8317  decode.d2.loss_dice: 0.4920  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.8586  decode.d3.loss_dice: 0.5201  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.8587  decode.d4.loss_dice: 0.5129  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 0.5062  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.8446  decode.d6.loss_dice: 0.5039  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.8273  decode.d7.loss_dice: 0.4922  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.8419  decode.d8.loss_dice: 0.4949\n",
      "07/02 18:03:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22850/32000]  base_lr: 2.0255e-06 lr: 2.0255e-07  eta: 0:24:16  time: 0.1612  data_time: 0.0100  memory: 5154  grad_norm: 109.1853  loss: 9.0936  decode.loss_cls: 0.0003  decode.loss_mask: 0.5376  decode.loss_dice: 0.3225  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.6819  decode.d0.loss_dice: 0.4581  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.5850  decode.d1.loss_dice: 0.3554  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.3377  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.5577  decode.d3.loss_dice: 0.3303  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.5528  decode.d4.loss_dice: 0.3324  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.5532  decode.d5.loss_dice: 0.3301  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.5319  decode.d6.loss_dice: 0.3119  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5296  decode.d7.loss_dice: 0.3180  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5316  decode.d8.loss_dice: 0.3182\n",
      "07/02 18:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22900/32000]  base_lr: 2.0156e-06 lr: 2.0156e-07  eta: 0:24:08  time: 0.1608  data_time: 0.0091  memory: 5154  grad_norm: 180.8871  loss: 11.0188  decode.loss_cls: 0.1592  decode.loss_mask: 0.5990  decode.loss_dice: 0.3785  decode.d0.loss_cls: 0.0479  decode.d0.loss_mask: 0.7273  decode.d0.loss_dice: 0.4989  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.6582  decode.d1.loss_dice: 0.4497  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.6368  decode.d2.loss_dice: 0.3967  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.6260  decode.d3.loss_dice: 0.4187  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.6157  decode.d4.loss_dice: 0.3933  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6097  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.5912  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.1497  decode.d7.loss_mask: 0.6049  decode.d7.loss_dice: 0.3848  decode.d8.loss_cls: 0.1517  decode.d8.loss_mask: 0.6044  decode.d8.loss_dice: 0.3860\n",
      "07/02 18:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22950/32000]  base_lr: 2.0056e-06 lr: 2.0056e-07  eta: 0:24:00  time: 0.1593  data_time: 0.0099  memory: 5153  grad_norm: 180.8941  loss: 12.0308  decode.loss_cls: 0.0008  decode.loss_mask: 0.7070  decode.loss_dice: 0.4441  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.8995  decode.d0.loss_dice: 0.5815  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 0.4741  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.7469  decode.d2.loss_dice: 0.4555  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7309  decode.d3.loss_dice: 0.4354  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.4420  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.7274  decode.d5.loss_dice: 0.4403  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.7142  decode.d6.loss_dice: 0.4332  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.7070  decode.d7.loss_dice: 0.4361  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6998  decode.d8.loss_dice: 0.4355\n",
      "07/02 18:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 18:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23000/32000]  base_lr: 1.9956e-06 lr: 1.9956e-07  eta: 0:23:52  time: 0.1579  data_time: 0.0089  memory: 5153  grad_norm: 170.7613  loss: 13.7262  decode.loss_cls: 0.0005  decode.loss_mask: 0.8452  decode.loss_dice: 0.4803  decode.d0.loss_cls: 0.0531  decode.d0.loss_mask: 1.0218  decode.d0.loss_dice: 0.6558  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.8610  decode.d1.loss_dice: 0.5020  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.8318  decode.d2.loss_dice: 0.4912  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.8601  decode.d3.loss_dice: 0.4979  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.8406  decode.d4.loss_dice: 0.4674  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.8589  decode.d5.loss_dice: 0.4807  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8539  decode.d6.loss_dice: 0.4753  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.8474  decode.d7.loss_dice: 0.4742  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.8461  decode.d8.loss_dice: 0.4744\n",
      "07/02 18:03:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0213  data_time: 0.0021  memory: 2166  \n",
      "07/02 18:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0287  data_time: 0.0060  memory: 1078  \n",
      "07/02 18:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 18:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.16 | 94.53 |\n",
      "|   lesion   | 78.99 | 92.16 |\n",
      "+------------+-------+-------+\n",
      "07/02 18:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.9400  mIoU: 85.5700  mAcc: 93.3400  data_time: 0.0110  time: 0.0360\n",
      "07/02 18:04:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23050/32000]  base_lr: 1.9856e-06 lr: 1.9856e-07  eta: 0:23:44  time: 0.1598  data_time: 0.0101  memory: 5153  grad_norm: 127.4389  loss: 10.1214  decode.loss_cls: 0.0001  decode.loss_mask: 0.6128  decode.loss_dice: 0.3816  decode.d0.loss_cls: 0.0218  decode.d0.loss_mask: 0.7556  decode.d0.loss_dice: 0.4867  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.6326  decode.d1.loss_dice: 0.3847  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6337  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5911  decode.d3.loss_dice: 0.3692  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.6152  decode.d4.loss_dice: 0.3807  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.6051  decode.d5.loss_dice: 0.3642  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5996  decode.d6.loss_dice: 0.3630  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5998  decode.d7.loss_dice: 0.3650  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6099  decode.d8.loss_dice: 0.3747\n",
      "07/02 18:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23100/32000]  base_lr: 1.9756e-06 lr: 1.9756e-07  eta: 0:23:36  time: 0.1588  data_time: 0.0091  memory: 5154  grad_norm: 171.6359  loss: 12.1447  decode.loss_cls: 0.0019  decode.loss_mask: 0.7132  decode.loss_dice: 0.4507  decode.d0.loss_cls: 0.0317  decode.d0.loss_mask: 0.8678  decode.d0.loss_dice: 0.5857  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.7076  decode.d1.loss_dice: 0.4517  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.7186  decode.d2.loss_dice: 0.4782  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 0.4700  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.7148  decode.d4.loss_dice: 0.4646  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.7128  decode.d5.loss_dice: 0.4745  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.7322  decode.d6.loss_dice: 0.4706  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.7316  decode.d7.loss_dice: 0.4577  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.7170  decode.d8.loss_dice: 0.4514\n",
      "07/02 18:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23150/32000]  base_lr: 1.9657e-06 lr: 1.9657e-07  eta: 0:23:28  time: 0.1622  data_time: 0.0102  memory: 5153  grad_norm: 147.3400  loss: 11.0710  decode.loss_cls: 0.0003  decode.loss_mask: 0.5953  decode.loss_dice: 0.4500  decode.d0.loss_cls: 0.0356  decode.d0.loss_mask: 0.7824  decode.d0.loss_dice: 0.5893  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.6584  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6016  decode.d2.loss_dice: 0.4513  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.6370  decode.d3.loss_dice: 0.4515  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.6348  decode.d4.loss_dice: 0.4411  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.6216  decode.d5.loss_dice: 0.4440  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6079  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6034  decode.d7.loss_dice: 0.4554  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6276  decode.d8.loss_dice: 0.4446\n",
      "07/02 18:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23200/32000]  base_lr: 1.9557e-06 lr: 1.9557e-07  eta: 0:23:20  time: 0.1578  data_time: 0.0093  memory: 5154  grad_norm: 148.1766  loss: 9.9887  decode.loss_cls: 0.0008  decode.loss_mask: 0.5401  decode.loss_dice: 0.4086  decode.d0.loss_cls: 0.0376  decode.d0.loss_mask: 0.6562  decode.d0.loss_dice: 0.5422  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.5743  decode.d1.loss_dice: 0.4361  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.5785  decode.d2.loss_dice: 0.4233  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.5564  decode.d3.loss_dice: 0.4241  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.5605  decode.d4.loss_dice: 0.4121  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.5516  decode.d5.loss_dice: 0.4015  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 0.4121  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5537  decode.d7.loss_dice: 0.4130  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5354  decode.d8.loss_dice: 0.4098\n",
      "07/02 18:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23250/32000]  base_lr: 1.9456e-06 lr: 1.9456e-07  eta: 0:23:12  time: 0.1596  data_time: 0.0091  memory: 5153  grad_norm: 123.6873  loss: 9.6480  decode.loss_cls: 0.0001  decode.loss_mask: 0.5512  decode.loss_dice: 0.3477  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.7562  decode.d0.loss_dice: 0.4992  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.6016  decode.d1.loss_dice: 0.3893  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.5904  decode.d2.loss_dice: 0.3771  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.5741  decode.d3.loss_dice: 0.3625  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.5605  decode.d4.loss_dice: 0.3640  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.5611  decode.d5.loss_dice: 0.3618  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5485  decode.d6.loss_dice: 0.3549  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.5547  decode.d7.loss_dice: 0.3527  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.5563  decode.d8.loss_dice: 0.3593\n",
      "07/02 18:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23300/32000]  base_lr: 1.9356e-06 lr: 1.9356e-07  eta: 0:23:04  time: 0.1581  data_time: 0.0089  memory: 5153  grad_norm: 200.3957  loss: 12.9476  decode.loss_cls: 0.1651  decode.loss_mask: 0.6987  decode.loss_dice: 0.4446  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 0.8349  decode.d0.loss_dice: 0.6122  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.7014  decode.d1.loss_dice: 0.4743  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.7125  decode.d2.loss_dice: 0.4578  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.6981  decode.d3.loss_dice: 0.4558  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 0.6874  decode.d4.loss_dice: 0.4486  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.6711  decode.d5.loss_dice: 0.4433  decode.d6.loss_cls: 0.1651  decode.d6.loss_mask: 0.6921  decode.d6.loss_dice: 0.4414  decode.d7.loss_cls: 0.1777  decode.d7.loss_mask: 0.7021  decode.d7.loss_dice: 0.4475  decode.d8.loss_cls: 0.1542  decode.d8.loss_mask: 0.7020  decode.d8.loss_dice: 0.4507\n",
      "07/02 18:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23350/32000]  base_lr: 1.9256e-06 lr: 1.9256e-07  eta: 0:22:56  time: 0.1588  data_time: 0.0092  memory: 5153  grad_norm: 110.0305  loss: 10.3706  decode.loss_cls: 0.0007  decode.loss_mask: 0.6068  decode.loss_dice: 0.3655  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.8054  decode.d0.loss_dice: 0.5100  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.6674  decode.d1.loss_dice: 0.4195  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6295  decode.d2.loss_dice: 0.3960  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.6143  decode.d3.loss_dice: 0.3783  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.6231  decode.d4.loss_dice: 0.3724  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.6167  decode.d5.loss_dice: 0.3851  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6136  decode.d6.loss_dice: 0.3730  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6011  decode.d7.loss_dice: 0.3689  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.6064  decode.d8.loss_dice: 0.3685\n",
      "07/02 18:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23400/32000]  base_lr: 1.9156e-06 lr: 1.9156e-07  eta: 0:22:48  time: 0.1594  data_time: 0.0099  memory: 5153  grad_norm: 179.6451  loss: 12.4520  decode.loss_cls: 0.0001  decode.loss_mask: 0.7665  decode.loss_dice: 0.4228  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.9419  decode.d0.loss_dice: 0.5502  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.7978  decode.d1.loss_dice: 0.4593  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.8045  decode.d2.loss_dice: 0.4463  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7883  decode.d3.loss_dice: 0.4404  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.8060  decode.d4.loss_dice: 0.4316  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.7849  decode.d5.loss_dice: 0.4263  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.7847  decode.d6.loss_dice: 0.4214  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 0.4188  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.7622  decode.d8.loss_dice: 0.4103\n",
      "07/02 18:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23450/32000]  base_lr: 1.9056e-06 lr: 1.9056e-07  eta: 0:22:40  time: 0.1594  data_time: 0.0089  memory: 5154  grad_norm: 198.8913  loss: 11.9699  decode.loss_cls: 0.0014  decode.loss_mask: 0.6863  decode.loss_dice: 0.4237  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.8773  decode.d0.loss_dice: 0.5712  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.7746  decode.d1.loss_dice: 0.4631  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.7148  decode.d2.loss_dice: 0.4369  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.7579  decode.d3.loss_dice: 0.4507  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.7618  decode.d4.loss_dice: 0.4429  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7285  decode.d5.loss_dice: 0.4229  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.6872  decode.d6.loss_dice: 0.4283  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7046  decode.d7.loss_dice: 0.4410  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.6946  decode.d8.loss_dice: 0.4318\n",
      "07/02 18:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23500/32000]  base_lr: 1.8955e-06 lr: 1.8955e-07  eta: 0:22:32  time: 0.1569  data_time: 0.0086  memory: 5153  grad_norm: 141.3556  loss: 9.7752  decode.loss_cls: 0.0002  decode.loss_mask: 0.5695  decode.loss_dice: 0.3569  decode.d0.loss_cls: 0.0213  decode.d0.loss_mask: 0.7277  decode.d0.loss_dice: 0.4962  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.5967  decode.d1.loss_dice: 0.3741  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.5716  decode.d2.loss_dice: 0.3824  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.5851  decode.d3.loss_dice: 0.3645  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.5790  decode.d4.loss_dice: 0.3726  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5721  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.5664  decode.d6.loss_dice: 0.3773  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5668  decode.d7.loss_dice: 0.3701  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5684  decode.d8.loss_dice: 0.3668\n",
      "07/02 18:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23550/32000]  base_lr: 1.8855e-06 lr: 1.8855e-07  eta: 0:22:25  time: 0.1602  data_time: 0.0095  memory: 5154  grad_norm: 227.7937  loss: 12.6611  decode.loss_cls: 0.0002  decode.loss_mask: 0.7354  decode.loss_dice: 0.4609  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.9059  decode.d0.loss_dice: 0.6348  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.7701  decode.d1.loss_dice: 0.5076  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.7606  decode.d2.loss_dice: 0.4970  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.7627  decode.d3.loss_dice: 0.5024  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.7753  decode.d4.loss_dice: 0.4998  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7571  decode.d5.loss_dice: 0.4939  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7204  decode.d6.loss_dice: 0.4640  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7274  decode.d7.loss_dice: 0.4598  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7336  decode.d8.loss_dice: 0.4622\n",
      "07/02 18:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23600/32000]  base_lr: 1.8755e-06 lr: 1.8755e-07  eta: 0:22:17  time: 0.1593  data_time: 0.0102  memory: 5153  grad_norm: 220.1828  loss: 14.0529  decode.loss_cls: 0.0003  decode.loss_mask: 0.8863  decode.loss_dice: 0.4839  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 1.0607  decode.d0.loss_dice: 0.5956  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.9069  decode.d1.loss_dice: 0.5163  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.9093  decode.d2.loss_dice: 0.4985  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.8619  decode.d3.loss_dice: 0.4949  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.8549  decode.d4.loss_dice: 0.4941  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.8790  decode.d5.loss_dice: 0.4807  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.8783  decode.d6.loss_dice: 0.4819  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.8812  decode.d7.loss_dice: 0.4771  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.8849  decode.d8.loss_dice: 0.4870\n",
      "07/02 18:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23650/32000]  base_lr: 1.8654e-06 lr: 1.8654e-07  eta: 0:22:09  time: 0.1585  data_time: 0.0088  memory: 5153  grad_norm: 143.5224  loss: 9.0743  decode.loss_cls: 0.0002  decode.loss_mask: 0.5281  decode.loss_dice: 0.3298  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.6410  decode.d0.loss_dice: 0.4637  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.5541  decode.d1.loss_dice: 0.3720  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.5385  decode.d2.loss_dice: 0.3456  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5393  decode.d3.loss_dice: 0.3507  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.5455  decode.d4.loss_dice: 0.3522  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5458  decode.d5.loss_dice: 0.3462  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5280  decode.d6.loss_dice: 0.3273  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 0.3301  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5374  decode.d8.loss_dice: 0.3305\n",
      "07/02 18:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23700/32000]  base_lr: 1.8554e-06 lr: 1.8554e-07  eta: 0:22:01  time: 0.1586  data_time: 0.0088  memory: 5153  grad_norm: 155.3029  loss: 9.6635  decode.loss_cls: 0.0002  decode.loss_mask: 0.5518  decode.loss_dice: 0.3791  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.6339  decode.d0.loss_dice: 0.4763  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.5761  decode.d1.loss_dice: 0.4048  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.5960  decode.d2.loss_dice: 0.4034  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.5476  decode.d3.loss_dice: 0.3854  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.5473  decode.d4.loss_dice: 0.3825  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.5498  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.5340  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5499  decode.d7.loss_dice: 0.3796  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5593  decode.d8.loss_dice: 0.3881\n",
      "07/02 18:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23750/32000]  base_lr: 1.8453e-06 lr: 1.8453e-07  eta: 0:21:53  time: 0.1568  data_time: 0.0079  memory: 5154  grad_norm: 153.8810  loss: 12.6608  decode.loss_cls: 0.0003  decode.loss_mask: 0.7537  decode.loss_dice: 0.4603  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.9085  decode.d0.loss_dice: 0.5793  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7902  decode.d1.loss_dice: 0.5009  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.7444  decode.d2.loss_dice: 0.4683  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.7582  decode.d3.loss_dice: 0.4554  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7750  decode.d4.loss_dice: 0.4575  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.7977  decode.d5.loss_dice: 0.4627  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.7806  decode.d6.loss_dice: 0.4649  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.7835  decode.d7.loss_dice: 0.4775  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.7521  decode.d8.loss_dice: 0.4648\n",
      "07/02 18:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23800/32000]  base_lr: 1.8352e-06 lr: 1.8352e-07  eta: 0:21:45  time: 0.1559  data_time: 0.0083  memory: 5153  grad_norm: 156.2383  loss: 9.5939  decode.loss_cls: 0.0003  decode.loss_mask: 0.5537  decode.loss_dice: 0.3446  decode.d0.loss_cls: 0.0618  decode.d0.loss_mask: 0.6954  decode.d0.loss_dice: 0.4712  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.6026  decode.d1.loss_dice: 0.3820  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.5942  decode.d2.loss_dice: 0.3758  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.5692  decode.d3.loss_dice: 0.3564  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.5732  decode.d4.loss_dice: 0.3538  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5774  decode.d5.loss_dice: 0.3629  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.5628  decode.d6.loss_dice: 0.3468  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5571  decode.d7.loss_dice: 0.3436  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.5556  decode.d8.loss_dice: 0.3494\n",
      "07/02 18:06:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23850/32000]  base_lr: 1.8252e-06 lr: 1.8252e-07  eta: 0:21:37  time: 0.2463  data_time: 0.0085  memory: 5153  grad_norm: 143.9621  loss: 10.5252  decode.loss_cls: 0.0003  decode.loss_mask: 0.6201  decode.loss_dice: 0.3854  decode.d0.loss_cls: 0.0239  decode.d0.loss_mask: 0.7524  decode.d0.loss_dice: 0.5071  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.6534  decode.d1.loss_dice: 0.4211  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.6224  decode.d2.loss_dice: 0.4059  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.6254  decode.d3.loss_dice: 0.4094  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6343  decode.d4.loss_dice: 0.4118  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.6244  decode.d5.loss_dice: 0.4053  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.6116  decode.d6.loss_dice: 0.3857  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.6208  decode.d7.loss_dice: 0.3924  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6201  decode.d8.loss_dice: 0.3806\n",
      "07/02 18:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23900/32000]  base_lr: 1.8151e-06 lr: 1.8151e-07  eta: 0:21:29  time: 0.1620  data_time: 0.0097  memory: 5153  grad_norm: 171.0745  loss: 12.4253  decode.loss_cls: 0.0003  decode.loss_mask: 0.7603  decode.loss_dice: 0.4196  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.9281  decode.d0.loss_dice: 0.5834  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.7825  decode.d1.loss_dice: 0.4712  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 0.4340  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 0.4678  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.8129  decode.d4.loss_dice: 0.4561  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7728  decode.d5.loss_dice: 0.4247  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7596  decode.d6.loss_dice: 0.4186  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7535  decode.d7.loss_dice: 0.4144  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7495  decode.d8.loss_dice: 0.4145\n",
      "07/02 18:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23950/32000]  base_lr: 1.8050e-06 lr: 1.8050e-07  eta: 0:21:21  time: 0.1636  data_time: 0.0097  memory: 5153  grad_norm: 226.5838  loss: 13.2428  decode.loss_cls: 0.0003  decode.loss_mask: 0.7791  decode.loss_dice: 0.4978  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.9760  decode.d0.loss_dice: 0.6224  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.8138  decode.d1.loss_dice: 0.5352  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.7771  decode.d2.loss_dice: 0.5115  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.7615  decode.d3.loss_dice: 0.5102  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7737  decode.d4.loss_dice: 0.5303  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.7862  decode.d5.loss_dice: 0.5171  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7688  decode.d6.loss_dice: 0.5106  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7619  decode.d7.loss_dice: 0.4918  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 0.5017\n",
      "07/02 18:06:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 18:06:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24000/32000]  base_lr: 1.7949e-06 lr: 1.7949e-07  eta: 0:21:13  time: 0.1630  data_time: 0.0091  memory: 5153  grad_norm: 230.4246  loss: 14.1558  decode.loss_cls: 0.0010  decode.loss_mask: 0.8485  decode.loss_dice: 0.5035  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 1.0142  decode.d0.loss_dice: 0.6359  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.8702  decode.d1.loss_dice: 0.5239  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.8578  decode.d2.loss_dice: 0.5354  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.8733  decode.d3.loss_dice: 0.5003  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.8679  decode.d4.loss_dice: 0.5024  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.8610  decode.d5.loss_dice: 0.4964  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.8386  decode.d6.loss_dice: 0.4810  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.8699  decode.d7.loss_dice: 0.4953  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.8547  decode.d8.loss_dice: 0.4981\n",
      "07/02 18:06:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0234  data_time: 0.0026  memory: 2168  \n",
      "07/02 18:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0296  data_time: 0.0062  memory: 1078  \n",
      "07/02 18:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 18:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.81 | 96.41 |\n",
      "|   lesion   | 79.49 | 88.18 |\n",
      "+------------+-------+-------+\n",
      "07/02 18:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 94.3800  mIoU: 86.1500  mAcc: 92.3000  data_time: 0.0118  time: 0.0382\n",
      "07/02 18:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24050/32000]  base_lr: 1.7848e-06 lr: 1.7848e-07  eta: 0:21:06  time: 0.1660  data_time: 0.0095  memory: 5153  grad_norm: 175.2303  loss: 12.4996  decode.loss_cls: 0.0002  decode.loss_mask: 0.7269  decode.loss_dice: 0.4554  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.8819  decode.d0.loss_dice: 0.5759  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.7695  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7594  decode.d2.loss_dice: 0.4620  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 0.4783  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7822  decode.d4.loss_dice: 0.4763  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7640  decode.d5.loss_dice: 0.4604  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.7577  decode.d6.loss_dice: 0.4635  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.7344  decode.d7.loss_dice: 0.4569  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7389  decode.d8.loss_dice: 0.4560\n",
      "07/02 18:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24100/32000]  base_lr: 1.7747e-06 lr: 1.7747e-07  eta: 0:20:58  time: 0.1615  data_time: 0.0098  memory: 5154  grad_norm: 202.8551  loss: 12.3422  decode.loss_cls: 0.0005  decode.loss_mask: 0.7691  decode.loss_dice: 0.4374  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.9069  decode.d0.loss_dice: 0.5630  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.7772  decode.d1.loss_dice: 0.4660  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.7206  decode.d2.loss_dice: 0.4327  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.7740  decode.d3.loss_dice: 0.4355  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.7493  decode.d4.loss_dice: 0.4332  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7764  decode.d5.loss_dice: 0.4379  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.7522  decode.d6.loss_dice: 0.4312  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 0.4358  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7606  decode.d8.loss_dice: 0.4379\n",
      "07/02 18:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24150/32000]  base_lr: 1.7646e-06 lr: 1.7646e-07  eta: 0:20:50  time: 0.1621  data_time: 0.0102  memory: 5154  grad_norm: 239.6759  loss: 12.9919  decode.loss_cls: 0.0005  decode.loss_mask: 0.7613  decode.loss_dice: 0.5117  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 0.9013  decode.d0.loss_dice: 0.5980  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.8036  decode.d1.loss_dice: 0.5389  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.8010  decode.d2.loss_dice: 0.4903  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.7603  decode.d3.loss_dice: 0.4852  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.7512  decode.d4.loss_dice: 0.4984  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.7487  decode.d5.loss_dice: 0.4975  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7554  decode.d6.loss_dice: 0.5030  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 0.4937  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.7772  decode.d8.loss_dice: 0.5034\n",
      "07/02 18:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24200/32000]  base_lr: 1.7545e-06 lr: 1.7545e-07  eta: 0:20:42  time: 0.1638  data_time: 0.0096  memory: 5153  grad_norm: 166.9942  loss: 12.1493  decode.loss_cls: 0.0006  decode.loss_mask: 0.7277  decode.loss_dice: 0.4284  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.8021  decode.d0.loss_dice: 0.5602  decode.d1.loss_cls: 0.2018  decode.d1.loss_mask: 0.7040  decode.d1.loss_dice: 0.4384  decode.d2.loss_cls: 0.1345  decode.d2.loss_mask: 0.7463  decode.d2.loss_dice: 0.4270  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.6930  decode.d3.loss_dice: 0.4291  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7200  decode.d4.loss_dice: 0.4479  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.6974  decode.d5.loss_dice: 0.4140  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6954  decode.d6.loss_dice: 0.4366  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7068  decode.d7.loss_dice: 0.4283  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7359  decode.d8.loss_dice: 0.4308\n",
      "07/02 18:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24250/32000]  base_lr: 1.7443e-06 lr: 1.7443e-07  eta: 0:20:34  time: 0.1612  data_time: 0.0100  memory: 5153  grad_norm: 134.3288  loss: 10.1544  decode.loss_cls: 0.0001  decode.loss_mask: 0.6217  decode.loss_dice: 0.3819  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.7950  decode.d0.loss_dice: 0.5310  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.6221  decode.d1.loss_dice: 0.3944  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.6044  decode.d2.loss_dice: 0.3646  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.5773  decode.d3.loss_dice: 0.3586  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.5937  decode.d4.loss_dice: 0.3586  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.5919  decode.d5.loss_dice: 0.3687  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.6087  decode.d6.loss_dice: 0.3651  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.6113  decode.d7.loss_dice: 0.3814  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6089  decode.d8.loss_dice: 0.3852\n",
      "07/02 18:07:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24300/32000]  base_lr: 1.7342e-06 lr: 1.7342e-07  eta: 0:20:26  time: 0.1607  data_time: 0.0098  memory: 5152  grad_norm: 229.4164  loss: 14.8012  decode.loss_cls: 0.0018  decode.loss_mask: 0.8815  decode.loss_dice: 0.5221  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 1.0560  decode.d0.loss_dice: 0.6699  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.9196  decode.d1.loss_dice: 0.5693  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.9218  decode.d2.loss_dice: 0.5544  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.8952  decode.d3.loss_dice: 0.5460  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.8705  decode.d4.loss_dice: 0.5318  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.8831  decode.d5.loss_dice: 0.5503  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.9031  decode.d6.loss_dice: 0.5370  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.8897  decode.d7.loss_dice: 0.5509  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.8997  decode.d8.loss_dice: 0.5473\n",
      "07/02 18:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24350/32000]  base_lr: 1.7241e-06 lr: 1.7241e-07  eta: 0:20:18  time: 0.1574  data_time: 0.0087  memory: 5153  grad_norm: 209.6335  loss: 12.3851  decode.loss_cls: 0.0005  decode.loss_mask: 0.7261  decode.loss_dice: 0.4473  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.8767  decode.d0.loss_dice: 0.6074  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.7580  decode.d1.loss_dice: 0.5135  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.7387  decode.d2.loss_dice: 0.4715  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.7427  decode.d3.loss_dice: 0.4677  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 0.4557  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7505  decode.d5.loss_dice: 0.4664  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.7447  decode.d6.loss_dice: 0.4566  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 0.4580  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.7576  decode.d8.loss_dice: 0.4492\n",
      "07/02 18:07:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24400/32000]  base_lr: 1.7139e-06 lr: 1.7139e-07  eta: 0:20:10  time: 0.1580  data_time: 0.0093  memory: 5153  grad_norm: 157.3882  loss: 12.0420  decode.loss_cls: 0.0003  decode.loss_mask: 0.7535  decode.loss_dice: 0.4320  decode.d0.loss_cls: 0.0358  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 0.5440  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.7515  decode.d1.loss_dice: 0.4487  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7384  decode.d2.loss_dice: 0.4303  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7504  decode.d3.loss_dice: 0.4304  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7292  decode.d4.loss_dice: 0.4209  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.7254  decode.d5.loss_dice: 0.4312  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7460  decode.d6.loss_dice: 0.4213  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7589  decode.d7.loss_dice: 0.4376  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.7417  decode.d8.loss_dice: 0.4293\n",
      "07/02 18:07:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24450/32000]  base_lr: 1.7038e-06 lr: 1.7038e-07  eta: 0:20:02  time: 0.1602  data_time: 0.0102  memory: 5153  grad_norm: 220.7096  loss: 12.6526  decode.loss_cls: 0.0004  decode.loss_mask: 0.7062  decode.loss_dice: 0.4893  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.8888  decode.d0.loss_dice: 0.6230  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.7691  decode.d1.loss_dice: 0.5276  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.7512  decode.d2.loss_dice: 0.5040  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7472  decode.d3.loss_dice: 0.4994  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.7390  decode.d4.loss_dice: 0.4886  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.7168  decode.d5.loss_dice: 0.4863  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7283  decode.d6.loss_dice: 0.4867  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.7154  decode.d7.loss_dice: 0.4921  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 0.4906\n",
      "07/02 18:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24500/32000]  base_lr: 1.6936e-06 lr: 1.6936e-07  eta: 0:19:54  time: 0.1619  data_time: 0.0093  memory: 5153  grad_norm: 257.5248  loss: 15.1992  decode.loss_cls: 0.1130  decode.loss_mask: 0.8457  decode.loss_dice: 0.5084  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 1.0021  decode.d0.loss_dice: 0.6837  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.8923  decode.d1.loss_dice: 0.5527  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.9183  decode.d2.loss_dice: 0.5622  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.9053  decode.d3.loss_dice: 0.5710  decode.d4.loss_cls: 0.2073  decode.d4.loss_mask: 0.8607  decode.d4.loss_dice: 0.5440  decode.d5.loss_cls: 0.1396  decode.d5.loss_mask: 0.8635  decode.d5.loss_dice: 0.5633  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.8560  decode.d6.loss_dice: 0.5526  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.8624  decode.d7.loss_dice: 0.5409  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.5316\n",
      "07/02 18:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24550/32000]  base_lr: 1.6834e-06 lr: 1.6834e-07  eta: 0:19:46  time: 0.1615  data_time: 0.0102  memory: 5153  grad_norm: 122.4540  loss: 10.9150  decode.loss_cls: 0.0001  decode.loss_mask: 0.6766  decode.loss_dice: 0.3713  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.8598  decode.d0.loss_dice: 0.4823  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.6952  decode.d1.loss_dice: 0.4054  decode.d2.loss_cls: 0.0001  decode.d2.loss_mask: 0.7207  decode.d2.loss_dice: 0.4003  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.6829  decode.d3.loss_dice: 0.3812  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.6788  decode.d4.loss_dice: 0.3735  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.6700  decode.d5.loss_dice: 0.3681  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.6706  decode.d6.loss_dice: 0.3727  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.6678  decode.d7.loss_dice: 0.3739  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.6761  decode.d8.loss_dice: 0.3665\n",
      "07/02 18:08:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24600/32000]  base_lr: 1.6733e-06 lr: 1.6733e-07  eta: 0:19:38  time: 0.1627  data_time: 0.0104  memory: 5154  grad_norm: 125.5844  loss: 9.3362  decode.loss_cls: 0.0002  decode.loss_mask: 0.5667  decode.loss_dice: 0.3477  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.6985  decode.d0.loss_dice: 0.4470  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.5809  decode.d1.loss_dice: 0.3695  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.5741  decode.d2.loss_dice: 0.3534  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5661  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.5444  decode.d4.loss_dice: 0.3357  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5549  decode.d5.loss_dice: 0.3449  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5542  decode.d6.loss_dice: 0.3370  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.5559  decode.d7.loss_dice: 0.3373  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5562  decode.d8.loss_dice: 0.3452\n",
      "07/02 18:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24650/32000]  base_lr: 1.6631e-06 lr: 1.6631e-07  eta: 0:19:30  time: 0.1605  data_time: 0.0098  memory: 5153  grad_norm: 251.0163  loss: 12.9652  decode.loss_cls: 0.0014  decode.loss_mask: 0.7921  decode.loss_dice: 0.4937  decode.d0.loss_cls: 0.0628  decode.d0.loss_mask: 0.8306  decode.d0.loss_dice: 0.5618  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.7811  decode.d1.loss_dice: 0.4999  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 0.4977  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.8151  decode.d3.loss_dice: 0.4725  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.8019  decode.d4.loss_dice: 0.4831  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.7890  decode.d5.loss_dice: 0.4747  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.7760  decode.d6.loss_dice: 0.4829  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.7783  decode.d7.loss_dice: 0.4831  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.7867  decode.d8.loss_dice: 0.4986\n",
      "07/02 18:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24700/32000]  base_lr: 1.6529e-06 lr: 1.6529e-07  eta: 0:19:22  time: 0.1626  data_time: 0.0099  memory: 5152  grad_norm: 173.4170  loss: 12.2863  decode.loss_cls: 0.0005  decode.loss_mask: 0.7245  decode.loss_dice: 0.4248  decode.d0.loss_cls: 0.0197  decode.d0.loss_mask: 0.9659  decode.d0.loss_dice: 0.6058  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.7952  decode.d1.loss_dice: 0.4769  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7769  decode.d2.loss_dice: 0.4561  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.7647  decode.d3.loss_dice: 0.4564  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.7469  decode.d4.loss_dice: 0.4471  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 0.4296  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.7193  decode.d6.loss_dice: 0.4240  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.7263  decode.d7.loss_dice: 0.4373  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 0.4246\n",
      "07/02 18:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24750/32000]  base_lr: 1.6427e-06 lr: 1.6427e-07  eta: 0:19:15  time: 0.1669  data_time: 0.0102  memory: 5153  grad_norm: 155.8544  loss: 11.2543  decode.loss_cls: 0.0003  decode.loss_mask: 0.6570  decode.loss_dice: 0.4353  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.7558  decode.d0.loss_dice: 0.5342  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.6717  decode.d1.loss_dice: 0.4558  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.6491  decode.d2.loss_dice: 0.4411  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6536  decode.d3.loss_dice: 0.4377  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.6617  decode.d4.loss_dice: 0.4449  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.6611  decode.d5.loss_dice: 0.4447  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.6705  decode.d6.loss_dice: 0.4417  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.6662  decode.d7.loss_dice: 0.4462  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.6545  decode.d8.loss_dice: 0.4417\n",
      "07/02 18:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24800/32000]  base_lr: 1.6325e-06 lr: 1.6325e-07  eta: 0:19:07  time: 0.1622  data_time: 0.0098  memory: 5154  grad_norm: 98.6880  loss: 8.3638  decode.loss_cls: 0.0006  decode.loss_mask: 0.4999  decode.loss_dice: 0.3141  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.5770  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.4820  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.4960  decode.d2.loss_dice: 0.3223  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.5138  decode.d3.loss_dice: 0.3243  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.4936  decode.d4.loss_dice: 0.3173  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.4998  decode.d5.loss_dice: 0.3146  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.4934  decode.d6.loss_dice: 0.3117  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.4926  decode.d7.loss_dice: 0.3086  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.4892  decode.d8.loss_dice: 0.3120\n",
      "07/02 18:08:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24850/32000]  base_lr: 1.6223e-06 lr: 1.6223e-07  eta: 0:18:59  time: 0.1639  data_time: 0.0091  memory: 5153  grad_norm: 191.1245  loss: 11.6098  decode.loss_cls: 0.0004  decode.loss_mask: 0.6961  decode.loss_dice: 0.4140  decode.d0.loss_cls: 0.0191  decode.d0.loss_mask: 0.8118  decode.d0.loss_dice: 0.5573  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.6931  decode.d1.loss_dice: 0.4529  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.6993  decode.d2.loss_dice: 0.4321  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.7126  decode.d3.loss_dice: 0.4399  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.7336  decode.d4.loss_dice: 0.4291  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.7085  decode.d5.loss_dice: 0.4368  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.7135  decode.d6.loss_dice: 0.4231  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.6898  decode.d7.loss_dice: 0.4197  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.6995  decode.d8.loss_dice: 0.4216\n",
      "07/02 18:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24900/32000]  base_lr: 1.6121e-06 lr: 1.6121e-07  eta: 0:18:51  time: 0.1628  data_time: 0.0098  memory: 5153  grad_norm: 188.2752  loss: 12.1434  decode.loss_cls: 0.0006  decode.loss_mask: 0.7265  decode.loss_dice: 0.4444  decode.d0.loss_cls: 0.0363  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 0.6245  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.7608  decode.d1.loss_dice: 0.4835  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.7627  decode.d2.loss_dice: 0.4927  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.7123  decode.d3.loss_dice: 0.4441  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.7075  decode.d4.loss_dice: 0.4439  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.7013  decode.d5.loss_dice: 0.4211  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.6990  decode.d6.loss_dice: 0.4177  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.7158  decode.d7.loss_dice: 0.4323  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.7353  decode.d8.loss_dice: 0.4389\n",
      "07/02 18:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24950/32000]  base_lr: 1.6019e-06 lr: 1.6019e-07  eta: 0:18:43  time: 0.1600  data_time: 0.0094  memory: 5153  grad_norm: 195.6068  loss: 12.8206  decode.loss_cls: 0.0816  decode.loss_mask: 0.7336  decode.loss_dice: 0.4352  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.8285  decode.d0.loss_dice: 0.5761  decode.d1.loss_cls: 0.0929  decode.d1.loss_mask: 0.7687  decode.d1.loss_dice: 0.5283  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.7241  decode.d2.loss_dice: 0.4858  decode.d3.loss_cls: 0.1103  decode.d3.loss_mask: 0.6738  decode.d3.loss_dice: 0.4378  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.6834  decode.d4.loss_dice: 0.4491  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.7018  decode.d5.loss_dice: 0.4517  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.7344  decode.d6.loss_dice: 0.4476  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.7257  decode.d7.loss_dice: 0.4406  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.7345  decode.d8.loss_dice: 0.4373\n",
      "07/02 18:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: mask2former_r50_8xb2-160k_ade20k-512x512_20250702_170121\n",
      "07/02 18:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25000/32000]  base_lr: 1.5916e-06 lr: 1.5916e-07  eta: 0:18:35  time: 0.1605  data_time: 0.0099  memory: 5153  grad_norm: 128.0041  loss: 10.1482  decode.loss_cls: 0.0002  decode.loss_mask: 0.5987  decode.loss_dice: 0.3829  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.7728  decode.d0.loss_dice: 0.5150  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.6131  decode.d1.loss_dice: 0.3858  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.6083  decode.d2.loss_dice: 0.3877  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.5968  decode.d3.loss_dice: 0.3775  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.6054  decode.d4.loss_dice: 0.3866  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.5990  decode.d5.loss_dice: 0.3870  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.5840  decode.d6.loss_dice: 0.3793  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.5897  decode.d7.loss_dice: 0.3812  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.5893  decode.d8.loss_dice: 0.3765\n",
      "07/02 18:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25000 iterations\n",
      "07/02 18:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [ 50/100]    eta: 0:00:02  time: 0.0214  data_time: 0.0022  memory: 2165  \n",
      "07/02 18:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    eta: 0:00:00  time: 0.0287  data_time: 0.0062  memory: 1078  \n",
      "07/02 18:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 18:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 92.08 | 94.23 |\n",
      "|   lesion   | 78.98 | 92.86 |\n",
      "+------------+-------+-------+\n",
      "07/02 18:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/100]    aAcc: 93.8900  mIoU: 85.5300  mAcc: 93.5500  data_time: 0.0116  time: 0.0368\n",
      "07/02 18:09:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25050/32000]  base_lr: 1.5814e-06 lr: 1.5814e-07  eta: 0:18:27  time: 0.1613  data_time: 0.0090  memory: 5154  grad_norm: 122.1843  loss: 10.7968  decode.loss_cls: 0.0006  decode.loss_mask: 0.6411  decode.loss_dice: 0.3896  decode.d0.loss_cls: 0.0195  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 0.5219  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.6705  decode.d1.loss_dice: 0.4008  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.6609  decode.d2.loss_dice: 0.4020  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.6598  decode.d3.loss_dice: 0.3921  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.6486  decode.d4.loss_dice: 0.3951  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.6591  decode.d5.loss_dice: 0.4013  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.6477  decode.d6.loss_dice: 0.3922  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.6468  decode.d7.loss_dice: 0.3866  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.6586  decode.d8.loss_dice: 0.3939\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# start training, maske2former performance is not very stable, you may make more trials\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmengine/mmengine/runner/runner.py:1777\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_compile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1777\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmengine/mmengine/runner/loops.py:289\u001b[0m, in \u001b[0;36mIterBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    288\u001b[0m data_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iterator)\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mval_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_begin\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    295\u001b[0m              \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters)):\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmengine/mmengine/runner/loops.py:313\u001b[0m, in \u001b[0;36mIterBasedTrainLoop.run_iter\u001b[0;34m(self, data_batch)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    318\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter,\n\u001b[1;32m    319\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[1;32m    320\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmengine/mmengine/model/base_model/base_model.py:114\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data, optim_wrapper)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optim_wrapper\u001b[38;5;241m.\u001b[39moptim_context(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preprocessor(data, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 114\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    115\u001b[0m parsed_losses, log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_losses(losses)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    116\u001b[0m optim_wrapper\u001b[38;5;241m.\u001b[39mupdate_params(parsed_losses)\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmengine/mmengine/model/base_model/base_model.py:361\u001b[0m, in \u001b[0;36mBaseModel._run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Unpacks data for :meth:`forward`\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    dict or list: Results of training or testing mode.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    363\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmsegmentation/mmseg/models/segmentors/base.py:94\u001b[0m, in \u001b[0;36mBaseSegmentor.forward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The unified entry for a forward process in both training and test.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03mThe method should accept three modes: \"tensor\", \"predict\" and \"loss\":\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    - If ``mode=\"loss\"``, return a dict of tensor.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(inputs, data_samples)\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py:178\u001b[0m, in \u001b[0;36mEncoderDecoder.loss\u001b[0;34m(self, inputs, data_samples)\u001b[0m\n\u001b[1;32m    174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(inputs)\n\u001b[1;32m    176\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 178\u001b[0m loss_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode_head_forward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss_decode)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_auxiliary_head:\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py:139\u001b[0m, in \u001b[0;36mEncoderDecoder._decode_head_forward_train\u001b[0;34m(self, inputs, data_samples)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run forward function and calculate loss for decode head in\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03mtraining.\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 139\u001b[0m loss_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(add_prefix(loss_decode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmsegmentation/mmseg/models/decode_heads/mask2former_head.py:126\u001b[0m, in \u001b[0;36mMask2FormerHead.loss\u001b[0;34m(self, x, batch_data_samples, train_cfg)\u001b[0m\n\u001b[1;32m    123\u001b[0m all_cls_scores, all_mask_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, batch_data_samples)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_by_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_cls_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_mask_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbatch_gt_instances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_img_metas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmdetection/mmdet/models/dense_heads/maskformer_head.py:348\u001b[0m, in \u001b[0;36mMaskFormerHead.loss_by_feat\u001b[0;34m(self, all_cls_scores, all_mask_preds, batch_gt_instances, batch_img_metas)\u001b[0m\n\u001b[1;32m    344\u001b[0m batch_gt_instances_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    345\u001b[0m     batch_gt_instances \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_dec_layers)\n\u001b[1;32m    346\u001b[0m ]\n\u001b[1;32m    347\u001b[0m img_metas_list \u001b[38;5;241m=\u001b[39m [batch_img_metas \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_dec_layers)]\n\u001b[0;32m--> 348\u001b[0m losses_cls, losses_mask, losses_dice \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_by_feat_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_cls_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_mask_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_gt_instances_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# loss from the last decoder layer\u001b[39;00m\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmdetection/mmdet/models/utils/misc.py:219\u001b[0m, in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m pfunc \u001b[38;5;241m=\u001b[39m partial(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m func\n\u001b[1;32m    218\u001b[0m map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(pfunc, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmap_results\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmdetection/mmdet/models/dense_heads/mask2former_head.py:322\u001b[0m, in \u001b[0;36mMask2FormerHead._loss_by_feat_single\u001b[0;34m(self, cls_scores, mask_preds, batch_gt_instances, batch_img_metas)\u001b[0m\n\u001b[1;32m    318\u001b[0m mask_point_preds \u001b[38;5;241m=\u001b[39m point_sample(\n\u001b[1;32m    319\u001b[0m     mask_preds\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), points_coords)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# dice loss\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m loss_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_dice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_point_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_point_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_total_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# mask loss\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# shape (num_queries, num_points) -> (num_queries * num_points, )\u001b[39;00m\n\u001b[1;32m    327\u001b[0m mask_point_preds \u001b[38;5;241m=\u001b[39m mask_point_preds\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmdetection/mmdet/models/losses/dice_loss.py:137\u001b[0m, in \u001b[0;36mDiceLoss.forward\u001b[0;34m(self, pred, target, weight, reduction_override, avg_factor)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weight \u001b[38;5;241m*\u001b[39m \u001b[43mdice_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnaive_dice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnaive_dice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavg_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/carasml/segmentation/Mask2former/mmdetection/mmdet/models/losses/dice_loss.py:57\u001b[0m, in \u001b[0;36mdice_loss\u001b[0;34m(pred, target, weight, eps, reduction, naive_dice, avg_factor)\u001b[0m\n\u001b[1;32m     54\u001b[0m     c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(target \u001b[38;5;241m*\u001b[39m target, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m eps\n\u001b[1;32m     55\u001b[0m     d \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m a) \u001b[38;5;241m/\u001b[39m (b \u001b[38;5;241m+\u001b[39m c)\n\u001b[0;32m---> 57\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m loss\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mask2former/lib/python3.10/site-packages/torch/_tensor.py:37\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start training, maske2former performance is not very stable, you may make more trials\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#after training/testing, clear cache\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best checkpoint: work_dirs/best_mIoU_iter_22000.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "# Setup a checkpoint file to load, input the location of best pth we trained\n",
    "def get_best_checkpoint(base_dir):\n",
    "    best_ckpt = None\n",
    "    latest_time = 0\n",
    "\n",
    "    pattern = os.path.join(base_dir, \"best_mIoU_iter_*.pth\")\n",
    "    candidates = glob.glob(pattern)\n",
    "\n",
    "    for ckpt_path in candidates:\n",
    "        mtime = os.path.getmtime(ckpt_path)\n",
    "        if mtime > latest_time:\n",
    "            latest_time = mtime\n",
    "            best_ckpt = ckpt_path\n",
    "\n",
    "    return best_ckpt\n",
    "\n",
    "best_ckpt = get_best_checkpoint(\"work_dirs/\")\n",
    "print(f\"Using best checkpoint: {best_ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 18:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 91957576\n",
      "    GPU 0: NVIDIA GeForce RTX 5090\n",
      "    CUDA_HOME: /usr/local/cuda-12.8/\n",
      "    NVCC: Cuda compilation tools, release 12.8, V12.8.93\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.7.0+cu128\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_100,code=sm_100;-gencode;arch=compute_120,code=sm_120;-gencode;arch=compute_120,code=compute_120\n",
      "  - CuDNN 90.7.1\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=134179474539648ba7dee1317959529fbd0e7f89, CUDA_VERSION=12.8, CUDNN_VERSION=9.7.1, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.7.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.22.0+cu128\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 91957576\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/02 18:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    test_cfg=dict(size_divisor=32),\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'ISIC'\n",
      "dataset_type = 'mydataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False, interval=5000, save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = 'work_dirs/best_mIoU_iter_22000.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        deep_stem=False,\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='SyncBN'),\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=32),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        enforce_decoder_input_project=False,\n",
      "        feat_channels=256,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        loss_cls=dict(\n",
      "            class_weight=[\n",
      "                1,\n",
      "                1,\n",
      "                0,\n",
      "            ],\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=False),\n",
      "        loss_dice=dict(\n",
      "            activate=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0,\n",
      "            naive_dice=True,\n",
      "            reduction='mean',\n",
      "            type='mmdet.DiceLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_mask=dict(\n",
      "            loss_weight=5.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=2,\n",
      "        num_queries=100,\n",
      "        num_transformer_feat_level=3,\n",
      "        out_channels=256,\n",
      "        pixel_decoder=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                init_cfg=None,\n",
      "                layer_cfg=dict(\n",
      "                    ffn_cfg=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2),\n",
      "                    self_attn_cfg=dict(\n",
      "                        batch_first=True,\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        im2col_step=64,\n",
      "                        init_cfg=None,\n",
      "                        norm_cfg=None,\n",
      "                        num_heads=8,\n",
      "                        num_levels=3,\n",
      "                        num_points=4)),\n",
      "                num_layers=6),\n",
      "            init_cfg=None,\n",
      "            norm_cfg=dict(num_groups=32, type='GN'),\n",
      "            num_outs=3,\n",
      "            positional_encoding=dict(normalize=True, num_feats=128),\n",
      "            type='mmdet.MSDeformAttnPixelDecoder'),\n",
      "        positional_encoding=dict(normalize=True, num_feats=128),\n",
      "        strides=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='mmdet.ClassificationCost', weight=2.0),\n",
      "                    dict(\n",
      "                        type='mmdet.CrossEntropyLossCost',\n",
      "                        use_sigmoid=True,\n",
      "                        weight=5.0),\n",
      "                    dict(\n",
      "                        eps=1.0,\n",
      "                        pred_act=True,\n",
      "                        type='mmdet.DiceCost',\n",
      "                        weight=5.0),\n",
      "                ],\n",
      "                type='mmdet.HungarianAssigner'),\n",
      "            importance_sample_ratio=0.75,\n",
      "            num_points=12544,\n",
      "            oversample_ratio=3.0,\n",
      "            sampler=dict(type='mmdet.MaskPseudoSampler')),\n",
      "        transformer_decoder=dict(\n",
      "            init_cfg=None,\n",
      "            layer_cfg=dict(\n",
      "                cross_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0),\n",
      "                ffn_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    add_identity=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_drop=0.0,\n",
      "                    num_fcs=2),\n",
      "                self_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0)),\n",
      "            num_layers=9,\n",
      "            return_intermediate=True),\n",
      "        type='Mask2FormerHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "num_classes = 2\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=6.25e-06,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            backbone=dict(decay_mult=1.0, lr_mult=0.1),\n",
      "            level_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_embed=dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),\n",
      "        norm_decay_mult=0.0),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(\n",
      "    betas=(\n",
      "        0.9,\n",
      "        0.999,\n",
      "    ),\n",
      "    eps=1e-08,\n",
      "    lr=6.25e-06,\n",
      "    type='AdamW',\n",
      "    weight_decay=0.05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=32000,\n",
      "        eta_min=0,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=32000, type='IterBasedTrainLoop', val_interval=1000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                max_size=2048,\n",
      "                resize_type='ResizeShortestEdge',\n",
      "                scales=[\n",
      "                    256,\n",
      "                    307,\n",
      "                    358,\n",
      "                    409,\n",
      "                    460,\n",
      "                    512,\n",
      "                    563,\n",
      "                    614,\n",
      "                    665,\n",
      "                    716,\n",
      "                    768,\n",
      "                    819,\n",
      "                    870,\n",
      "                    921,\n",
      "                    972,\n",
      "                    1024,\n",
      "                ],\n",
      "                type='RandomChoiceResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "            dict(\n",
      "                keymap=dict(gt_seg_map='mask', img='image'),\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        border_mode=4,\n",
      "                        interpolation=1,\n",
      "                        p=0.5,\n",
      "                        rotate=(\n",
      "                            -180,\n",
      "                            180,\n",
      "                        ),\n",
      "                        scale=(\n",
      "                            0.8,\n",
      "                            1.1,\n",
      "                        ),\n",
      "                        translate_percent=(\n",
      "                            -0.05,\n",
      "                            0.05,\n",
      "                        ),\n",
      "                        type='Affine'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                hue_shift_limit=10,\n",
      "                                p=1.0,\n",
      "                                sat_shift_limit=10,\n",
      "                                type='HueSaturationValue',\n",
      "                                val_shift_limit=10),\n",
      "                            dict(\n",
      "                                brightness_limit=0.1,\n",
      "                                contrast_limit=0.1,\n",
      "                                p=1.0,\n",
      "                                type='RandomBrightnessContrast'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                    dict(\n",
      "                        p=0.5,\n",
      "                        transforms=[\n",
      "                            dict(\n",
      "                                border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                            dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                        ],\n",
      "                        type='OneOf'),\n",
      "                ],\n",
      "                type='Albu'),\n",
      "            dict(type='ConvertMaskFromAlbu'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_path',\n",
      "                    'img_shape',\n",
      "                    'img',\n",
      "                    'gt_seg_map',\n",
      "                ),\n",
      "                type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        max_size=2048,\n",
      "        resize_type='ResizeShortestEdge',\n",
      "        scales=[\n",
      "            256,\n",
      "            307,\n",
      "            358,\n",
      "            409,\n",
      "            460,\n",
      "            512,\n",
      "            563,\n",
      "            614,\n",
      "            665,\n",
      "            716,\n",
      "            768,\n",
      "            819,\n",
      "            870,\n",
      "            921,\n",
      "            972,\n",
      "            1024,\n",
      "        ],\n",
      "        type='RandomChoiceResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(num_classes=8, type='ConvertMaskForAlbu'),\n",
      "    dict(\n",
      "        keymap=dict(gt_seg_map='mask', img='image'),\n",
      "        transforms=[\n",
      "            dict(\n",
      "                border_mode=4,\n",
      "                interpolation=1,\n",
      "                p=0.5,\n",
      "                rotate=(\n",
      "                    -180,\n",
      "                    180,\n",
      "                ),\n",
      "                scale=(\n",
      "                    0.8,\n",
      "                    1.1,\n",
      "                ),\n",
      "                translate_percent=(\n",
      "                    -0.05,\n",
      "                    0.05,\n",
      "                ),\n",
      "                type='Affine'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        hue_shift_limit=10,\n",
      "                        p=1.0,\n",
      "                        sat_shift_limit=10,\n",
      "                        type='HueSaturationValue',\n",
      "                        val_shift_limit=10),\n",
      "                    dict(\n",
      "                        brightness_limit=0.1,\n",
      "                        contrast_limit=0.1,\n",
      "                        p=1.0,\n",
      "                        type='RandomBrightnessContrast'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "            dict(\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(border_mode=4, p=1.0, type='ElasticTransform'),\n",
      "                    dict(border_mode=4, p=1.0, type='GridDistortion'),\n",
      "                ],\n",
      "                type='OneOf'),\n",
      "        ],\n",
      "        type='Albu'),\n",
      "    dict(type='ConvertMaskFromAlbu'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_path',\n",
      "            'img_shape',\n",
      "            'img',\n",
      "            'gt_seg_map',\n",
      "        ),\n",
      "        type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='ISIC',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='mydataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmengine/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 18:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/02 18:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "/home/test/carasml/segmentation/Mask2former/mmsegmentation/mmseg/datasets/transforms/loading.py:83: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 18:09:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by local backend from path: work_dirs/best_mIoU_iter_22000.pth\n",
      "07/02 18:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/best_mIoU_iter_22000.pth\n",
      "07/02 18:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 50/100]    eta: 0:00:02  time: 0.0224  data_time: 0.0025  memory: 6833  \n",
      "07/02 18:09:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/100]    eta: 0:00:00  time: 0.0297  data_time: 0.0065  memory: 5742  \n",
      "07/02 18:09:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/02 18:09:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+------------+-------+-------+\n",
      "|   Class    |  IoU  |  Acc  |\n",
      "+------------+-------+-------+\n",
      "| background | 93.01 | 95.54 |\n",
      "|   lesion   | 80.74 | 91.71 |\n",
      "+------------+-------+-------+\n",
      "07/02 18:09:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/100]    aAcc: 94.5900  mIoU: 86.8800  mAcc: 93.6300  data_time: 0.0145  time: 0.0405\n"
     ]
    }
   ],
   "source": [
    "%run tools/test.py work_dirs/mask2former_r50_8xb2-160k_ade20k-512x512.py {best_ckpt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#after training/testing, clear cache\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/best_mIoU_iter_22000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/carasml/segmentation/Mask2former/mmengine/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7e25cc28fc40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile('work_dirs/mask2former_r50_8xb2-160k_ade20k-512x512.py')\n",
    "\n",
    "# Init the model from the config and the checkpoint\n",
    "checkpoint_path = best_ckpt\n",
    "model = init_model(cfg, checkpoint_path, 'cuda:0')\n",
    "\n",
    "img = mmcv.imread('ISIC/images/validation/ISIC_0012255.jpg')\n",
    "result = inference_model(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "vis_result = show_result_pyplot(model, img, result)\n",
    "plt.imshow(mmcv.bgr2rgb(vis_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export \n",
    "Currently MMdeploy does not support exporting Mask2former to other backends yet.\n",
    "If you need model to export, please refer to https://mmdeploy.readthedocs.io/en/latest/03-benchmark/supported_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (mask2former)",
   "language": "python",
   "name": "mask2former"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "0442e67aee3d9cbb788fa6e86d60c4ffa94ad7f1943c65abfecb99a6f4696c58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
